{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction "},"content/JavaBasic/基本类型和包装类型.html":{"url":"content/JavaBasic/基本类型和包装类型.html","title":"基本类型和包装类型","keywords":"","body":"基本类型和包装类型的区别 包装类型可以为NULL，基本类型不可以 包装类型可以应用于 POJO 中，而基本类型则不行。数据库的查询结果可能是 null，如果使用基本类型的话，因为要自动拆箱(将包装类型转为基本类型，比如说把 Integer 对象转换成 int 值），就会抛出 NullPointerException 的异常。 包装类型可用于泛型，基本类型不可以 泛型不能使用基本类型，因为使用基本类型时会编译出错。因为泛型在编译时会进行类型擦除，最后只保留原始类型，而原始类型只能是 Object 类及其子类——基本类型是个特例。 基本类型比包装类型更高效 基本类型在栈中直接存储的具体数值，而包装类型则存储的是堆中的引用。 两个包装类型的值可以相同但却不相等 Integer chenmo = new Integer(10); Integer wanger = new Integer(10); System.out.println(chenmo == wanger); // false System.out.println(chenmo.equals(wanger )); // true 自动装箱和自动拆箱 把基本类型转换成包装类型的过程叫做装箱(boxing)。反之，把包装类型转换成基本类型的过程叫做拆箱(unboxing)。 自动装箱是通过 Integer.valueOf() 完成的，自动拆箱是通过 Integer.intValue() 完成的。 // 1）基本类型和包装类型 int a = 100; Integer b = 100; System.out.println(a == b);//true // 2）两个包装类型 Integer c = 100; Integer d = 100; System.out.println(c == d);//true // 3） c = 200; d = 200; System.out.println(c == d);//false 第一段代码，基本类型和包装类型进行 == 比较，这时候 b 会自动拆箱，直接和 a 比较值，所以结果为 true。 第二段代码，当需要进行自动装箱时，如果数字在 -128 至 127 之间时，会直接使用缓存中的对象(IntegerCache)而不是重新建一个对 象。100 在这个范围之内，结果是true。 第三段代码，200 不在这个范围之内，所以 new 出来了两个 Integer 对象，结果是 false。 "},"content/JavaBasic/多态.html":{"url":"content/JavaBasic/多态.html","title":"多态","keywords":"","body":"多态的定义 Java具备面向对象的三个特征：继承，封装和多态 多态性是允许你将父对象设置成为一个或更多的他的子对象相等的技术。在程序中定义的引用变量所指向的具体类型和通过该引用变量的方法调用在编程的时候并不确定，当处于运行期间才确定。这样不用修改源码就可以把变量绑定到不同的类实例上，让程序拥有了多个运行状态，这就是多态。 多态的三个前提条件： 1. 要有继承关系 2. 子类要重写父类的方法 3. 父类引用指向子类对象 补充一下第二点，既然多态存在必须要有“子类重写父类方法”这一条件，那么以下三种类型的方法是没有办法表现出多态特性的（因为不能被重写）： 1、static方法，因为被static修饰的方法是属于类的，而不是属于实例的 2、final方法，因为被final修饰的方法无法被子类重写 3、private方法和protected方法，前者是因为被private修饰的方法对子类不可见，后者是因为尽管被protected修饰的方法可以被子类见到，也可以被子类重写，但是它是无法被外部所引用的，一个不能被外部引用的方法，怎么能谈多态呢 多态的分类: 编译时多态，即方法的重载，从JVM的角度来讲，这是一种静态分派（static dispatch） 运行时多态，即方法的重写，从JVM的角度来讲，这是一种动态分派（dynamic dispatch 静态分派 静态分派原理 class Human{ } class Man extends Human{ } class Woman extends Human{ } public class StaticPai{ public void say(Human hum){ System.out.println(\"I am human\"); } public void say(Man hum){ System.out.println(\"I am man\"); } public void say(Woman hum){ System.out.println(\"I am woman\"); } public static void main(String[] args){ Human man = new Man(); Human woman = new Woman(); StaticPai sp = new StaticPai(); sp.say(man); sp.say(woman); } } // 执行结果为 I am human ，I am human 我们把上面代码中的“Human”称为变量的静态类型，后面的“Men”称为变量的实际类型。静态类型是在编译期间可知的；而实际类型变化的结果在运行期间才可确定，编译器在编译程序时并不知道一个对象的实际类型是什么。 mian()中两次调用sayHello()方法，在方法接受者已经确定是对象“sp”的前提下，使用哪个重载版本，就完全取决于传入参数的数量和数据类型。编译器在重载时通过参数的静态类型而不是实际类型作为判断依据的，因此在编译阶段Java编译器根据参数的静态类型决定使用哪个重载版本。 静态分派优先级 public class Overload { private static void sayHello(char arg){ System.out.println(\"hello char\"); } private static void sayHello(Object arg){ System.out.println(\"hello Object\"); } private static void sayHello(int arg){ System.out.println(\"hello int\"); } private static void sayHello(char... arg){ System.out.println(\"hello cHAR...\"); } // 测试代码 public static void main(String[] args) { sayHello('a'); } } // 运行结果 hello char 优先级顺序为：char>int>long>float>double>Character>Serializable>Object>... 其中...为变长参数，将其视为一个数组元素。变长参数的重载优先级最低。 因为 char 转型到 byte 或 short 的过程是不安全的，所以不会选择参数类型为byte 或 short的方法进行重载，故优先级列表里也没有。 上面讲解的主要是 基本数据类型的优先级匹配问题 若是引用类型，则根据 继承关系 进行优先级匹配 动态分派 // 定义类 class Human { public void sayHello(){ System.out.println(\"Human say hello\"); } } // 继承自 抽象类Human 并 重写sayHello() class Man extends Human { @Override protected void sayHello() { System.out.println(\"man say hello\"); } } class Woman extends Human { @Override protected void sayHello() { System.out.println(\"woman say hello\"); } } // 测试代码 public static void main(String[] args) { // 情况1 Human man = new man(); man.sayHello(); // 情况2 man = new Woman(); man.sayHello(); } } // 运行结果 man say hello woman say hello invokevirtual指令多态查找执行的第一步就是在运行期确定接收者（执行sayhello方法的对象）的实际类型，第二步将常量池中类方法符号引用解析到不同的直接引用上。这个过程就是Java语言中方法重写的本质。 两者的区别 类型 分派原理 发生阶段 应用场景 静态分派 根据变量的静态类型 编译器（不由虚拟机执行） 方法重载 动态分派 根据变量的动态类型 运行期（由虚拟机执行） 方法重写 "},"content/JavaBasic/泛型.html":{"url":"content/JavaBasic/泛型.html","title":"泛型","keywords":"","body":"泛型的定义 泛型，即“参数化类型”。就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。其存在的意义在于： 强制的类型检查：Java 编译器会对泛型代码进行强制类型检查，如果违反类型安全则会抛出错误。在编译阶段解决类型错误，能更有效的减少 Bug 消除类型强制转换：如果不使用泛型，则在进行代码编写是需要手动进行类型转换 实现通用算法：通过泛型，程序员能在不同类型的集合上实现通用算法 泛型类、方法、接口 /** * Description: 泛型方法 */ public class GenericMethod3 { static class Animal { @Override public String toString() { return \"Animal\"; } } static class Dog extends Animal { @Override public String toString() { return \"Dog\"; } } static class Fruit { @Override public String toString() { return \"Fruit\"; } } //泛型类 static class GenericClass { public void show01(T t) { System.out.println(t.toString()); } //泛型方法 public void show02(T t) { System.out.println(t.toString()); } public void show03(K k) { System.out.println(k.toString()); } } public static void main(String[] args) { Animal animal = new Animal(); Dog dog = new Dog(); Fruit fruit = new Fruit(); GenericClass genericClass = new GenericClass<>(); //泛型类在初始化时限制了参数类型 genericClass.show01(dog); // genericClass.show01(fruit); //泛型方法的参数类型在使用时指定 genericClass.show02(dog); genericClass.show02(fruit); genericClass.show03(animal); genericClass.show03(dog); genericClass.show03(fruit); // genericClass.show03(animal); } } 通配符 指定了泛型类型的上界 指定了泛型类型的下界 指定了没有限制的泛型类型 类型擦除（泛型的实现） Java 语言引入了泛型，以在编译时提供更严格的类型检查并支持泛型编程。为实现泛型 Java 编译器会进行类型擦除： 替换所有类型参数为他们的上界或者 Object，因此，字节码仅包含普通的类，接口和方法。 必要时插入类型转换，以保持类型安全。 生成桥接方法以在扩展的泛型类型中保留多态。 类型擦除可确保不会为参数化类型创建新的类；因此，泛型不会产生运行时开销。 泛型类型的擦除 在类型擦除过程中，Java 编译器将擦除所有类型参数，如果类型参数是有界的，则将每个参数替换为其第一个边界；如果类型参数是无界的，则将其替换为 Object。 public class Node { private T data; private Node next; public Node(T data, Node next) { this.data = data; this.next = next; } public T getData() { return data; } // ... } 由于 T 是无界的，所以其类型擦除后的代码为： public class Node { private Object data; private Node next; public Node(Object data, Node next) { this.data = data; this.next = next; } public Object getData() { return data; } // ... } 而对于以下代码的擦除又不一样： public class Node> { private T data; private Node next; public Node(T data, Node next) { this.data = data; this.next = next; } public T getData() { return data; } // ... } //擦除后 public class Node { private Comparable data; private Node next; public Node(Comparable data, Node next) { this.data = data; this.next = next; } public Comparable getData() { return data; } // ... } 泛型方法擦除 泛型方法的擦除规则和泛型类型的擦除规则类似： // Counts the number of occurrences of elem in anArray. public static int count(T[] anArray, T elem) { int cnt = 0; for (T e : anArray) if (e.equals(elem)) ++cnt; return cnt; } public static void draw(T shape) { /* ... */ } //擦除后 public static int count(Object[] anArray, Object elem) { int cnt = 0; for (Object e : anArray) if (e.equals(elem)) ++cnt; return cnt; } public static void draw(Shape shape) { /* ... */ } 桥接方法 对于以下两个类： public class Node { public T data; public Node(T data) { this.data = data; } public void setData(T data) { System.out.println(\"Node.setData\"); this.data = data; } } public class MyNode extends Node { public MyNode(Integer data) { super(data); } public void setData(Integer data) { System.out.println(\"MyNode.setData\"); super.setData(data); } } 类型擦除： public class Node { public Object data; public Node(Object data) { this.data = data; } public void setData(Object data) { System.out.println(\"Node.setData\"); this.data = data; } } public class MyNode extends Node { public MyNode(Integer data) { super(data); } public void setData(Integer data) { System.out.println(\"MyNode.setData\"); super.setData(data); } } 在类型擦除后，方法的签名不匹配，导致重写的方法不生效，Node.setData(T) 变成了 Node.setData(Object)。为解决这个问题，Java 编译器在子类型中生成桥接方法，对于 MyNode 其生成的方法如下： class MyNode extends Node { // Bridge method generated by the compiler // public void setData(Object data) { setData((Integer) data); } public void setData(Integer data) { System.out.println(\"MyNode.setData\"); super.setData(data); } // ... } 这样，在类型擦除之后，MyNode 具有与 Node 的 setData(Object) 方法相同的方法签名的桥接方法，并将其委托给的 setData(Integer) 方法。 "},"content/JavaBasic/反射.html":{"url":"content/JavaBasic/反射.html","title":"反射","keywords":"","body":"反射 JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。 获取class对象的四种方式 知道具体类的情况下可以使用。Class alunbarClass = TargetObject.class; 通过 Class.forName()传入类的路径获取。一旦初始化，就会触发目标对象的 static块代码执行，static参数也会被再次初始化。 通过对象实例instance.getClass()获取。 xxxClassLoader.loadClass()传入类路径获取。不进行包括初始化等一系列步骤，静态块和静态对象不会得到执行 创建对象 Class c = Class.forName(\"A的全类名\"); Constructor constructor = c.getConstructor(); Object obj = constructor.newInstance(); Class.forName(\"HelloWorld\").newInstance(); 无论是反射，还是New，其实都是通过类加载器对.class文件加载进内存中，创建了Class对象。Java中反射属于动态编译，而new属于静态编译。 静态编译：在编译时确定类型，绑定对象 动态编译：运行时确定类型，绑定对象 优缺点 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 1,性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。2,安全问题，让我们可以动态操作改变类的属性同时也增加了类的安全隐患。 "},"content/JavaBasic/集合.html":{"url":"content/JavaBasic/集合.html","title":"集合","keywords":"","body":"List List是有序的队列，List中的每一个元素都有一个索引。List中允许有重复的元素。实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。 Arraylist 与 LinkedList 区别 1. 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 2. 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构 3. 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以对于add(\bE e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O（1），如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。 4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 5. 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 ArrayList 与 Vector Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。 Set HashSet（无序，唯一）: 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承于 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树) 当把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。 Map HashMap：数组+链表+红黑树 LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 Hashtable： 数组+链表组成的， TreeMap： 红黑树（自平衡的排序二叉树） HashMap 和 HashSet HashMap 和 Hashtable 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰。 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 "},"content/JavaBasic/ConcurrentHashMap.html":{"url":"content/JavaBasic/ConcurrentHashMap.html","title":"ConcurrentHashMap","keywords":"","body":"1.7和1.8区别 在 JDK1.7 的实现上，ConrruentHashMap 由一个个 Segment 组成，简单来说， ConcurrentHashMap 是一个 Segment 数组，它通过继承 ReentrantLock 来进行加锁，通过每次锁住一个 segment 来保证每个 segment 内的操作的线程安全性从而实现全局线程安全。 在 JDK1.7 的实现上 取消了 segment 分段设计，直接使用 Node 数组来保存数据，并且采用 Node 数组元素作为锁来实现每一行数据进行加锁来进一步减少并发冲突的概率 将原本数组+单向链表的数据结构变更为了数组+单向链表+红黑树的结构。采用单向列表方式，那么查询某个节点的时间复杂度就变为 O(n); 因此对于 队列长度超过 8 的列表，JDK1.8 采用了红黑树的结构，那么查询的时间复杂度就会降低到 O(logN),可以提升查找的性能。 Put源码 final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //用来记录链表的长度 for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); //如果数组为空，则进行数组初始化 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null,new Node(hash, key, value, null))) //cas 将新的值封装成 node 插入 break; } // else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { ////头结点的hash值大于0，说明是链表 if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash &&((ek = e.key) == key ||(ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; //一直遍历到链表的最末端，直接把新的值加入到链表的最后面 if ((e = e.next) == null) { pred.next = new Node(hash, key,value, null); break; } } } //如果当前的 f 节点是一颗红黑树 else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key,value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { ////如果链表长度已经达到临界值 8 ////tab 的长度是不是小于 64， 如果是，则执行扩容 //否则，将当前链表转化为红黑树结构存储 if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 数组初始化 private final Node[] initTable() { Node[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node[] nt = (Node[])new Node[n]; //将这个数组赋值给table table = tab = nt; //计算下次扩容的大小 sc = n - (n >>> 2); } } finally { //设置sizeCtl为sc sizeCtl = sc; } break; } } return tab; } sizeCtl 这个标志是在 Node 数组初始化或者扩容的时候的一个控制位标识，负数代表正在进行初化或者扩容操作。 -1 代表正在初始化。-N 代表有 N-1个线程正在进行扩容操作 0 标识 Node 数组还没有被初始化，正数代表初始化或者下一次扩容的大小 addCount addCount 来增加 ConcurrentHashMap 中的元素个数， 并且还会可能触发扩容操作。 ConcurrentHashMap 是采用 CounterCell 数组来记录元素个数的。 首先判断 counterCells 是否为空，如果为空，就通过 cas 操作尝试修改 baseCount 变量，对这个变量进行原子累加操作。在没有竞争的情况下，仍然采用 baseCount 来记录元素个数。如果 cas 失败说明存在竞争，这个时候不能再采用 baseCount 来累加，而是通过CounterCell 来记录。 CounterCell 数组的每个元素，都存储一个元素个数，而实际我们调用size 方法就是通过这个循环累加来得到的。 transfer 扩容 判断是否需要扩容，也就是当更新后的键值对总数 baseCount >= 阈值 sizeCtl 时，进行 rehash，这里面会有两个逻辑。 如果当前正在处于扩容阶段，则当前线程会加入并且协助扩容 如果当前没有在扩容，则直接触发扩容操作 ConcurrentHashMap 并没有直接加锁，而是采用 CAS 实现无锁的并发同步策略，最精华 的部分是它可以利用多线程来进行协同扩容。它把 Node 数组当作多个线程之间共享的任务队列，然后通过维护一个指针来划 分每个线程锁负责的区间，每个线程通过区间逆向遍历来实现扩容，一个已经迁移完的 bucket 会被替换为一个 ForwardingNode 节点，标记当前 bucket 已经被其他线程迁移完了。 把 Node 数组进行拆分，让每个线程处理自己的区域，假设 table 数组总长度是 64，默认情况下，那么每个线程可以分到 16 个 bucket。 然后每个线程处理的范围，按照倒序来做迁移 通过 for 自循环处理每个槽位中的链表元素，默认 advace 为真，通过 CAS 设置 transferIndex 属性值，并初始化 i 和 bound 值，i 指当前处理的槽位序号，bound 指需要处理的槽位边界， 先处理槽位 31 的节点; (bound,i) =(16,31) 从 31 的位置往前推动。 通过分配好迁移的区间之后，开始对数据进行迁移。对数组该节点位置加锁，开始处理数组该位置的迁移工作。ConcurrentHashMap 在做链表迁移时，会用高低位来实现。通过 fn&n 可以把这个链表中的元素分为两类，将低位的链表放在 i 位置也就是不动，将高位链表放在 i+n 位置。 Get源码 //会发现源码中没有一处加了锁 public V get(Object key) { Node[] tab; Node e, p; int n, eh; K ek; int h = spread(key.hashCode()); //计算hash if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {//读取首节点的Node元素 if ((eh = e.hash) == h) { //如果该节点就是首节点就返回 if ((ek = e.key) == key || (ek != null && key.equals(ek))) return e.val; } //hash值为负值表示正在扩容，这个时候查的是ForwardingNode的find方法来定位到nextTable来 //eh=-1，说明该节点是一个ForwardingNode，正在迁移，此时调用ForwardingNode的find方法去nextTable里找。 //eh=-2，说明该节点是一个TreeBin，此时调用TreeBin的find方法遍历红黑树，由于红黑树有可能正在旋转变色，所以find里会有读写锁。 //eh>=0，说明该节点下挂的是一个链表，直接遍历该链表即可。 else if (eh get操作全程不需要加锁是因为Node的成员val是用volatile修饰的和数组用volatile修饰没有关系。 数组用volatile修饰主要是保证在数组扩容的时候保证可见性。 "},"content/JavaBasic/HashMap.html":{"url":"content/JavaBasic/HashMap.html","title":"HashMap","keywords":"","body":"Put源码 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) { Node[] tab; Node p; int n, i; //初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //判断该位置是否为空 if ((p = tab[i = (n - 1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else { //e为临时节点，判断是否覆盖 Node e; K k; //覆盖原来节点 if (p.hash == hash &&((k = p.key) == key || (key != null && key.equals(k)))) e = p; //树节点 else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { //链表情况 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //触发树化操作 if (binCount >= TREEIFY_THRESHOLD - 1) // treeifyBin(tab, hash); break; } if (e.hash == hash &&((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } if (e != null) { V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; //判断是否扩容 //hashmap中的元素个数超过数组大小*loadFactor if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } hash计算 hash = key.hashCode()的高16位和低16位异或的方式 hash值尽可能分散 数组的位置：(n-1) & hash 数组的大小必须是2的n次幂，保证最后为1111，与操作计算时才取决于hash值 resize扩容 原位置只有一个元素，直接hash之后放置 原位置是红黑树，split(tree)，会判断是否小于6，转链表 原位置是链表，则通过判断e.hash & oldCap) == 0,==0则放入原位置，!=0则移动到 容量扩大，左移一位 remove()方法 原位置是红黑树时，会根据下面条件动态判断，节点数小于6可能转化。 root == null|| (movable&& (root.right == null|| (rl = root.left) == null || rl.left == null) Get()方法 get(Object key)流程，通过传入的key通过hash()算法得到hash值，在通过(n - 1) & hash找到数组下标，如果数组下标所对应的node值正好key一样就返回，否则找到node.next找到下一个节点，看是否是treenNode，如果是，遍历红黑树找到对应node，如果不是遍历链表找到node。 "},"content/JavaBasic/hashcode和equals.html":{"url":"content/JavaBasic/hashcode和equals.html","title":"hashcode和equals","keywords":"","body":"hashcode hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode()定义在 JDK 的 Object 类中，这就意味着 Java 中的任何类都包含有 hashCode() 函数。另外需要注意的是： Object 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的， 该方法通常用来将对象的内存地址 转换为整数之后返回。 equals() equals() 的作用是用来判断两个对象是否相等。 若某个类没有覆盖equals()方法，当它的通过equals()比较两个对象时，实际上是比较两个对象是不是同一个对象。这时，等价于通过“==”去比较这两个对象。 我们可以覆盖类的equals()方法，来让equals()通过其它方式比较两个对象是否相等。通常的做法是：若两个对象的内容相等，则equals()方法返回true；否则，返回fasle。 重写equals必须重写hashcode 如果根据 equals(Object) 方法，两个对象是相等的，那么对这两个对象中的每个对象调用 hashCode 方法都必须生成相同的整数结果。 重写hashcode方法为了将数据存入HashSet/HashMap/Hashtable类时进行比较 "},"content/JavaConcurrency/JMM.html":{"url":"content/JavaConcurrency/JMM.html","title":"内存模型JMM","keywords":"","body":"JMM的定义 Java内存模型(Java Memory Model简称JMM)是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量(包括实例字段，静态字段和构成数组对象的元素)的访问方式。 JMM 抽象模型分为主内存、工作内存。主内存是共享内存区域，所有变量都存储在主内存。工作内存是每个线程独占的，线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存。线程间的通信(传值)必须通过主内存来完成。 此处的主内存和工作内存跟JVM内存划分（堆、栈、方法区）是在不同的层次上进行的。主内存从某个程度上讲应该包括了堆和方法区，而工作内存从某个程度上讲则应该包括程序计数器、虚拟机栈以及本地方法栈。从更底层的来说，主内存对应的是硬件的物理内存，工作内存对应的是寄存器和高速缓存。 JMM内存交互操作 lock(锁定)作用于主内存的变量，把一个变量标记为一条线程独占状态 unlock(解锁):作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read(读取):作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load(载入):作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use(使用):作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎。 assign(赋值):作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量。 store(存储):作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中， 以便随后的write的操作。 write(写入):作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中。 JMM内存同步规则 如果要把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作， 如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。 不允许一个线程无原因地(没有发生过任何assign操作)把数据从工作内存同步回主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化(load 或者assign)的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load 操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复 执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和 unlock必须成对出现。 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变 量之前需要重新执行load或assign操作初始化变量的值。 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中(执行store和write操 作) "},"content/JavaConcurrency/volatile.html":{"url":"content/JavaConcurrency/volatile.html","title":"Volatile","keywords":"","body":"volatile的特性 volatile是Java虚拟机提供的轻量级的同步机制。volatile关键字有如下作用 可见性。保证被volatile修饰的共享变量对所有线程总数可见 有序性。禁止指令重排序优化 不能保证原子性。对单个volatile变量的读写具有原子性。对i++这种复合操作不具有原子性 volatile的可见性 JMM内存交互层面：volatile修饰的变量的read、load、use操作和assign、store、write必须是连续的，即修改后必须立即同步回主内存，使用时必须从主内存刷新，由此保证volatile变量的可见性。 底层实现：通过汇编的lock前缀指令，它会锁定变量缓存行区域并写回主内存，这个操作称为“缓存锁定”，缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据。一个处理器的缓存回写到内存内存会导致其他处理器的缓存无效。 缓存一致性 解决缓存不一致的问题，在 CPU 层面做了很多事情， 主要提供了两种解决办法：总线锁和缓存锁 总线锁。在多CPU下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK# 信号，这个信号使得其他处理器无法通过总线来访问到共 享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据。所以总线锁定的开销比较大。 缓存锁。就是控制锁的保护粒度，保证对于被多个 CPU 缓存的同一份数据是一致的就行，它核心机制是基于缓存一致性协议来实现的。 缓存一致性协议 最常见的就是 MESI 协议。 只有Core 0访问变量x，它的Cache line状态为E(Exclusive)。 3个Core都访问变量x，它们对应的Cache line为S(Shared)状态。 Core 0修改了x的值之后，这个Cache line变成了M(Modified)状态，其他Core对应的Cache line变成了I(Invalid)状态。 在MESI协议中，每个Cache的Cache控制器不仅知道自己的读写操作，而且也监听(snoop)其它Cache的读写操作。每个Cache line所处的状态根据本核和其它核的读写操作在4个状态间进行迁移。 volatile的有序性 java语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。重排序分为编译器重排序和处理器重排序。 为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。 禁止编译器重排序 下图是JMM针对编译器制定的volatile重排序规则表。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后。当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前。当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 禁止处理器重排序 编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 下面是基于保守策略的JMM内存屏障插入策略。 在每个volatile写操作的前面插入一个StoreStore屏障。在每个volatile写操作的后面插入一个StoreLoad屏障。在每个volatile读操作的后面插入一个LoadLoad屏障。在每个volatile读操作的后面插入一个LoadStore屏障。 屏障类型 指令示例 说明 LoadLoadBarriers Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 StoreStoreBarriers Store1;StoreStore;Store2 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 LoadStoreBarriers Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoadBarriers Store1;StoreLoad;Load1 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作.它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 下面通过具体的示例代码进行说明 class VolatileBarrierExample { int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() { int i = v1; // 第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; // 普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; // 第二个 volatile } } volatile不能保证原子性 public class VolatileVisibility { public static volatile int i = 0; public static void increase(){ i++; } } 在并发场景下，i变量的任何改变都会立马反应到其他线程中，但是如此存在多条线程同时 调用increase()方法的话，就会出现线程安全问题，毕竟i++操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一 个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败。 总线风暴 由于Volatile的MESI缓存一致性协议，需要不断的从主内存嗅探和cas不断循环，无效交互会导致总线带宽达到峰值。 "},"content/JavaConcurrency/synchronized.html":{"url":"content/JavaConcurrency/synchronized.html","title":"Synchronized","keywords":"","body":"synchronized 的基本认识 synchronized 有三种方式来加锁，分别是 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁 静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 不同的修饰类型，代表锁的控制粒度。 synchronized存储 HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头 (Header)、实例数据(Instance Data)和对齐填充(Padding)。 对象头：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁(线程)ID，偏向时间，数组长度(数组对象)等 实例数据：即创建对象时，对象中成员变量，方法等。 对齐填充：对象的大小必须是8字节的整数倍。 instanceOopDesc继承自 oopDesc，oopDesc 的定义载 Hotspot 源码中的 oop.hpp 文件中。oopDesc 的定义包含两个成员mark 和 _metadata。_mark 表示对象标记、属于 markOop 类型，也就是Mark World。metadata 表示类元信息，类元信息存储的是对象指向它的类元数据的首地址。 Mark World Mark word 记录了对象和锁有关的信息，当某个对象被 synchronized 关键字当成同步锁时，那么围绕这个锁的一系列操作都和 Mark word 有关系。 为什么任何对象都可以实现锁 首先，Java 中的每个对象都派生自 Object 类，而每个Java Object 在 JVM 内部都有一个 native 的 C++对象oop/oopDesc 进行对应。 线程在获取锁的时候，实际上就是获得一个监视器对象(monitor)，monitor 可以认为是一个同步对象，所有的 Java 对象是天生携带 monitor。 锁的升级 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的 竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单 向的，也就是说只能从低到高升级，不会出现锁的降级。 偏向锁 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，会在对象头中存储当前线程的ID。当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程。 当存在 2 个以上的线程竞争，如果开启偏向锁，反而会提升获取锁的资源消耗。所以可以通过 jvm 参数UseBiasedLocking 来设置开启或关闭偏向锁。 轻量级锁 倘若偏向锁失败，虚拟机会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，会进行自旋锁的优化手段。如果直接挂起，线程之间的切换需要从用户态转换到核心态。默认情况下自旋的次数是 10 次， 可以通过 preBlockSpin 来修改。在 JDK1.6 之后，引入了自适应自旋锁，自适应意味着自旋的次数不是固定不变的，而是根据前一次在同一个锁上自旋的时间以及锁的拥有者的状态来决定。 重量级锁 当轻量级锁膨胀到重量级锁之后，意味着线程只能被挂起阻塞来等待被唤醒了。在字节码中会看到一个 monitorenter 和 monitorexit。monitorenter 表示去获得一个对象监视器。monitorexit 表示释放 monitor 监视器的所有权，使得其他被阻塞的线程可以尝试去获得这个监视器 monitor 依赖操作系统的 MutexLock(互斥锁)来实现的, 线程被阻塞后便进入内核(Linux)调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能。 任意线程对 Object(Object 由 synchronized 保护)的访问，首先要获得 Object 的监视器。如果获取失败，线程进入同步队列，线程状态变为 BLOCKED。当访问 Object 的前驱(获得了锁的线程)释放了锁，则该释放操作唤醒阻塞在同步队列中的线程，使其重新尝试对监视器的获取。 "},"content/JavaConcurrency/ReentrantLock.html":{"url":"content/JavaConcurrency/ReentrantLock.html","title":"Lock","keywords":"","body":"Lock 几个常见的锁实现 ReentrantLock:表示重入锁，它是唯一一个实现了 Lock 接口的类。重入锁指的是线程在获得锁之后，再次获取该锁不需要阻塞，而是直接关联一次计数器增加重入次数 ReentrantReadWriteLock:重入读写锁，它实现了 ReadWriteLock 接口，在这个类中维护了两个锁，ReadLock和WriteLock，他们都分别实现了 Lock 接口。读写锁是一种适合读多写少的场景下解决线程安全问题的工具，基本原则是: 读和读不互斥、读和写互斥、写和写互斥。 StampedLock: stampedLock 是 JDK8 引入的新的锁机制，可以简单认为是读写锁的一个改进版本，读写锁虽然通过分离读和写的功能使得读和读之间可以完全并发，但是读和写是有冲突的，如果大量的读线程存在，可能会引起写线程的饥饿。stampedLock 是一种乐观的读策略，使得乐观锁完全不会阻塞写线程 使用案例 //Reenrantlock Lock lock=new ReentrantLock(); lock.lock(); lock.unlock(); //ReentrantReadWriteLock ReentrantReadWriteLock rwl=new ReentrantReadWriteLock(); Lock read=rwl.readLock(); Lock write=rwl.writeLock(); ReentrantLock的实现原理 AQS AQS，全称 AbstractQueuedSynchronizer，它是一个同步工具也是 Lock 用来实现线程同步的核心组件。 AQS内部维护属性volatile int state表示资源的可用状态 AQS定义两种资源共享方式。Exclusive-独占，Share-共享 AQS定义两种队列。同步等待队列，条件等待队列 同步等待队列 同步等待队列是一个 FIFO 的双向链表。当线程争抢锁失败后会封装成 Node 加入到队列中，当获取锁的线程释放锁以 后，会从队列中唤醒一个阻塞的节点(线程)。 条件等待队列 条件等待队列使某个或者某些线程一起等待某个条件(Condition)，只有当该条件具备时，这些等待线程才会被唤醒，从而重新争夺锁。 源码分析 锁的获取流程 时序图 ReentrantLock.lock()调用时序图 ReentrantLock.lock() 这个是reentrantLock获取锁的入口，Sync有两个具体的实现NofairSync和FailSync。 public void lock() { sync.lock(); } NofairSync.lock() CAS 成功，就表示成功获得了锁。CAS 失败，调用 acquire(1)走锁竞争 final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } AQS.accquire() public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 通过 tryAcquire 尝试获取独占锁，如果成功返回 true，失败返回 false。 如果 tryAcquire 失败，则会通过 addWaiter 方法将当前线程封装成 Node 添加到 AQS 队列尾部。 acquireQueued，将 Node 作为参数，通过自旋去尝试获取锁。 NonfairSync.tryAcquire protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } ReentrantLock.nofairTryAcquire 获取当前线程，判断当前的锁的状态。如果 state=0 表示当前是无锁状态，通过 cas 更新 state 状态的值 。当前线程是属于重入，则增加重入次数 final boolean nonfairTryAcquire(int acquires) { //获取当前执行的线程 final Thread current = Thread.currentThread(); int c = getState();//获得 state 的值 if (c == 0) {//表示无锁状态 //cas替换state的值，cas 成功表示获取锁成功 if (compareAndSetState(0, acquires)) { //保存当前获得锁的线程,下次再来的时候不要再尝试竞争锁 setExclusiveOwnerThread(current); return true; } }else if (current == getExclusiveOwnerThread()) { //如果同一个线程来获得锁，直接增加重入次数 int nextc = c + acquires; if (nextc AQS.addWaiter 当 tryAcquire 方法获取锁失败以后，则会先调用addWaiter将当前线程封装成Node。传递Node.EXCLUSIVE，表示独占状态。当前链表中的 tail 节点是否为空，如果不为空，则通过 cas 操作把当前线程的node 添加到 AQS 队列。如果为空或者 cas 失败，调用 enq 将节点添加到 AQS 队列 private Node addWaiter(Node mode) { //把当前线程封装为 Node Node node = new Node(Thread.currentThread(), mode); //tail 是 AQS 中表示同步队列队尾的属性，默认是 null Node pred = tail; if (pred != null) {//tail 不为空的情况下，说明队列中存在节点 node.prev = pred;//把当前线程的 Node 的 prev 指向 tail //通过 cas 把 node加入到 AQS 队列，也就是设置为 tail指向当前 node if (compareAndSetTail(pred, node)) { //设置成功以后，把原 tail 节点的next指向当前 node pred.next = node; return node; } } enq(node);//tail=null,把 node 添加到同步队列 return node; } //enq 就是通过自旋操作把当前节点加入到队列中 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 图解分析 假设 3 个线程来争抢锁，那么截止到 enq 方法运行结束之后，或者调用 addwaiter 方法结束后，AQS 中的链表结构图 AQS.acquireQueued 通过 addWaiter 方法把线程添加到链表后，会接着把 Node 作为参数传递给 acquireQueued 方法，去竞争锁 获取当前节点的 prev 节点.如果 prev 节点为 head 节点，那么它就有资格去争抢锁，调用 tryAcquire 抢占锁. 如果获得锁失败，则根据 waitStatus 决定是否需要挂起线程 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor();//获取当前节点的 prev 节点 if (p == head && tryAcquire(arg)) { //如果是 head 节点，说明有资格去争抢锁 setHead(node); //获得锁的节点设置为 head p.next = null; //把原 head 节点从链表中移除 failed = false; return interrupted; } //ThreadA 可能还没释放锁，使得 ThreadB 在执行tryAcquire时会返回false if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) interrupted = true; //返回当前线程在等待过程中有没有中断过。 } } finally { if (failed) cancelAcquire(node); } } shouldParkAfterFailedAcquire 这个方法的主要作用是，通过Node的状态来判断，竞争锁失败以后是否应该被挂起。如果pred 节点状态为 SIGNAL，那就表示可以放心挂起当前线程。通过循环扫描链表把 CANCELLED 状态的节点移除。修改 pred 节点的状态为 SIGNAL，返回 false。 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus;//前置节点的waitStatus if (ws == Node.SIGNAL) return true;//返回 true，意味着可以直接放心的挂起了 if (ws > 0) {//ws大于0，意味着prev节点取消了排队，直接移除这个节点 do { node.prev = pred = pred.prev; //相当于: pred=pred.prev; node.prev=pred; } while (pred.waitStatus > 0); //从列表中移除 CANCELLED 的节点 pred.next = node; } else {//利用 cas 设置 prev 节点的状态为 SIGNAL(-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } parkAndCheckInterrupt LockSupport.park 挂起当前线程 Thread.interrupted，返回当前线程是否被其他线程触发过中断请求。如果返回 true，意味着在 acquire 方法中会执行selfInterrupt() private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 图解分析 锁的释放流程 ReentrantLock.unlock 在 unlock 中，会调用 release 方法来释放锁 public final boolean release(int arg) { if (tryRelease(arg)) { //释放锁成功 Node h = head; //得到 aqs 中 head 节点 //如果 head 节点不为空并且状态!=0.调用唤醒后续节点 if (h != null && h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } ReentrantLock.tryRelease 这个方法可以认为是一个设置锁状态的操作，通过将 state 状态减掉传入的参数值 (参数是 1)，如果结果状态为 0，就将排它锁的 Owner 设置为 null，以使得其它的线程有机会进行执行。 protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } unparkSuccessor private void unparkSuccessor(Node node) { int ws = node.waitStatus;//获得 head 节点的状态 if (ws 0 表示 cancelled 状态. 通过 //从尾部节点开始扫描，找到距离 head 最近的一个 if (s == null || s.waitStatus > 0) { waitStatus 挂起的线程继续执行 通过 ReentrantLock.unlock，原本挂起的线程被唤醒以后继续执行。原来被挂起的线程是在 acquireQueued 方法中，所以被唤醒以后继续从这个方法开始执行。 设置新的头节点，新 head 节点的 prev=null。把原 head 节点的 next 节点指向为 null。 图解分析 通过锁的释放，原本的结构就发生了一些变化。head 节点的 waitStatus 变成了 0，ThreadB 被唤醒。 设置新 head 节点的 prev=null，设置原 head 节点的 next 节点为 null。 公平锁和非公平锁 FairSync.tryAcquire protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 这个方法与 nonfairTryAcquire(int acquires)比较，不同的地方在于判断条件多了hasQueuedPredecessors()方法，也就是加入了同步队列中当前节点是否有前驱节点]的判断，如果该方法返回 true，则表示有线程比当前线程更早地请求获取锁， 因此需要等待前驱线程获取并释放锁之后才能继续获取锁。 "},"content/JavaConcurrency/Condition.html":{"url":"content/JavaConcurrency/Condition.html","title":"并发工具","keywords":"","body":"Condition Condition 基本使用 ReentrantLock lock = new ReentrantLock(); Condition condition = lock.newCondition(); condition.await(); condition.signal(); Condition 源码分析 调用 Condition，需要获得 Lock 锁，意味着会存在一个 AQS 同步队列。假如两个线程同时运行的话，那么 AQS 的队列可能是下面这种情况。 condition.await 调用 Condition 的 await()方法(或者以 await 开头的方法)，会使当前线程进入等待队列并释 放锁，同时线程状态变为等待状态。当从 await()方法返回时，当前线程一定获取了 Condition 相关联的锁。 public final void await() throws InterruptedException { if (Thread.interrupted()) //表示await允许被中断 throw new InterruptedException(); //创建一个新的节点，节点状态为 condition，采用的数据结构为单向链表 Node node = addConditionWaiter(); //释放当前的锁，得到锁的状态，并唤醒AQS队列中的一个线程 int savedState = fullyRelease(node); int interruptMode = 0; //如果当前节点没有在同步队列上，即还没有被 signal，则将当前线程阻塞 while (!isOnSyncQueue(node)) { //判断这个节点是否在 AQS 队列上，第一次判断的是 false，因为前面释放 //锁了 LockSupport.park(this); //通过 park 挂起当前线程 if((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 当这个线程醒来,会尝试拿锁,acquireQueued返回false 就是拿到锁了 if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 如果线程被中断了,需要抛出异常.或者什么都不做 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); addConditionWaiter 这个方法的主要作用是把当前线程封装成 Node，添加到等待队列。这里的队列不再是双向链表，而是单向链表。 private Node addConditionWaiter() { Node t = lastWaiter; if (t != null && t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } //构建一个Node，waitStatus=CONDITION。 这里的链表是一个单向的 Node node = new Node(Thread.currentThread(), Node.CONDITION) if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } 执行完 addConditionWaiter 这个方法之后，就会产生一个这样的 condition 队列。 fullyRelease fullRelease，就是如果当前锁存在多次重入，那么在这个方法中只需要释放一次就会把所有的重入次数归零。 final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); //获得重入的次数 if (release(savedState)) {//释放锁并且唤醒下一个同步队列中的线程 failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } 此时，同步队列会触发锁的释放和重新竞争。ThreadB 获得了锁。 isOnSyncQueue 判断当前节点是否在同步队列中，返回 false 表示不在，返回 true 表示在。如果不在 AQS 同步队列，说明当前节点没有唤醒去争抢同步锁，所以需要把当前线程阻塞起来，直到其他的线程调用 signal 唤醒。 如果 ThreadA 的 waitStatus 的状态为 CONDITION，说明它存在于 condition 队列中，不在 AQS 队列。因为 AQS 队列的状态一定不可能有 CONDITION 如果 node.prev 为空，说明也不存在于 AQS 队列，原因是 prev=null 在 AQS 队列中只有一种可能性，就是它是 head 节点，head 节点意味着它是获得锁的节点。 如果 node.next 不等于空，说明一定存在于 AQS 队列中，因为只有 AQS 队列才会存在next 和 prev 的关系 findNodeFromTail，表示从 tail 节点往前扫描 AQS 队列，一旦发现 AQS 队列的节点和当前节点相等，说明节点一定存在于 AQS 队列中 final boolean isOnSyncQueue(Node node) { if (node.waitStatus == Node.CONDITION || node.prev== null) return false; if (node.next != null) // If has successor,it mustbe on queue return true; return findNodeFromTail(node); } Condition.signal await 方法会阻塞 ThreadA，然后 ThreadB 抢占到了锁获得了执行权限，这个时候在 ThreadB 中调用了 Condition 的 signal()方法，将会唤醒在等待队列中节点。 public final void signal() { //先判断当前线程是否获得了锁，这个判断比较简单，直接用获得锁的线程和当前线程相比即可 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; // 拿到 Condition 队列上第一个节点 if (first != null) doSignal(first); } private void doSignal(Node first) { do { //从 Condition 队列中删除 first 节点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 将 next 节点设置成 null first.nextWaiter = null; } while(!transferForSignal(first&&(first =firstWaiter) !=null); } transferForSignal 该方法先是 CAS 修改了节点状态，如果成功，将这个节点放到 AQS 队列中，然后唤醒 这个节点上的线程。此时，那个节点就会在 await 方法中苏醒。 final boolean transferForSignal(Node node) { //更新节点的状态为0如果更新失败，只有一种可能就是节点被 CANCELLED 了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //调用enq，把当前节点添加到AQS队列。并且返回返回按当前节点 Node p = enq(node); int ws = p.waitStatus; // 如果上一个节点的状态被取消了, 或设置上一个节点的状态为SIGNAL失败了 if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); // 唤醒节点上的线程. //如果node的prev节点已经是signal状态，那么被阻塞线程唤醒工作由 AQS 队 //列来完成 return true; CountDownLatch CountDownLatch基本使用 CountDownLatch countDownLatch = new CountDownLatch(3); //countDown() 方法每次调用都会将 state 减 1，直到 state 的值为 0 countDownLatch.countDown(); //await 是一个阻 塞方法，当 state 减为 0 的时候，await 方法才会返回 countDownLatch.await(); CountDownLatch源码分析 countDownLatch.await() public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) doAcquireSharedInterruptibly private void doAcquireSharedInterruptibly(int arg)throws InterruptedException { final Node node = addWaiter(Node.SHARED); //创建一个共享模式的节点添加到队列中 boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg);//就判断尝试获取锁 if (r >= 0) {//r>=0表示获取到了执行权限，这个时候因为state!=0，所以不会执行这段代码 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } //阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &&parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } 假如这个时候有 3 个线程调用了 await 方法，由于这个时候 state 的值还不为 0，所以这三个线程都会加入到 AQS 队列中。并且三个线程都处于阻塞状态。 CountDownLatch.countDown public void countDown() { sync.releaseShared(1); } public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } //用自旋的方式减1 protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; } } AQS. doReleaseShared 共享锁的释放和独占锁的释放有一定的差别。前面唤醒锁的逻辑和独占锁是一样，先判断头结点是不是 SIGNAL 状态，如果是，则修改为 0，并且唤醒头结点的下一个节点。 标识为 PROPAGATE状态的节点，是共享锁模式下的节点状态，处于这个状态下的节点，会对线程的唤醒进行传播。 private void doReleaseShared() { for (;;) { Node h = head; if (h != null && h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL){ if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } // 这个 CAS 失败的场景是:执行到这里的时候，刚好有一个节点入队，入队会将这个 ws 设置为 -1 else if (ws == 0 && !compareAndSetWaitStatus(h,0,Node.PROPAGATE)) continue; // loop on failed CAS } // 如果到这里的时候，前面唤醒的线程已经占领了 head，那么再 循环 // 通过检查头节点是否改变了，如果改变了就继续循环 if (h == head) // loop if head changed break; } } h == head说明头节点还没有被刚刚用 unparkSuccessor 唤醒的线程(这里可以理解为 ThreadB)占有，此时 break 退出循环。 h != head说明头节点被刚刚唤醒的线程(这里可以理解为 ThreadB)占有，那么这里重新进入下一轮循环，唤醒下一个节点。我们知道，等到 ThreadB 被唤醒后，其实是会主动唤醒 ThreadC。 唤醒之后 一旦线程被唤醒，代码又会继续回到 doAcquireSharedInterruptibly 中来执行。如果当前 state 满足=0 的条件，则会执行 setHeadAndPropagate 方法。 private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); if (propagate > 0 || h == null || h.waitStatus PROPAGATE状态存在的意义 在setHeadAndPropagate中我们可以看到如下的一段代码: if (propagate > 0 || h == null || h.waitStatus 为什么不只是用propagate > 0来判断呢？我们知道目前AQS代码中的Node.PROPAGATE状态就是为了此处可以读取到h.waitStatus 看一下下面的bug import java.util.concurrent.Semaphore; public class TestSemaphore { private static Semaphore sem = new Semaphore(0); private static class Thread1 extends Thread { @Override public void run() { sem.acquireUninterruptibly(); } } private static class Thread2 extends Thread { @Override public void run() { sem.release(); } } public static void main(String[] args) throws InterruptedException { for (int i = 0; i 让我们来分析一下上面的程序： 上面的程序循环中做的事情就是放出4个线程，其中2个线程用于获取信号量，另外2个用于释放信号量。每次循环主线程会等待所有子线程执行完毕。出现bug也就是线程hang住的问题就在于两个获取信号量的线程有一个会没办法被唤醒，队列就死掉了。 在AQS的共享锁中，一个被park的线程，不考虑线程中断和前驱节点取消的情况，有两种情况可以被unpark：一种是其他线程释放信号量，调用unparkSuccessor；另一种是其他线程获取共享锁时通过传播机制来唤醒后继节点。 我们假设某次循环中队列里排队的节点为情况为：head -> t1的node -> t2的node(也就是tail) 信号量释放的顺序为t3先释放，t4后释放: 时刻1: t3调用releaseShared，调用了unparkSuccessor(h)，head的等待状态从-1变为0 时刻2: t1由于t3释放了信号量，被t3唤醒，调用Semaphore.NonfairSync的tryAcquireShared，返回值为0 时刻3: t4调用releaseShared,读到此时h.waitStatus为0(此时读到的head和时刻1中为同一个head)，不满足条件,因此不会调用unparkSuccessor(h)。 时刻4: t1获取信号量成功，调用setHeadAndPropagate时，因为不满足propagate > 0（时刻2的返回值也就是propagate==0）,从而不会唤醒后继节点 这就好比是一个精巧的多米诺骨牌最终由于设计的失误导致动力无法传递下去，至此AQS中的同步队列宣告死亡。 那么引入PROPAGATE是怎么解决问题的呢？引入之后，调用releaseShared方法不再简单粗暴地直接unparkSuccessor,而是将传播行为抽了一个doReleaseShared方法出来。再看上面的那种情况: 时刻1：t3调用releaseShared -> doReleaseShared -> unparkSuccessor，完了之后head的等待状态为0 时刻2：t1由于t3释放了信号量，被t3唤醒，调用Semaphore.NonfairSync的tryAcquireShared，返回值为0 时刻3：t4调用releaseShared，读到此时h.waitStatus为0(此时读到的head和时刻1中为同一个head)，将等待状态置为PROPAGATE 时刻4：t1获取信号量成功，调用setHeadAndPropagate时，可以读到h.waitStatus ，从而可以接下来调用doReleaseShared唤醒t2 也就是说，上面会产生线程hang住bug的case在引入PROPAGATE后可以被规避掉。在PROPAGATE引入之前，之所以可能会出现线程hang住的情况，就是在于releaseShared有竞争的情况下，可能会有队列中处于等待状态的节点因为第一个线程完成释放唤醒，第二个线程获取到锁，但还没设置好head，又有新线程释放锁，但是读到老的head状态为0导致释放但不唤醒，最终后一个等待线程既没有被释放线程唤醒，也没有被持锁线程唤醒。所以，仅仅靠tryAcquireShared的返回值来决定是否要将唤醒传递下去是不充分的。 "},"content/JavaConcurrency/threadpool.html":{"url":"content/JavaConcurrency/threadpool.html","title":"线程池","keywords":"","body":"Java中提供的线程池 ThreadPoolExecutor 默认线程池 ScheduledThreadPoolExecutor 定时线程池 ThreadpoolExecutor public ThreadPoolExecutor(int corePoolSize, //核心线程数量 int maximumPoolSize, //最大线程数 long keepAliveTime, //超时时间,超出核心线程数量以外的线程空余存活时间 TimeUnit unit, //存活时间单位 BlockingQueue workQueue,//保存执行任务的队列 ThreadFactory threadFactory,//创建新线程使用的工厂 RejectedExecutionHandler handler //当任务无法执行的时候的处理方式 newFixedThreadPool public static ExecutorService newFixedThreadPool(int nThreads){ return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); } 核心线程数和最大线程数都是指定值，当线程数超过核心线程数后，任务都会被放到阻塞队列中。另外 keepAliveTime 为 0，也就是超出核心线程数量以外的线程空余存活时间。阻塞队列是 LinkedBlockingQueue，使用的是默认容量 Integer.MAX_VALUE， 相当于没有上限。 newCachedThreadPool public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,new SynchronousQueue()); } 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。并且没有核心线程，非核心线程数无上限，但是每个空闲的时间只有 60 秒，超过后就会被回收。 newSingleThreadExecuto 它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 newScheduledThreadPool 创建一个可以指定线程的数量的线程池，但是这个线程池还带有延迟和周期性执行任务的功能，类似定时器。 执行流程 线程池状态 RUNNING：能够接收新任务，以及对已添加的任务进行处理。初始化状态是RUNNING。 SHUTDOWN：不接收新任务，但能处理已添加的任务。调用线程池的shutdown()接口时，线程池由RUNNING -> SHUTDOWN。 STOP：不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。调用线程池的shutdownNow()。 TIDYING：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING 状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在 ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。由STOP -> TIDYING。 TERMINATED：线程池彻底终止，就变成TERMINATED状态。线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING - > TERMINATED。 原理分析 execute() public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); //1.当前池中线程比核心数少，新建一个线程执行任务 if (workerCountOf(c) ctl ctl 是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了Integer类型来保存，高3位保存runState，低29位保存 workerCount。 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING,0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 addWorker() addWorker方法的主要工作是在线程池中创建一个新的线程并执行，用循环 CAS 操作来将线程数加 1。 firstTask参数用于指定新增的线程执行的第一个任务，core参数为true表示判断corePoolSize，false表示判断maximumPoolSize。 private boolean addWorker(Runnable firstTask, boolean core) { retry: //goto语句,避免死循环 for (;;) { int c = ctl.get(); int rs = runStateOf(c); if (rs >= SHUTDOWN && ! (rs == SHUTDOWN && firstTask == null &&! workQueue.isEmpty())) return false; for (;;) { //自旋 int wc = workerCountOf(c);//获得Worker工作线程数 //如果工作线程数大于默认容量大小或者大于核心线程数大小，则直接返回 //false 表示不能再添加 worker。 if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize)) return false; //通过cas来增加工作线程数， 如果 cas 失败，则直接重试 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl //再次获取ctl的值 if (runStateOf(c) != rs) //如果不相等，说明线程的状态发生变化 continue retry; } } //上面对worker数量做原子+1操作,下面才是正式构建一个worker boolean workerStarted = false; //工作线程是否启动的标识 boolean workerAdded = false; //工作线程是否已经添加成功的标识 Worker w = null; try { w = new Worker(firstTask); //构建一个Worker final Thread t = w.thread; //从 worker 对象中取出线程 if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); //这里有个重入锁，避免并发问题 try { int rs = runStateOf(ctl.get()); //只有当前线程池是正在运行状态，[或是 SHUTDOWN 且 firstTask //为空]，才能添加到 workers 集合中 if (rs largestPoolSize) largestPoolSize = s; //更新线程池出现过的最大线程数 workerAdded = true;//表示工作线程创建成功了 } } finally { mainLock.unlock(); //释放锁 } if (workerAdded) { t.start();//如果worker添加成功，启动线程 workerStarted = true; } } } finally { if (! workerStarted) //如果添加失败，递减实际工作线程数，从workers集合中移除该worker addWorkerFailed(w); } return workerStarted;//返回结果 } Worker()类说明 addWorker 方法只是构造了一个 Worker，并且把 firstTask 封装到 worker 中。每个worker,都是一个线程，同时里面包含了一个firstTask，即初始化时要被首先执行的任务。最终执行任务的是 runWorker()方法。 private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ private static final long serialVersionUID = 6138294804551838833L; //真正执行task的线程，由 ThreadFactury 创建 final Thread thread; Runnable firstTask; //这就是需要执行的 task volatile long completedTasks; //完成的任务数，用于线程池统计 Worker(Runnable firstTask) { setState(-1); //初始状态 -1,防止在调用 runWorker()前中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } public void run() { runWorker(this);//执行task任务 } } runWorker() 线程池中执行任务的真正处理逻辑，主要做下面几件事。 如果 task 不为空,则开始执行 task。如果 task 为空，则通过 getTask()再去取任务，如果不为空,则执行该任务。执行完毕后,通过 while 循环继续 getTask()取任务。如果 getTask()取到的任务依然是空。那么整个runWorker()方法执行完毕。runWorker 方法执行完之后，也就是 Worker 中的 run 方法执行完，由 JVM 自动回收。 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // 允许中断 boolean completedAbruptly = true; try { //实现了线程复用，如果 task 为空，则通过 getTask 来获取任务 while (task != null || (task = getTask()) != null) { w.lock(); //上锁，为了在shutdown()时不终止正在运行的 worker //对于 stop 状态以上是要中断线程的 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task);//默认没有实现，可以重写 Throwable thrown = null; try { task.run(); //执行任务中的run方法 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); //默认而也是没有实现 } } finally { //置空任务(这样下次循环开始时,task 依然为 null,需要再通过 //getTask()取) + 记录该 Worker 完成任务数量 + 解锁 task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { //1.将入参 worker 从数组 workers 里删除掉; //2.根据allowCoreThreadTimeOut来决定是否补充新的Worker processWorkerExit(w, completedAbruptly); } } getTask() worker 线程会从阻塞队列中获取需要执行的任务。在线程从工作队列 poll 任务时，加上了超时限制，如果线程在 keepAliveTime 的时间内 poll 不到任务，销毁线程。 private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) {//自旋 int c = ctl.get(); int rs = runStateOf(c); if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())){ decrementWorkerCount(); return null;//返回 null，则当前 worker 线程会退出 } int wc = workerCountOf(c); // timed变量用于判断是否需要进行超时控制。 //超过核心线程数量的线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut ||wc > corePoolSize; //timed && timedOut 如果为 true，表示当前操作需要进行超时控制， //并且上次从阻塞队列中 获取任务发生了超时 if ((wc > maximumPoolSize || (timed && timedOut)) && (wc > 1 ||workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { //根据 timed 来判断，如果为 true，则通过阻塞队列 poll 方法进行超 //时控制，如果在 keepaliveTime 时间内没有获取到任务，则返回 //null.否则通过 take 方法阻塞式获取队列中的任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null)//如果拿到的任务不为空，则直接返回给worker进行处理 return r; //如果 r==null，说明已经超时了，设置 timedOut=true，在下次自旋 //的时候进行回收 timedOut = true; } catch (InterruptedException retry) { // 如果获取任务时当前线程发生了中断，则设置 timedOut 为false 并 //返回循环重试 timedOut = false; } } } 线程池使用 线程池大小 CPU 密集型，主要是执行计算任务，响应时间很快，cpu 一直在运行，那线程池的最大线程数可以配置为 cpu 核心数+1 如果是 IO 密集型，主要是进行 IO 操作，cpu 出于空闲状态， 线程池设定最佳线程数目 = (线程池设定的线程等待时间+线程 CPU 时间)/ 线程 CPU 时间 )* CPU 数目 线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程 prestartAllCoreThreads()：初始化所有核心线程 线程池关闭 ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是 shutdown()和shutdownNow()。shutdown()不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。shutdownNow()立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 线程池容量的动态调整 ThreadPoolExecutor 提供了动态调整线程池容量大小的方法setCorePoolSize()和 setMaximumPoolSize() 任务缓存队列 workQueue 的类型为 BlockingQueue，通常可以取下面三种类型: ArrayBlockingQueue:基于数组的先进先出队列，此队列创建时必须指定大小; LinkedBlockingQueue:基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为 Integer.MAX_VALUE; SynchronousQueue:这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 线程池监控 线程池提供了相应的扩展方法，通过重写线程池的 beforeExecute、afterExecute 和 shutdown 等方式就可以实现对线程的监控. public long getTaskCount() //线程池已执行与未执行的任务总数 public long getCompletedTaskCount() //已完成的任务数 public int getPoolSize() //线程池当前的线程数 public int getActiveCount() //线程池中正在执行任务的线程数量 submit执行 线程池的执行任务有两种方法，一种是 submit、一种是 execute。区别： execute 只可以接收一个 Runnable 的参数 。submit 可以接收 Runable 和 Callable 这两种类型的参数 execute 如果出现异常会抛出。submit 方法调用不会抛异常，除非调用 Future.get execute 没有返回值。submit 传入一个 Callable，可以得到一个 Future 的返回值 Future 表示一个任务的生命周期，并提供了相应的方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。 public interface Future { //取消当前任务 boolean cancel(boolean mayInterruptIfRunning); // 当前的 Future 是否被取消，返回 true 表示已取消 boolean isCancelled(); // 当前 Future 是否已结束。包括运行完成、抛出异常以及取消，都表示当前 //Future 已结束 boolean isDone(); // 获取 Future 的结果值。如果当前 Future 还没有结束，那么当前线程就等 //待，直到 Future 运行结束，那么会唤醒等待结果值的线程的。 V get() throws InterruptedException, ExecutionException; // 获取 Future 的结果值。与 get()相比较多了允许设置超时时间 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } 定时线程池 ScheduledThreadPoolExecutor，它用来处理延时任务或定时任务。 将任务封装成SchduledFutureTask，包含任务开始的时间、任务的序号 任务执行的时间间隔。 有三种提交任务的方式: schedule。该方法指任务在指定延迟时间到达后触发，只会执行一次 scheduledAtFixedRate，执行周期固定，不管任务执行时间 scheduledWithFixedDelay，固定延迟， DelayedWorkQueue ScheduledThreadPoolExecutor自己实现阻塞的工作队列， DelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和 PriorityQueue，无界队列。 DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面。保证每次出队的任务都是当前队列中执行时间最靠前的。由于它是基于堆结构的队列，堆结构在执行插入和删除操作时的最坏时间复杂度是logN。 执行流程 线程从DeayQueue中获取已到期的SchduledFutureTask。 执行SchduledFutureTask 修改SchduledFutureTask的time变量为下次将要执行的时间 将修改后的SchduledFutureTask放回DeayQueue。 "},"content/JavaConcurrency/ThreadLocal.html":{"url":"content/JavaConcurrency/ThreadLocal.html","title":"ThreadLocal","keywords":"","body":"数据结构 Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，也就是说每个线程有一个自己的ThreadLocalMap。 ThreadLocalMap有自己的独立实现，可以简单地将它的key视作ThreadLocal，value为代码中放入的值（实际上key并不是ThreadLocal本身，而是它的一个弱引用）。 每个线程在往ThreadLocal里放值的时候，都会往自己的ThreadLocalMap里存，读也是以ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。 注意Entry， 它的key是ThreadLocal k ，继承自WeakReference， 也就是我们常说的弱引用类型。 Set方法 通过hash计算后的槽位对应的Entry数据为空，直接将数据放到该槽位即可。 槽位数据不为空，key值与当前ThreadLocal通过hash计算获取的key值一致，直接更新 槽位数据不为空，往后遍历过程中，遇到key过期的Entry，进行探测式数据清理工作。经过一轮探测式清理后，key过期的数据会被清理掉，没过期的数据经过rehash重定位后所处的桶位置理论上更接近i= key.hashCode & (tab.len - 1)的位置 扩容 扩容后的tab的大小为oldLen * 2，然后遍历老的散列表，重新计算hash位置，然后放到新的tab数组中，如果出现hash冲突则往后寻找最近的entry为null的槽位，遍历完成之后，oldTab中所有的entry数据都已经放入到新的tab中了 Get方法 子线程获取 使用ThreadLocal的时候，在异步场景下是无法给子线程共享父线程中创建的线程副本数据的。为了解决这个问题，JDK中还有一个InheritableThreadLocal类。 实现原理是子线程是通过在父线程中通过调用new Thread()方法来创建子线程，Thread#init方法在Thread的构造方法中被调用。在init方法中拷贝父线程数据到子线程中。 "},"content/JavaConcurrency/阻塞队列和原子操作.html":{"url":"content/JavaConcurrency/阻塞队列和原子操作.html","title":"原子操作和阻塞队列","keywords":"","body":"阻塞队列 ArrayBlockingQueue add add 方法可以看到，add 方法最终还是调用 offer 方法来添加数据。 判断添加的数据是否为空，添加重入锁，判断队列长度，如果队列长度等于数组长度，表示满了 直接返回 false，否则，直接调用 enqueue 将元素添加到队列中 enqueue，这个是最核心的逻辑，方法内部通过 putIndex 索引直接将 元素添加到数组 items。putIndex 为等于数组长度的时候重新设置为 0。因为 ArrayBlockingQueue 是一个 FIFO 的队列，队列添加元素时，是从队尾获取 putIndex 来存储元素，当 putIndex 等于数组长度时，下次就需要从数组头部开始添加了 put put 方法和 add 方法功能一样，差异是 put 方法如果队列满了，会阻塞 take take 方法是一种阻塞获取队列中元素的方法 它的实现原理很简单，有就删除没有就阻塞，注意这个阻 塞是可以中断的，如果队列没有数据那么就加入 notEmpty 条件队列等待(有数据就直接取走，方法结束)，如果有新的 put 线程添加了数据，那么 put 操作将会唤醒 take 线程。 原子操作类 原子更新基本类型 AtomicBoolean、AtomicInteger、AtomicLong 原子更新数组 AtomicIntegerArray 、 AtomicLongArray 、AtomicReferenceArray 原子更新引用 AtomicReference 、 AtomicReferenceFieldUpdater 、 AtomicMarkableReference(更新带有标记位的引用类型) 原子更新字段 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、 AtomicStampedReference AtomicInteger 原理分析 public final int getAndIncrement() { return unsafe.getAndAddInt(this,valueOffset, 1); } public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } valueOffset。通过 unsafe.objectFieldOffset() 获取当前 Value 这个变量在内存中的偏移量，后续会基于 这个偏移量从内存中得到 value 的值来和当前的值做比较， 实现乐观锁。 getAndAddInt。通过 do/while 循环，基于 CAS 乐观锁来做原子递增。实 际上前面的 valueOffset 的作用就是从主内存中获得当前 value 的值和预期值做一个比较，如果相等，对 value 做递增并结束循环 Java8优化 大量的线程同时并发修改一个AtomicInteger，可能有很多线程会不停的自旋，进入一个无限重复的循环中。 Java 8推出了一个新的类，LongAdder，他就是尝试使用分段CAS以及自动分段迁移的方式来大幅度提升多线程高并发执行CAS操作的性能！ 在LongAdder的底层实现中，首先有一个base值，刚开始多线程来不停的累加数值，都是对base进行累加的，比如刚开始累加成了base = 5。 接着如果发现并发更新的线程数量过多，就会开始施行分段CAS的机制，也就是内部会搞一个Cell数组，每个数组是一个数值分段。 这时，让大量的线程分别去对不同Cell内部的value值进行CAS累加操作，这样就把CAS计算压力分散到了不同的Cell分段数值中了！ 而且他内部实现了自动分段迁移的机制，也就是如果某个Cell的value执行CAS失败了，那么就会自动去找另外一个Cell分段内的value值进行CAS操作。 最后，如果你要从LongAdder中获取当前累加的总值，就会把base值和所有Cell分段数值加起来返回给你。 "},"content/JVM/内存区域.html":{"url":"content/JVM/内存区域.html","title":"内存区域","keywords":"","body":"JVM架构 运行时数据区 线程共享区域：JVM启动的时候，这块区域就开始分配空间。 线程私有区域：没有线程的时候，这块区域是不存在的。这块空间的生命周期特别短暂，不存在垃圾回收的问题。 方法区 类型信息：类型的全限定名、超类的全限定名、类型标志(该类是类类型还是接口类型)、类的访问描述符(public、private、default、abstract、final、static)。 类型的常量池：存放该类所用到的常量的有序集合，包括直接常量(如字符串、整数、浮点数的常量)和对其他类型、字段、方法的符号引用。常量池中每一个保存的常量都有一个索引，就像数组中的字段一样。因为 常量池中保存着所有类型使用到的类型、字段、方法的字符引用，所以它也是动态连接的主要对象(在 动态链接中起到核心作用)。 字段信息：字段修饰符(public、protect、private、default) 、字段的类型、字段名称 方法信息：方法修饰符、方法返回类型、方法名、方法参数个数、类型、顺序等、方法字节码、操作数栈和该方法在栈帧中的局部变量区大小。 类变量(静态变量)：指该类所有对象共享的变量，即使没有任何实例对象时，也可以访问的类变量。它们与类进行绑定。 指向类加载器的引用：每一个被JVM加载的类型，都保存这个类加载器的引用，类加载器动态链接时会用到。 指向class实例的引用：类加载的过程中，虚拟机会创建该类型的Class实例，方法区中必须保存对该对象的引用。通过 Class.forName(String className)来查找获得该实例的引用，然后创建该类的对象。 方法表：为了提高访问效率，JVM可能会对每个装载的非抽象类，都创建一个数组，数组的每个元素是实例可能调用的方法的直接引用，包括父类中继承过来的方法。这个表在抽象类或者接口中是没有的。 运行时常量池：用于存放编译器生成的各种字面常量和符号引用，这部分内容被类加载后进入方法区的运行时常量池中存放。 字面量：文本字符串，被声明为final的常量池、基本数据类型的值。 符号引用：类和结构的完全限定名、字段名称和描述符、方法名称和描述符。 -MetaspaceSize（指定初始空间大小） -MaxMetaspaceSize（元空间最大值） class文件常量池和运行时常量池 class文件常量池存储的是当class文件被java虚拟机加载进来后存放在方法区的一些字面量和符号引用，字面量包括字符串，基本类型的常量。 运行时常量池是当class文件被加载完成后，java虚拟机会将class文件常量池里的内容转移到运行时常量池里，运行时常量池也是每个类都有一个。在class文件常量池的符号引用有一部分是会被转变为直接引用的，比如说类的静态方法或私有方法，实例构造方法，父类方法，这是因为这些方法不能被重写其他版本，所以能在加载的时候就可以将符号引用转变为直接引用，而其他的一些方法是在这个方法被第一次调用的时候才会将符号引用转变为直接引用的。 运行时常量池相对于Class文件常量池的另外一个特征具有动态性，可以在运行期间将新的常量放入池中(典型的如String类的intern()方法)。 永久代和元空间 方法区在JDK 8中就是Metaspace，在JDK6或7中就是Perm Space 区别 存储位置不同，永久代物理是堆的一部分，和新生代，老年代地址是连续的，而元空间属于本地内存。由于永久代它的大小是比较小的，而元空间的大小是决定于内地内存的。 所以说永久代使用不当，比较容易出现OOM异常。而元空间一般不会。 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中。 永久代替换为元空间 字符串存在永久代中，容易出现性能问题和永久代内存溢出。字符串常量池存放到堆中。 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。 堆 Java堆中，主要是用来存储对象和数组的。堆被划分为老年代和年轻代。 -Xms（最小值）,-Xmx（最大值），-Xmn（年轻代） 内存分配原则 优先在 Eden 分配,如果 Eden 空间不足虚拟机则会进行一次 MinorGC 大对象直接接入老年代 长期存活的对象进入老年代，每个对象都有一个【age】，当age到达设定的年龄的时候就会进入老年代，默认是15岁。 对象创建 内存分配方式 分配方法 说明 收集器 指针碰撞 内存地址连续 Serial 和 ParNew 空闲列表 内存地址不连续 CMS 收集器和 Mark-Sweep 内存分配安全 CAS，比较和交换(Compare And Swap)：CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 TLAB，本地线程分配缓冲(Thread Local Allocation Buffer即TLAB)：为每一个线程预先分配一块内存，JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配。 对象内存布局 对象头 用于存储对象自身的运行数据，如GC分代年龄，锁状态标志，线程持有的锁等 另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪一个类的实例 实例数据 存储的是对象真正有效的信息。 对齐填充 这部分并不是必须要存在的，没有特别的含义，在jvm中对象的大小必须是8字节的整数倍，而对象头也 是8字节的倍数，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 对象访问定位 句柄：稳定，对象被移动只要修改句柄中的地址 直接指针：访问速度快，节省了一次指针定位的开销 程序计数器 程序计数器占用的内存空间很小，由于Java虚拟机的多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，在任意时刻，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能够恢复到正确的执行位置，每条线程需要有一个独立的程序计数器(线程私有)。 如果线程正在执行Java方法，则计数器记录的是正在执行的虚拟机字节码指令的地址； 如果正在执行的是Native方法，则这个计数器为空。 本地方法栈 如果当前线程执行的方法是Native类型的（使用native关键字修饰的方法，主要指的是c语言），这些方法就会在本地方法栈中执行。 虚拟机栈 虚拟机栈是一个线程执行的区域，保存着一个线程中方法的调用状态。 每一个被线程执行的方法，为该栈中的栈帧，即每个方法对应一个栈帧。 调用一个方法，就会向栈中压入一个栈帧；一个方法调用完成，就会把该栈帧从栈中弹出。 -Xss设置大小 栈帧 每个栈帧中包括局部变量表、操作数栈、指向运行时常量池的引用(动态链接)、方法返回地址。 局部变量表：方法中定义的局部变量以及方法的参数存放在这张表中 局部变量表中的变量不可直接使用，如需要使用的话，必须通过相关指令将其加载至操作数栈中作为操作数使用。 操作数栈：以压栈和出栈的方式存储操作数 动态链接；每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。 当一个方法开始执行后,只有两种方式可以退出，一种是遇到方法返回的字节码指令;一种是遇见异常，并且 这个异常没有在方法体内得到处理。 "},"content/JVM/内存分配和垃圾回收.html":{"url":"content/JVM/内存分配和垃圾回收.html","title":"内存分配和垃圾回收","keywords":"","body":"内存分配 对象优先在Eden区分配 大多数情况下，对象在新生代中 Eden 区分配。 当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC，剩余存活的对象会被挪到为空的那块survivor 区。GC期间虚拟机如果发现无法存入 Survior空间，这种情况会把存活的对象部分挪到老年代，部分可能还会放在Survivor区。下一次eden区满了后又会触发minor gc，把eden区和survivor去垃圾对象回收，把剩余存活的对象一次性挪动到另外一块为空的survivor区。 逃逸分析 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象(比如:字符串、数组)。JVM参数 - XX:PretenureSizeThreshold 可以设置大对象的大小，如果对象超过设置大小会直接进入老年代，不会进入年轻代，这个参数只在 Serial 和ParNew两个收集器下有效。 长期存活的对象进入老年代 对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1。对象 在 Survivor 中每熬过一次 MinorGC，年龄就增加1岁，当它的年龄增加到一定 程度(默认为15岁)，就会被晋升到老年代中。对象晋升到老年代的年龄阈 值，可以通过参数来-XX：MaxTenuringThreshold设置。 当前放对象的Survivor区域里(其中一块区域，放对象的那块s区)，一批对象的总大小大于这块Survivor区域内存大小的50%，那么此时大于等于这批对象年龄最大值的对象，就可以直接进入老年代了。 象动态年龄判断机制一般是在minor gc之后触发的。 空间分配担保 -XX:-HandlePromotionFailure设置是否允许，jdk1.8默认设置。 年轻代每次Minor Gc之前，JVM都会计算下老年代剩余可用空间是否小于年轻代里现有的所有对象大小之和(包括垃圾对象)。如果允许担保，就会看老年代的可用内存大小，是否大于之前每一次minor gc后进入老年代的对象的平均大小。如果小于，那么就会触发一次Full gc。如果大于则尝试进行一次Minor Gc。 垃圾回收 回收内存区域 堆内存。对象，数组。 方法区。废弃常量，无用的类。 废弃常量。不使用的字符串常量、不使用的符号引用。 无用的类。该类所有的实例都已经被回收。加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象在任何地方没有被引用，也无法通过反射访问该类的方法。 回收方式 Minor GC/Young GC：新生代的的垃圾收集。 Major GC/Full GC：一般会回收老年代，年轻代，方法区的垃圾。 system.gc()，老年代不够用，方法区不够用，当新生代的对象无法被老年代担保成功时。 判断对象被回收 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1。任何时候计数器为0的对象就是不可能再被使用的。 这个方法实现简单，效率高，其最主要的原因是它很难解决对象之间相互循环引用的问题。 可达性分析 这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点， 从这些节点开始向下搜索，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象。 能作为GC Root：虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等。 可达性分析中标记为不可达的对象，需进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize方法，对象将直接被回收。如果这个对象覆盖了finalize方法，对象要在finalize()中与引用链上的任何的一个对象建立关联可避免被回收。 对象引用 强引用。普通的变量引用。Object obj = new Object() 软引用。将对象用SoftReference软引用类型的对象包裹，正常情况不会被回收，但是GC做完后发现释放不出空间存放新的对象，则会把这些软引用的对象 回收掉。软引用可用来实现内存敏感的高速缓存。 弱引用。将对象用WeakReference软引用类型的对象包裹，描述非必须对象，GC会直接回收掉。 虚引用。提供PhanomReference来实现，目的是为了能在这个类被回收时得到一个通知。 垃圾收集算法 标记—清除 标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。标记清除后会产生大量不连续的碎片。标记和清除两个过程都比较耗时，效率不高。 复制算法 将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 标记—整理 标记过程与“标记-清除”算法一样，但后续步骤是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。 标记实现方案 把标记直接记录在对象头上，如Serial收集器 把标记记录在与对象相互独立的数据结构上，如G1、CMS使用了一种相当于堆内存的1/64大小的，称为BitMap的结构来记录标记信息 直接把标记信息记在引用对象的指针上，如ZGC 垃圾收集器 Serial收集器 它是一种单线程收集器，不仅仅意味着它只会使用一个CPU或者一条收集线程去完成垃圾收集工作，更重要的是其在进行垃圾收集的时候需要暂停其他所有的工作线程。 新生代采用复制算法，老年代采用标记-整理算法。 ParNew收集器 ParNew收集器就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为 (控制参数、收集算法、回收策略等等)和Serial收集器完全一样。默认的收集线程数跟cpu核数相同，当然也可以用参数(-XX:ParallelGCThreads)指定收集线程数。 Parallel Scavenge收集器 使用复制算法的收集器，又是并行的多线程收集器，看上去和ParNew一样，但是Parallel Scanvenge更关注系统的吞吐量 。 吞吐量=运行用户代码的时间/(运行用户代码的时间+垃圾收集时间)。若吞吐量越大，意味着垃圾收集的时间越短，则用户代码可以充分利用CPU资源，尽快完成程序 的运算任务。 -XX:MaxGCPauseMillis控制最大的垃圾收集停顿时间。 -XX:GCTimeRatio直接设置吞吐量的大小。 Parallel Old收集器 Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和\"标记-整理算法\"进行垃圾回收。吞吐量优先。 CMS收集器 CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。采用的是\"标记-清除算法\",整个过程分为4步。 初始标记。标记GC Roots关联到的对象，Stop The World，速度很快 并发标记 。进行GC Roots Tracing 并发预清理。此阶段标记从新生代晋升的对象、新分配到老年代的对象以及在并发阶段被修改了的对象。可以减少下一个stop-the-world 重新标记阶段的工作量 并发可中止预清理阶段。获得所期望的eden空间占用率。预清理阶段后，如果Eden 空间占用大于 CMSScheduleRemarkEdenSizeThreshold 设置的值, 会启动可中止预清理，直到占用率达到 CMSScheduleRemarkEdenPenetration 设置的值或扫描多长时间 重新标记 。为了修正并发标记期间因为用户程序继续运行而导致标记 产生变动的那一部分对象的标记记录。这个阶段依然需要扫描新生代 并发清除 。开启用户线程，同时GC线程开始对未标记的区域做清扫。 缺点 对CPU资源敏感。在并发阶段，会占用一部分线程导致应用程序变慢降低总吞吐量。默认回收线程数（处理器核心线程数+3）/4。 无法处理浮动垃圾。在并发清理阶段又产生垃圾，这种浮动垃圾只能等到下一次gc再清理。 回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 并发失败(concurrent mode failure)。CMS运行期间预留的内存无法满足程序分配新对象的需求，会导致一次并发失败。此时会暂停用户线程，用serial old垃圾收集器来回收。 相关参数 -XX:+UseConcMarkSweepGC:启用cms -XX:ConcGCThreads:并发的GC线程数 -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩整理(减少碎片) -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次，默认是0，代表每次FullGC后都会压缩一次 -XX:CMSInitiatingOccupancyFraction: 当老年代使用达到该比例时会触发FullGC(默认 是92，这是百分比) -XX:+CMSScavengeBeforeRemark:在CMS 重新标记前启动一次minor gc，目的在于减少老年代对年轻代的引用，降低CMS GC的标记阶段时的开销，一般CMS的GC耗时 80%都在 remark阶段。 G1收集器 G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。 回收算法主要用的是复制算法。 G1将Java堆划分为多个大小相等的独立区域(Region)。一般Region大小等于堆大小除以2048，可以用参数\"-XX:G1HeapRegionSize\"手动指定Region大小。 G1保留了年轻代和老年代的概念，但不再是物理隔阂了，它们都是(可以不连续)Region的集合。一个Region可能之前是年轻代，如果Region进行了垃圾回收，之后可能又会变成老年代，也就是 说Region的区域功能可能会动态变化。G1有专门分配大对象的Region叫Humongous区，而不是让大对象直接进入老年代的 Region中 初始标记(Initial Marking) ， 暂停用户线程，并记录下gc roots直接能引用的对象，并且修改TAMS的值 并发标记(Concurrent Marking) 最终标记(Final Marking) 筛选回收， 对各个Region的回收价值和成本进行排序（collecton set），根据用户所期望的GC停顿时间制定回收计划。可以用JVM参数 -XX:MaxGCPauseMillis指定 G1垃圾收集分类 YoungGC YoungGC并不是说现有的Eden区放满了就会马上触发，而且G1会计算下现在Eden区回收大概要多久时间，如果回收时间远远小于参数 -XX:MaxGCPauseMills 设定的值，那么增加年轻代 的region，继续给新对象存放，不会马上做Young GC，直到下一次Eden区放满，G1计算回收时 间接近参数 -XX:MaxGCPauseMills 设定的值，那么就会触发Young GC。 MixedGC 不是FullGC，老年代的堆占有率达到参数(-XX:InitiatingHeapOccupancyPercen)设定的值 则触发，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)以 及大对象区，正常情况G1的垃圾收集是先做MixedGC，主要使用复制算法，需要把各个region中 存活的对象拷贝到别的region里去，拷贝过程中如果发现没有足够的空region能够承载拷贝对象 就会触发一次Full GC Full GC 停止系统程序，然后采用单线程进行标记、清理和压缩整理，好空闲出来一批Region来供下一次MixedGC使用，这个过程是非常耗时的。 Remember Set 每个Region被分成了多个Card，在不同Region中的Card会相互引用。每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系。 G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。 SATB 全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记，即默认它们是存活的。 ZGC收集器 ZGC以低延迟为首要目标的一款垃圾收集器。它是基于动态Region内存布局，不设年龄分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的收集器。在JDK 11新加入，还在实验阶段，主要特点是：回收TB级内存（最大4T），停顿时间不超过10ms。 ZGC的Region可以具有如图所示的大、中、小三类容量。小型容量固定为2MB，用于放置小于256KB的小对象。中型容量固定为32MB，用于放置大于等于256KB但小于4MB的对象。大型容量不固定，可以动态变化，用于放置4MB或以上的大对象。 ZGC将Linux下46位中的高4位取出，用来存储4个标志位，剩余的42位可以支持4T的内存。 Finalizable：表示是否只能通过finalize()方法才能被访问到，其他不行； Remapped：表示是否进入了重分配集（即被移动过）； Marked1、Marked0：表示对象的三色标记状态（黑色，白色，灰色）； 收集流程 并发标记：遍历对象图做可达性分析的阶段，初始标记和最终标记也会出现短暂的停顿，整个标记阶段只会更新染色指针中的Marked 0、Marked 1标志位。 并发预备重分配：这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集（Relocation Set）。ZGC每次回收都会扫描所有的Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本。 并发重分配：把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（Forward Table），记录从旧对象到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”（Self-Healing）能力。 并发重映射：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用。合并到下一次垃圾收集循环中的并发标记阶段里去完成。 "},"content/JVM/类加载.html":{"url":"content/JVM/类加载.html","title":"类加载","keywords":"","body":"JVM程序执行流程 Class文件详解 魔数和版本号 所有的由Java编译器编译而成的class文件的前4个字节是0xCAFEBABE。 JVM会首先读取文件的前4个字节，判断该4个字节是否是“0xCAFEBABE”，如果是，则JVM会认为可以将此文件当作class文件来加载并使用。 常量池 包括常量池计数器和数据区 访问标志 用于表示某个类或者接口的访问权限及基础属性。如public、final、interface、abstract。 类索引、父类索引、接口索引 类索引用于确定这个类的全限定名，父类索引用于确定这个类父类的全限定名，接口索引用来描述这个类实现了哪些接口。 字段表集合 描述当前类或接口声明的所有字段，不包括从父类或父接 口继承的部分。 方法表集合 描述当前类或接口中声明的方法，不包括从父类或父接口继承的方法。 类加载 类加载时机 遇到 new 、 getstatic 、 putstatic 和 invokestatic 这四条字节码指令时，如果对应的类没有初始化，则要对对应的类先进行初始化。 这四个指令对应到我们java代码中的场景分别是: new关键字实例化对象的时候; 读取或设置一个类的静态字段(读取被final修饰，已在编译器把结果放入常量池的静态字段除外) ;调用类的静态方法时。 使用 java.lang.reflect 包方法时对类进行反射调用的时候。 初始化一个类的时候发现其父类还没初始化，要先初始化其父类。 当虚拟机开始启动时，用户需要指定一个主类，虚拟机会先执行这个主类的初始化 类加载过程 加载 通过一个类的全限定名来获取定义此类的二进制流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区中这个类的各种数据的访问入口 验证 准备 仅仅为类变量(即static修饰的字段变量)分配内存并且设置该类变量的初始值即零值。 不包含用final修饰的static，因为final在编译的时候就会分配了(编译器的优化)。同时也不会为实例变量分配初始化。 解析 解析是虚拟机将常量池的符号引用替换为直接引用的过程。 符号引用指向了类的名称或者方法的名称或者字段的名称等，不是内存中的表示方式。 直接引用可以是:直接指向目标的指针、相对偏移量、一个能间接定位到目标的句柄。 初始化 到了此阶段，才真正开始执行类中定义的Java程序代码(初始化成为代码设定的默认值)。 其实初始化过程就是调用类初始化方法的过程，完成对static修饰的类变量的手动赋值还有主动调用静 态代码 卸载 当一个类对应的对象都已经回收的时候，会触发卸载。 类加载器 双亲委派 双亲委派机制，加载某个类时会先委托父加载器寻找目标类，找不 到再委托上层父加载器加载，如果所有父加载器在自己的加载类路径下都找不到目标类，则在自己的类加载路径中查找并载入目标类。 JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。 protected synchronized Class loadClass(String name, boolean resolve) throws ClassNotFoundException { //1 首先检查类是否被加载 Class c = findLoadedClass(name); if (c == null) { try { if (parent != null) { //2 没有则调用父类加载器的loadClass()方法； c = parent.loadClass(name, false); } else { //3 若父类加载器为空，则默认使用启动类加载器作为父加载器； c = findBootstrapClass0(name); } } catch (ClassNotFoundException e) { //4 若父类加载失败，抛出ClassNotFoundException 异常后 //再调用自己的findClass() 方法。 c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } 优点 沙箱安全机制：自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库被随意篡改 避免类的重复加载:当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载类的唯一性 破坏 可以继承ClassLoader类，然后重写其中的loadClass方法或者重写findClass方法 编译 前端编译 Java的执行过程整体可以分为两个部分，第一步由javac将源码编译成字节码，在这个过程中会进行词法分析、语法分析、语义分析，编译原理中这部分的编译称为前端编译。 泛型、自动装箱、自动拆箱、遍历循环（for-each），都是前端编译实现 后端编译 接下来无需编译直接逐条将字节码解释执行，在解释执行的过程中，虚拟机同时对程序运行的信息进行收集，在这些信息的基础上，编译器会逐渐发挥作用，它会进行后端编译——把字节码编译成机器码，但不是所有的代码都会被编译，只有被JVM认定为的热点代码，才可能被编译。 Java程序最初是通过解释器(Interpreter)进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“热点代码”。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（JIT）。 编译器和解释器的协调工作流程 解释器可以省去编译的时间，立即执行。在程序运行后，编译器把代码编译成本地代码之后，可以获取更高的执行效率。同时，编译后代码相对于字节码占用空间多。当程序运行环境中内存限制较大，使用解释器执行节约内存，反之可以使用编译执行提升效率 。 热点代码 运行过程中会被即时编译器编译的热点代码有两类：被多次调用的方法和被多次执行的循环体。两种情况，编译器都是以整个方法作为编译对象。 判断是不是热点代码有下面两种方式 基于采样的热点探测。虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这个方法就是热点方法。 基于计数器的热点探测。采用这种方法的虚拟机会为每个方法(甚至是代码块)建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是热点方法。 编译器 HotSpot虚拟机中内置了两个即时编译器:Client Complier和Server Complier，简称为C1、C2编译器，分别用在客户端和服务端。用户也可以使用“-client”或“-server”参数去强制指定。用Client Complier获取更高的编译速度，用Server Complier 来获取更好的编译质量。 JIT优化 公共子表达式消除 如果一个表达式E已经 计算过了，并且从先前的计算到现在E中所有变量的值都没有发生变化，那么E的这次出现就成为了公共 子表达式。 int d = (c*b)*12+a+(a+b*c); //优化为 int d = E*12+a+(a+E); 方法内联 将方法调用直接使用方法体中的代码进行替换，这就是方法内联，减少了方 法调用过程中压栈与入栈的开销。 private int add4(int x1， int x2， int x3， int x4) { return add2(x1， x2) + add2(x3， x4); } private int add2(int x1， int x2) { return x1 + x2; } //优化后 private int add4(int x1， int x2， int x3， int x4) { return x1 + x2 + x3 + x4; } 逃逸分析 通过逃逸分析，Java Hotspot编译器能够 分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。 "},"content/JVM/JVM调优.html":{"url":"content/JVM/JVM调优.html","title":"JVM调优","keywords":"","body":"JPS 查看java进程 Jinfo 实时查看和调整JVM配置参数 查看JVM参数和java系统参数。 Jstat stat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下: jstat [-命令选项] [vmid] [间隔时间(毫秒)] [查询次数] jstat -gc pid ，可以评估程序内存使用及GC压力整体情况。包括各个分区的大小和使用大小，垃圾回收次数，垃圾回收消耗时间 jstat -gccapaciy pid，堆内存统计。 jsta -gcnew pid，新生代垃圾回收统计。 Jmap 查看内存信息 jmap -histo pid，实例个数以及占用内存大小，类名称 jmap -heap pid，堆信息 jmap -dump，堆内存dump Jstack 查看线程堆栈信息。jstack pid。 top top命令查看各个进程的cpu使用情况，默认按cpu使用率排序。 top -Hp pid 找出该进程内最耗费CPU的线程，将线程id转化为16进制 jstack pid 查看线程的堆栈信息。nid与上述16进制对应。或jstack pid|grep -A 10 nid 查看对应的堆栈信息找出可能存在问题的代码 gc.log [GC (Allocation Failure) [ParNew: 367523K->1293K(410432K), 0.0023988 secs] 522739K->156516K(1322496K), 0.0025301 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] GC：表明进行了一次垃圾回收，前面没有Full修饰，表明这是一次Minor GC Allocation Failure：表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。 ParNew：表明本次GC发生在年轻代并且使用的是ParNew垃圾收集器。 367523K->1293K(410432K)：单位是KB。三个参数分别为：GC前该内存区域(这里是年轻代)使用容量，GC后该内存区域使用容量，该内存区域总容量。 0.0023988 secs：该内存区域GC耗时，单位是秒 522739K->156516K(1322496K)：三个参数分别为：堆区垃圾回收前的大小，堆区垃圾回收后的大小，堆区总大小。 0.0025301 secs：该内存区域GC耗时，单位是秒 [Times: user=0.04 sys=0.00, real=0.01 secs]：分别表示用户态耗时，内核态耗时和总耗时 "},"content/Mysql/架构.html":{"url":"content/Mysql/架构.html","title":"架构","keywords":"","body":"MySql体系结构 MySql模块详解 Connectors：用来支持各种语言和 SQL 的交互，比如 PHP，Python，Java 的 JDBC Management Serveices & Utilities：系统管理和控制工具，包括备份恢复、MySQL 复制、集群等等 Connection Pool：连接池，管理需要缓冲的资源，包括用户密码权限线程等等 SQL Interface：用来接收用户的 SQL 命令，返回用户需要的查询结果 Parser：用来解析 SQL 语句 Optimizer：查询优化器 Cache and Buffer：查询缓存，除了行记录的缓存之外，还有表缓存，Key 缓存，权限缓存等等 Pluggable Storage Engines：插件式存储引擎，它提供 API 给服务层使用，跟具体的文件打交道 Parser解析器 这一步主要是对语句基于 SQL 语法进行词法和语法分析和语义的解析。 词法分析就是把一个完整的 SQL 语句打碎成一个个的单词。第二步是语法分析，语法分析会对 SQL 做一些语法检查，比如单引号有没有闭合。然后根据 MySQL 定义的语法规则，根据 SQL 语句生成一个数据结构，解析树。 解析 SQL 时有预处理器。，它会检查生成的解析树，解决解析器无法解析的语义。比如，它会检查表和列名是否存在，检查名字和别名，保证没有歧义。 Optimizer优化器 查询优化器的目的就是根据解析树生成不同的执行计划(Execution Plan)，然后选择一种最优的执行计划，MySQL 里面使用的是基于开销(cost)的优化器，那种执行计划开销最小，就用哪种。优化器最终会把解析树变成一个查询执行计划，查询执行计划是一个数据结构。 MySQL 的优化器能处理哪些优化类型呢? 举两个简单的例子:当我们对多张表进行关联查询的时候，以哪个表的数据作为基准表。有多个索引可以使用的时候，选择哪个索引。 存储引擎 Innodb Myisam 存储文件 .frm 表定义文件 ，.ibd 数据文件和索引文件 .frm 表定义文件， .myd 数据文件 ，.myi 索引文件 锁 表锁，行锁 表锁 事务 支持 不支持 count 扫表 专门存储 (加where也扫表) 外键 支持 不支持 InnoDB内存和磁盘结构 内存结构 buffer Pool Buffer Pool 缓存的是页面信息，包括数据页、索引页。 InnoDB 操作数据有一个最小的逻辑单位，叫做页(索引页和数据页)。我们对于数据的操作，不是每次都直接操作磁盘，因为磁盘的速度太慢了。InnoDB 使用了一种缓冲池的技术，也就是把磁盘读到的页放到一块内存区域里面。这个内存区域就叫 Buffer Pool。 下一次读取相同的页，先判断是不是在缓冲池里面，如果是，就直接读取，不用再次访问磁盘。修改数据的时候，先修改缓冲池里面的页。内存的数据页和磁盘数据不一致的时候， 我们把它叫做脏页。InnoDB 里面有专门的后台线程把Buffer Pool的数据写入到磁盘，每隔一段时间就一次性地把多个修改写入磁盘。 Change Buffer 如果这个数据页不是唯一索引，不存在数据重复的情况，也就不需要从磁盘加载索引页判断数据是不是重复(唯一性检查)。这种情况下可以先把修改记录在内存的缓冲池中，从而提升更新语句(Insert、Delete、Update)的执行速度。这一块区域就是 Change Buffer。 最后把 Change Buffer 记录到数据页的操作叫做 merge。什么时候发生 merge，有几种情况:在访问这个数据页的时候，或者通过后台线程、或者数据库 shut down、 redo log 写满时触发。 自适应hash InnoDB 只支持显式创建 B+Tree 索引，对于一些热点数据页， InnoDB 会自动建立自适应 Hash 索引，也就是在 B+Tree 索引基础上建立 Hash 索引， 这个过程对于客户端是不可控制的，隐式的。 Redo Log 如果 Buffer Pool 里面的脏页还没有刷入磁盘时，数据库宕机或者重启，这些数据丢失。为了避免这个问题，InnoDB 把所有对页面的修改操作专门写入一个日志文件，并且在数据库启动时从这个文件进行恢复操作，用它来实现事务的持久性。 这个文件就是磁盘的 redo log(叫做重做日志)，对应于/var/lib/mysql/目录下的 ib_logfile0 和 ib_logfile1。在 Buffer Pool 里面有一块内存区域 (Log Buffer)专门用来保存即将要写入日志文件的数据 InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。 磁盘结构 系统表空间 数据字典：由内部系统表组成，存储表和索引的元数据(定义信息)。 双写缓冲：如果出现了 写入失效，就用页的副本来还原这个页，然后再应用 redo log。这个页的副本就是 double write，InnoDB 的双写技术。通过它实现了数据页的可靠性 独占表空间 我们可以让每张表独占一个表空间。这个开关通过 innodb_file_per_table 设置，开启后，则每张表会开辟一个表空间，这个文件就是数据目录下的 ibd 文件，存放表的索引和数据。 undo log tablespace undo log( 撤销日志或回滚日志)记了事务发生之前的数据状态。 如果修改数据时出现异常，可以用 undo log 来实现回滚操作(保持原子性） 后台进程 后台线程的主要作用是负责刷新内存池中的数据和把修改的数据页刷新到磁盘。 master thread 负责刷新缓存数据到磁盘并协调调度其它后台进程。 IO thread 分为 insert buffer、log、read、write 进程。分别用来处理 insert buffer、 重做日志、读写请求的 IO 回调。 purge thread 用来回收 undo 页。 page cleaner thread 用来刷新脏页。 除了 InnoDB 架构中的日志文件，MySQL 的 Server 层也有一个日志文件，叫做binlog，它可以被所有的存储引擎使用。 更新语句执行流程 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。 redo log 和binlog redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 崩溃恢复时的判断规则。 如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交； 如果redo log里面的事务只有完整的prepare，就拿着XID去binlog找对应的事务。提交事务或者回滚事务。 "},"content/Mysql/索引.html":{"url":"content/Mysql/索引.html","title":"索引","keywords":"","body":"索引数据结构 多路平衡查找树（B Tree） B Tree 保持平衡：比如路数是3的时候，我们插入数据 1、2、3，在插入 3 的时候，子节点会变成 4 路，这个时候必须进行分裂。把中间的数据 2 提上去，把 1 和 3 变 成 2 的子节点。 节点的分裂和合并，其实就是 InnoDB 页的分裂和合并。可以看到，在更新索引的时候会有大量的索引的结构的调整，所以解释了为什么我们不要在频繁更新的列上建索引，或者为什么不要更新主键。 B+树(加强版多路平衡查找树) 它的关键字的数量是跟路数相等的 B+Tree 的根节点和枝节点中都不会存储数据，只有叶子节点才存储数据。搜索 B+Tree 的每个叶子节点增加了一个指向相邻叶子节点的指针，它的最后一个数据会指向下一个叶子节点的第一个数据，形成了一个有序链表的结构。 它是根据左闭右开的区间 [ )来检索数据。 InnoDB 中的 B+Tree 的特点: 扫库、扫表能力更强(对表进行全表扫描，只需要遍历叶子节点就可以 了，不需要遍历整棵 B+Tree 拿到所有的数据) B+Tree 的磁盘读写能力相对于 B Tree 来说更强(根节点和枝节点不保存数据区， 所以一个节点可以保存更多的关键字，一次磁盘加载的关键字更多) 排序能力更强(因为叶子节点上有下一个数据区的指针，数据形成了链表) 效率更加稳定(B+Tree 永远是在叶子节点拿到数据，所以 IO 次数是稳定的) 索引落地形式 在 InnoDB 里面，它是以主键为索引来组织数据的存储的，所以索引文件和数据文件是同一个文件，都在.ibd 文件里面。 聚集索引(聚簇索引)就是索引键值的逻辑顺序跟表数据行的物理存储顺序是一致的。主键索引是聚集索引，非主键都是非聚集索引。辅助索引存储的是辅助索引和主键值。如果使用辅助索引查询，会根据主键值在主 键索引中查询，最终取得数据。 辅助索引里面存储的是主键值，能够节省空间消耗，同时因为有分叉和合并的操作，键值的地址会发生变化，所以在辅助索引里面不能存储地址。 假设一条记录是 1K，一个叶子节点(一页)可以存储 16 条记录。非叶子节点可以存储多少个指针? 假设索引字段是 bigint 类型，长度为 8 字节。指针大小在 InnoDB 源码中设置为 6 字节，这样一共 14 字节。非叶子节点(一页)可以存储 16384/14=1170 个这样的单元(键值+指针)，代表有 1170 个指针。 树深度为 2 的时候，有 1170^2 个叶子节点，可以存储的数据为 1170*1170*16=21902400。 索引使用 索引类型 普通索引，也叫非唯一索引，是最普通的索引，没有任何的限制。 唯一索引，键值不能重复。主键索引是一种特殊的唯一索引，键值不能为空。主键索引用 primay key 创建。 全文索引，针对比较大的数据，解决like查询效率低的问题，可以创建全文索引。只有文本类型的字段才可以创建全文索引，比如 char、varchar、text。 联合索引 由多个字段组成的索引 使用顺序就是创建的顺序,省空间、容易形成覆盖索引。联合索引最左匹配原则。 覆盖索引 非主键索引，我们先通过索引找到主键索引的键值，再通过主键值查出索引里面没有的数据，它比基于主键索引的查询多扫描了一棵索引树，这个过程就叫回表。 在辅助索引里面，不管是单列索引还是联合索引，如果 select 的数据列只用从索引 中就能够取得，不必从数据区中读取，这时候使用的索引就叫做覆盖索引，这样就避免 了回表。 前缀索引 使用字符串的前几个字符作为索引，不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引(Covering Index)。 索引选择性，不重复的个数与总个数的比值。 count(distinct left(city,4))/count(*) as sel4 索引下推 last_name 和 first_name 上面创建联合索引。 select * from employees where last_name='wang' and first_name LIKE '%zi'; 这条 SQL 有两种执行方式: 1、根据联合索引查出所有姓 wang 的二级索引数据，然后回表，到主键索引上查询 全部符合条件的数据(3 条数据)。然后返回给 Server 层，在 Server 层过滤出名字以 zi 结尾的员工。 2、根据联合索引查出所有姓 wang 的二级索引数据(3 个索引)，然后从二级索引 中筛选出 first_name 以 zi 结尾的索引(1 个索引)，然后再回表，到主键索引上查询全 部符合条件的数据(1 条数据)，返回给 Server 层。 关闭索引下推，执行1。 set optimizer_switch='index_condition_pushdown=off'; 索引的比较是在存储引擎进行的，数据记录的比较，是在 Server层进行的。而当 first_name 的条件不能用于索引过滤时，Server 层不把first_name 的条件传递给存储引擎，所以读取了两条没有必要的记录。 开启索引下推，执行2。 索引条件下推(Index Condition Pushdown)，5.6 以后完善的功能。只适用于二级索引。目标是减少访问表的完整行的读数量从而减少 I/O 操作。 普通索引还是唯一索引 普通索引和唯一索引，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer 索引使用原则 在用于 where 判断 order 排序和 join 的(on)字段上创建索引。 索引个数不要太多，浪费空间，更新变慢。 区分度低的字段，不要建索引。 离散度太低，导致扫描行数过多。 频繁更新的值，不要作为主键或者索引。导致页分裂 组合索引把散列性高(区分度高)的值放在前面。 不建议用无序的值(例如身份证、UUID )作为索引。 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作(计算、函数、(自动or手动)类型转换)，会导致索引失效而转向全表扫描 不能使用索引中范围条件右边的列。 少用or或in，用它查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、 表大小等多个因素整体评估是否使用索引。可以讲大的范围拆分成多个小范围。 用不到索引 索引列上使用函数(replace\\SUBSTR\\CONCAT\\sum count avg)、表达式、 计算(+ - * /)不会使用索引 字符串不加引号，出现隐式转换，不会使用索引 like 条件中前面带% 负向查询，NOT LIKE 不能。!= (<>)和 NOT IN 在某些情况下可以。 用不用索引，最终都是优化器说了算。优化器是基于 cost 开销(Cost Base Optimizer)，它不是基于规则(Rule-Based Optimizer)，也不是基于语义。怎么样开销小就怎么来。 索引优化 order by与group by MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 建立索引，（name，age，position） Using Index 的情况 select * from employees where name = 'LiLei' and position = 'dev' order by age; 查询用到了name索引，age索引列用在排序过程中 select *from employees where name='LiLei'order by age,position; 查找只用到索引name，age和position用于排序 select * from employees where name = 'LiLei' and age = 18 order by position，age; 因为age为常量，在排序中被优化，所以索引未颠倒 Using Filesort select *from employees where name='LiLei'order by position; 查询使用了name索引，由于用了position进行排序，跳过了 age。 select *from employees where name='LiLei'order by position,age; 索引的创建顺序为 name,age,position，但是排序的时候age和position颠倒位置了 select *from employees where name='LiLei'order by age asc,position desc; position desc变成了降序，导致与索引的排序方式不同，Mysql8以上版本有降序索引可以支持该种查询方式。 select *from employees where name in ('LiLei','hanmei') order by age,position; 对于排序来说，多个相等条件也是范围查询 优化总结 order by满足两种情况会使用Using index。order by语句使用索引最左前列。使用where子句与order by子句条件列组合满足索引最左前列 尽量在索引列上完成排序，遵循索引建立(索引创建的顺序)时的最左前缀法则。 如果order by的条件不在索引列上，就会产生Using filesort。 group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having，能写在where中 的限定条件就不要去having限定了。 filesort排序原理 filesort使用两种排序方式 单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序。 双路排序(回表排序)：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段。 MySQL 通过比较系统变量 max_length_for_sort_data(默认1024字节) 的大小和需要查询的字段总大小来判断使用哪种排序模式。 如果比查询字段的总长度大，那么使用单路排序模式。否则使用双路排序模式。 分页查询优化 select * from employees limit 90000,5; 表示从表 employees 中取出从 90001 行开始的 5 行记录。看似只查询了 5 条记录，实际这条 SQL 是先读取 90005 条记录，然后抛弃前 10000 条记录，然后读到后面 5 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的。 根据自增且连续的主键排序的分页查询 该 SQL 表示查询从第 90001开始的五行数据，没添加单独 order by，表示通过主键排序。我们再看表 employees ，因为主键是自增并且连续的，所以可以改写成按照主键去查询从第 90001开始的五行数据。 select * from employees where id > 90000 limit 5; 改写得满足两个条件。主键自增且连续，结果是按照主键排序的。 非主键字段排序的分页查询 select * from employees ORDER BY name limit 90000,5; 没有使用 name 字段的索引，原因是扫描整个索引并查找到没索引的行(可能要遍历多个索引树)的成本比扫描全表的成本更高，所以优化器放弃使用索引。 关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录，SQL 改写如下 select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id; 原 SQL 使用的是 filesort 排序，而优化后的 SQL 使用的是索引排序。 join关联查询优化 示例表: CREATETABLE`t1`( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a` (`a`) )ENGINE=InnoDBAUTO_INCREMENT=10001DEFAULTCHARSET=utf8; create table t2 like t1; 往t1表插入1万行记录，往t2表插入100行记录 嵌套循环连接 Nested-Loop Join(NLJ) 算法 一次一行循环地从第一张表(称为驱动表)中读取行，在这行数据中取到关联字段，根据关联字段在另一张表(被驱动表)里取出满足条件的行，然后取出两张表的结果合集。 select * from t1 inner join t2 on t1.a= t2.a; 驱动表是 t2，被驱动表是 t1。先执行的就是驱动表。优化器一般会优先选择小表做驱动表。一般 join 语句中，如果执行计划 Extra 中未出现 Using join buffer 则表示使用的 join 算法是 NLJ。 上面sql的大致流程如下： 从表 t2 中读取一行数据; 从第 1 步的数据中，取出关联字段 a，到表 t1 中查找; 取出表 t1 中满足条件的行，跟 t2 中获取到的结果合并，作为结果返回给客户端; 重复上面 3 步。 整个过程会读取 t2 表的所有数据(扫描100行)，然后遍历这每行数据中字段 a 的值，根据 t2 表中 a 的值索引扫描 t1 表 中的对应行(扫描100次 t1 表的索引，1次扫描可以认为最终只扫描 t1 表一行完整数据，也就是总共 t1 表也扫描了100 行)。因此整个过程扫描了 200 行。 如果被驱动表的关联字段没索引，使用NLJ算法性能会比较低。mysql会选择Block Nested-Loop Join 算法。 基于块的嵌套循环连接 Block Nested-Loop Join(BNL)算法 把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比。 select * from t1 inner join t2 on t1.b= t2.b; 上面sql的大致流程如下: 把 t2 的所有数据放入到 join_buffer 中。 把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比。 返回满足 join 条件的数据。 整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) = 10100。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是 100 * 10000= 100 万次。 被驱动表的关联字段没索引，使用 Nested-Loop Join，那么扫描行数为 100 * 10000 = 100万次，这个是磁盘扫描。相比于磁盘扫描，BNL的内存计算会快得多。 关联sql优化 关联字段加索引，让mysql做join操作时尽量选择NLJ算法。 小标驱动大表，写多表连接sql时如果明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间。只适用于inner join，因为left join，right join已经代表指定了表的执行顺序。 in和exsits优化 原则：小表驱动大表，即小的数据集驱动大的数据集。 in：当B表的数据集小于A表的数据集时，in优于exists select * from A where id in(select id from B) #等价于: for(select id from B){ select * from A where A.id = B.id } exists：当A表的数据集小于B表的数据集时，exists优于in select * from A where exists(select 1 from B where B.id=A.id) #等价于: for(select * from A){ select * from B where B.id = A.id } count（） select count(1) from employees; select count(id) from employees; select count(name) from employees; select count(*) from employees; 对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。 对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。 对于count(字段)来说： 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加； 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。 按照效率排序的话，count(字段) mysql最终选择辅助索引而不是主键聚集索引，因为二级索引相对主键索引存储数据更少，检索性能应该更高。 如果只需要知道表总行数的估计值可以用如下sql查询，性能很高。 show table status like 'employees'; 索引选择错误 选择索引是优化器的工作。优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。优化器还会结合是否使用临时表、是否排序等因素进行综合判断。 扫描行数，只能根据统计信息来估算记录数。采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 解决方案 一种方法是，像我们第一个例子一样，采用force index强行选择一个索引。analyze table t 命令，可以用来重新统计索引信息 第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引 第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引 "},"content/Mysql/执行计划.html":{"url":"content/Mysql/执行计划.html","title":"执行计划","keywords":"","body":"慢查询日志 MySQL慢查询就是在日志中记录运行比较慢的SQL语句，这个功能需要开启才能用。 long_query_time = 10 #指执行超过多久的SQL会被日志记录下来 log-slow-queries = /var/lib/mysql/mysql-slow.log #日志地址 log_queries_not_using_indexes #未使用索引查询 log_output #日志存储方式 Explain执行计划 explain select (select 1 from actor where id = 1) from (select * from film where id = 1) id列 id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的 顺序增长的。id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。 select_type列 select_type 表示对应行是简单还是复杂的查询。 simple：简单查询。查询不包含子查询和union primary：复杂查询中最外层的 select subquery：包含在 select 中的子查询(不在 from 子句中) derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表 union：在 union 中的第二个和随后的 select table列 这一列表示 explain 的一行正在访问哪个表。 当 from 子句中有子查询时，table列是 \\ 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。 type列 这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。 依次从最优到最差分别为:system > const > eq_ref > ref > range > index > ALL 。一般来说，得保证查询达到range级别，最好达到ref NUll：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 const：mysql能对查询的某部分进行优化并将其转化成一个常量。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。 system：是const的特例，表里只有一条元组匹配 eq_ref：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。 ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行 range：范围扫描通常出现在 in(), between ,> ,= 等操作中。使用一个索引来检索给定 范围的行。 index：index:扫描全表索引，这通常比ALL快一些。 ALL：ALL:即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了 possible_keys列 这一列显示查询可能使用哪些索引来查找。 explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 key列 这一列显示mysql实际采用哪个索引来优化对该表的访问。 如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视key列中的索引，在查询中使用 force index、ignore index。 key_len列 这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。如果字段允许为 NULL，需要1字节记录是否为 NULL。 key_len计算规则如下： char(n)：n字节长度，varchar(n)：2字节存储字符串长度，如果是utf-8，则长度 3n +2，tinyint：1字节，smallint：2字节 ，int：4字节，bigint：8字节 ，date：3字节，timestamp：4字节，datetime：8字节 ref列 这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有:const(常量)，字段名(例:film.id) rows列 这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。 Extra列 这一列展示的是额外信息。常见的重要值如下。 Using index：使用覆盖索引 Using where，Using index condition： Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行 优化的，首先是想到用索引来优化。 Using filesort：将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘 完成排序。这种情况下一般也是要考虑使用索引来优化的。 Select tables optimized away：使用某些聚合函数(比如 max、min)来访问存在索引的某个字段 "},"content/Mysql/锁和MVCC.html":{"url":"content/Mysql/锁和MVCC.html","title":"锁和MVCC","keywords":"","body":"MySql事务 事务特性 事务的四大特性:ACID。 第一个，原子性，Atomicity。数据库的一系列操作，要么都是成功，要么都是失败，不可能出现部分成功或者部分失败的情况。原子性，在 InnoDB 里面是通过 undo log 来实现的，它记录了数据修改之前的值(逻 辑日志)，一旦发生异常，就可以用 undo log 来实现回滚操作。 第二个，一致性，consistent，指的是数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。比如主键必须是唯一的，字段长度符合要求。除了数据库自身的完整性约束，还有一个是用户自定义的完整性。 第三个，隔离性，Isolation，就是多个的事务，对表或者行的并发操作，应该是透明的，互相不干扰的。通过这种方式，我们最终也是保证业务数据的一致性。 第四个，持久性，Durable，对数据库的任意 的操作，增删改，只要事务提交成功，那么结果就是永久性的。持久性是通过 redo log 和 double write 双写缓冲来实现的，我们操作数据的时候，会先写到内存的 buffer pool 里面，同时记录 redo log，如果在刷盘之前出现异常，在 重启后就可以读取 redo log 的内容，写入到磁盘，保证数据的持久性。当然，恢复成功的前提是数据页本身没有被破坏，是完整的，这个通过双写缓冲 (double write)保证。 事务带来问题 脏读 事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求 不可重复读 事务A读取到了事务B已提交的数据，导致前后两次读取数据不一致的情 况，我们把它叫做不可重复读 幻读 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 一句话:事务A读取到了事务B提交的新增数据。 不可重复读是修改或者删除，幻读是插入。 隔离级别 论是脏读，还是不可重复读，还是幻读，它们都是数据库的读一致性的问题。读一致性的问题，必须要由数据库提供一定的事务隔离机制来解决。InnoDB 对数据库事务隔离级别。 Read Uncommitted(未提交读)，一个事务可以读取到其他事务未提交的数据，会出现脏读，所以叫做 RU。 Read Committed(已提交读)，也就是一个事务只能读取到其他事务已提交的数据，不能读取到其他事务未提交的数据，它解决了脏读的问题。 Repeatable Read (可重复读)，它解决了不可重复读的问题，也就是在同一个事务里面多次读取同样的数据结果是一样的，但是在这个级别下，没有定义解决幻读的问题。 Serializable(串行化)，在这个隔离级别里面，所有的事务都是串行执行的，也就是对数据的操作需要排队，已经不存在事务的并发操作了，所以它解决了所有的问题。 MVCC 如果要解决读一致性的问题，实现事务隔离，总体上来说，我们有两大类的方案。 第一种，读取数据时锁定要操作的数据，不允许其他的事务修改。这种方案叫做基于锁的并发控制 Lock Based Concurrency Control(LBCC)。 第二种，在修改数据的时候给它建立一个备份或者叫快照，后面再来读取这个快照就行了。这种方案叫做多版本的并发控制 Multi Version Concurrency Control (MVCC)。 MVCC实现 MVCC 在mysql 中的实现依赖的是 undo log 与 read view 。 在MVCC并发控制中，读操作可以分成两类。快照读与当前读。 快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。简单的select操作，属于快照读，不加锁。 当前读，读取的是记录的最新版本，并且当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。插入/更新/删除操作，属于当前读，需要加锁 InnoDB 为每行记录都实现了两个隐藏字段 DB_TRX_ID，理解为创建版本号，在数据新增或者修改为新数据的时候，记录当前事务ID，编号是自动递增。 DB_ROLL_PTR，回滚指针，指向回滚段中的undo log。理解为删除版本号，数据被删除或记录为旧数据的时候，记录当前事务 ID。使用UPDATE语句修改该行数据时，会首先使用排他锁锁定改行，将该行当前的值复制到undo log中，然后再真正地修改当前行的值，最后填写事务ID，使用回滚指针指向undo log中修改前的行。 查找规则：只能查找创建时间小于等于当前事务 ID 的数据，和删除时间大于当前事务 ID 的行(或未删除)。 Undolog undo log分为两种：insert undo log和update undo log insert undo log：是在 insert 操作中产生的 undo log。因为 insert 操作的记录只对事务本身可见， rollback 在该事务中直接删除 ，不需要进行 purge 操作。 update undo log ：是 update 或 delete 操作中产生的 undo log，因为会对已经存在的记录产生影响， rollback时MVCC机制会找他的历史版本进行恢复。因此 update undo log 不能在事务提交时就进行删除，而是将事务提交时放到入 history list 上， 等待 purge 线程进行最后的删除操作。 Read View MySQL中的事务在开始到提交这段过程中，都会被保存到一个叫trx_sys的事务链表中。事务链表中保存的都是还未提交的事务，事务一旦被提交，则会被从事务链表中摘除 RR隔离级别下，在每个事务开始的时候，会将当前系统中的所有的活跃事务拷贝到一个列表中(read view)。 RC隔离级别下，在每个语句开始的时候，会将当前系统中的所有的活跃事务拷贝到一个列表中(read view)。 锁 锁的类型 共享锁 也叫读锁，多个事务可以共享一把读锁。可以用select ...... lock in share mode 的方式手工加上一把读锁。 排他锁 只要一个事务获取了一行数据的排它锁，其他的事务就不能再获取这一行数 据的共享锁和排它锁。 排它锁的加锁方式有两种。第一种是自动加排他锁，在操作数据时（增删改）都会默认加上一个排它锁。第二种是手工加锁，用一个 FOR UPDATE 给一行数据加上一个排它锁。 意向锁 由数据 库自己维护的。当给一行数据加上共享锁之前，数据库会自动在这张表上面加一个意向共享锁。给一行数据加上排他锁之前，数据库会自动在这张表上面加一个意向排他锁。 行锁的原理 InnoDB 的行锁，就是通过锁住索引来实现的。 查询没有使用索引，会进行全表扫描，导致锁表。 通过唯一索引给数据行加锁，主键索引也会被锁住 锁的算法 数据库里面存在的主键值，我们把它叫做 Record 根据主键，这些存在的 Record 隔开的数据不存在的区间，我们把它叫做 Gap，间隙，它是一个左开右开的区间。 间隙(Gap)连同它左边的记录(Record)，我们把它叫做临键的区间， 它是一个左开右闭的区间。 字符可以用 ASCII 码来排序 记录锁 对于唯一性的索引(包括唯一索引和主键索引)使用等值查询，精准匹配到一条记录的时候，这个时候使用的就是记录锁。 比如where id = 1 4 7 10 ，使用不同的 key 去加锁，不会冲突，它只锁住这个 record。 间隙锁 当我们查询的记录不存在，没有命中任何一个 record，无论是用等值查询还是范围查询的时候，它使用的都是间隙锁。 间隙锁主要是阻塞插入 insert。相同的间隙锁之间不冲突。 Gap Lock 只在 RR 中存在。如果要关闭间隙锁，就是把事务隔离级别设置成 RC， 并且把 innodb_locks_unsafe_for_binlog 设置为 ON。这种情况下除了外键约束和唯一性检查会加间隙锁，其他情况都不会用间隙锁。 临键锁 当使用了范围查询，不仅仅命中了 Record 记录，还包含了 Gap 间隙，在这种情况下我们使用的就是临键锁，它是 MySQL 里面默认的行锁算法，相当于记录锁加上间隙锁。 临键锁，锁住最后一个 key 的下一个左开右闭的区间。 select * from t2 where id >5 and id 8 and id 唯一性索引，等值查询匹配到一条记录的时候，退化成记录锁。 没有匹配到任何记录的时候，退化成间隙锁。 隔离级别的实现 RU 隔离级别：不加锁。 Serializable ：所有的 select 语句都会被隐式的转化为 select ... in share mode，会和 update、delete 互斥 可重复读（RR） RR 隔离级别下，普通的 select 使用快照读(snapshot read)，底层使用 MVCC 来实现。 加锁的 select(select ... in share mode / select ... for update)以及更新操作 update, delete 等语句使用当前读(current read)，底层使用记录锁、或者间隙锁、 临键锁。 已提交读（RC） RC 隔离级别下，普通的 select 都是快照读，使用 MVCC 实现。 加锁的 select 都使用记录锁，因为没有 Gap Lock。所以 RC 会出现幻读的问题。 区别 RC 和 RR 主要有几个区别: RR 的间隙锁会导致锁定范围的扩大。 条件列未使用到索引，RR 锁表，RC 锁行。 RC 的“半一致性”(semi-consistent)读能增加 update 操作的并发性。 在 RC 中，一个 update 语句，如果读到一行已经加锁的记录，此时 InnoDB 返回记录最近提交的版本，由 MySQL 上层判断此版本是否满足 update 的 where 条件。若满 足(需要更新)，则 MySQL 会重新发起一次读操作，此时会读取行的最新版本(并加锁)。 死锁 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 在InnoDB中，innodb_lock_wait_timeout的默认值是50s。第二种策略耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。 热点行更新导致的性能问题。 能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加 "},"content/Mysql/优化.html":{"url":"content/Mysql/优化.html","title":"Mysql优化","keywords":"","body":"优化思路 连接配置优化 增加服务端的可用连接数，及时释放不活动的连接。 客户端减少从服务端获取的连接数，引入连接池，实现连接的重用。建议连接池大小是机器核数乘以 2 加 1 缓存，架构优化 主从复制 binlog 格式 STATEMENT：记录每一条修改数据的 SQL 语句(减少日志量，节约 IO)。 ROW：记录哪条数据被修改了，修改成什么样子了(5.7 以后默认)。 MIXED：结合两种方式，一般的语句用 STATEMENT，函数之类的用 ROW。 原理 slave 服务器执行 start slave，开启主从复制开关， slave 服务器的 IO 线程请 求从 master 服务器读取 binlog(如果该线程追赶上了主库，会进入睡眠状态)。 master 服务器创建 Log Dump 线程，把 binlog 发送给 slave 服务器。slave 服 务器把读取到的 binlog 日志内容写入中继日志 relay log(会记录位置信息，以便下次继 续读取)。 slave 服务器的 SQL 线程会实时检测 relay log 中新增的日志内容，把 relay log 解析成 SQL 语句，并执行。 异步与同步复制 在主从复制的过程中，MySQL 默认是异步复制的。也就是说， 对于主节点来说，写入 binlog，事务结束，就返回给客户端了。对于 slave 来说，接收 到 binlog，就完事儿了，master 不关心 slave 的数据有没有写入成功。 同步复制，等待全部从库的事务执行完毕，才返回给客户端呢。 半同步复制 主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到 binlog 并写到 relay log 中才返回给客户端。master 不会等待很长的时间，但是 返回给客户端的时候，数据就即将写入成功了，因为它只剩最后一步读取 relay log，写入从库。 异步复制之 GTID 复制 把在主库上并行执行的事务，分为一个组，并且给他们编号， 这一个组的事务在从库上面也可以并行执行。这个编号，我们把它叫做 GTID(Global Transaction Identifiers)，这种主从复制的方式，我们把它叫做基于 GTID 的复制。 和原来的日志相比，多了last-commited和sequence-number。last-commited是事务提交时上次事物的编号，如果具备同一个last-commited说明在一个组内，可以并发执行。 如果我们要使用 GTID 复制，我们可以通过修改配置参数打开它，默认是关闭的：show global variables like 'gtid_mode'; 主从一致 强制读主 在cache里记录哪些数据发生过写请求，路由决定读主还是读从。 分库分表 垂直切分 垂直分表有两种，一种是单库的，一种是多库的。 单库分表，比如：商户信息表，拆分成基本信息表，联系方式表，结算信息表，附件表等等。 多库垂直分表就是把原来存储在一个库的不同的表，拆分到不同的数据库 水平切分 问题 跨库关联查询 字段冗余。查询合同库的合同表的时候需要关联客户库的客户表，我们可以直接把一些经常关联查询的客户字段放到合同表 数据同步。比如商户系统要查询产品系统的产品表，我们干脆在商户系统创建一 张产品表，通过 ETL 或者其他方式定时同步产品数据 全局表。在所有的数据库都存储相同的基础数据。 ER 表(绑定表)。把父表和数据和从属于父表的数据落到一个节点上 全局事务 全局事务。比如 XA 两阶段提交 基于可靠消息服务的分布式事务。消息中间件 柔性事务 TCC 最大努力通知，通过消息中间件向其他系统发送消息(重复投递+定期校对) 排序、翻页、函数计算问题 需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。 全局主键 uuid 数据库。把序号维护在数据库的一张表中。这张表记录了全局主键的类型、位数、起始值，当前值。当其他应用需要获得全局 ID 时，先 for update 锁行，取到值+1 后并且更新后 返回。并发性比较差。 雪花算法 强依赖机器时钟，如果时钟回拨，则可能导致生成 ID 重复。 "},"content/Mysql/分库分表.html":{"url":"content/Mysql/分库分表.html","title":"分库分表","keywords":"","body":"分表 单表数据量太大，会极大影响你的 sql 执行的性能 分表，就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。 分库 分库，就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 # 分库分表前 分库分表后 并发支撑情况 MySQL 单机部署，扛不住高并发 MySQL 从单机到多机，能承受的并发增加了多倍 磁盘使用情况 MySQL 单机磁盘容量几乎撑满 拆分为多个库，数据库服务器磁盘使用率大大降低 SQL 执行性能 单表数据量太大，SQL 越跑越慢 单表数据量减少，SQL 执行效率明显提升 中间件 综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。 Sharding-jdbc 这种 client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 Sharding-jdbc 的依赖； Mycat 这种 proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。 中间件可以根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。 水平拆分 水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分 垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去 方式 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。 或者是按照某个字段 hash 一下均匀分散，这个较为常用。 range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。 分库分表迁移 双写迁移方案，就是在线上系统里面，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库。 然后系统部署之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。 导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。 接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次。 动态扩容缩容 一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。 刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。 减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。 步骤： 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。 "},"content/Redis/数据结构.html":{"url":"content/Redis/数据结构.html","title":"数据结构","keywords":"","body":"数据结构 简单字符串SDS Redis中字符串的实现。 SDS特点 不用担心内存溢出问题，如果需要会对 SDS 进行扩容 获取字符串长度时间复杂度为 O(1)，因为定义了 len 属性 通过“空间预分配”( sdsMakeRoomFor)和“惰性空间释放”，防止多 次重分配内存。 空间预分配。对 SDS 进行扩展， 会为 SDS 分配修改所必须要的空间和额外的未使用空间。 惰性空间释放。缩短 SDS 保存的字符串时， 不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free属性将这些字节的数量记录起来， 并等待将来使用。 判断是否结束的标志是 len 属性，能保存二进制数据，二进制安全。 链表 跳跃表skiplist 跳表查询、插入、删除的时间复杂度为O(log n) 跳跃表节点 typedef struct zskiplistNode { //层 struct zskiplistLevel { //前进指针，对应 level 的下一个节点 struct zskiplistNode *forward; //从当前节点到下一个节点的跨度(跨越的节点数) unsigned long span; } level[]; robj *obj; //成员对象 double score; //分值 struct zskiplistNode *backward; //后退指针 } zskiplistNode; 层。level数组可以包含多个元素。每个元素都包含指向其他节点的前进指针，即每一层都有一个前进指针。每次创建一个新节点时，根据幂次定律（越大的数出现的概率越小）随机生成一个1到32之间的层数。 跨度。记录两个节点之间的距离。用来计算节点在跳跃表中的排位。 后退指针。用于从表尾向前访问节点，每个节点只有一个后退指针。 分值。节点按照分值大小进行排序。分值相同则按照字典序排序。 跳跃表 通过一个zskiplist结构来记录跳跃表节点。 header。指向跳跃表的表头节点。 tail。指向跳跃表的表尾节点。 level。层数最大的节点的层数。 length。包含节点的数量 压缩列表 经过特殊编码的双向链表，它不存储指向上一个链表节点和指向下一 个链表节点的指针，而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能， 来换取高效的内存空间利用率，是一种时间换空间的思想。只用在字段个数少，字段值小的场景里面。 每个压缩列表节点可以保存一个字节数组或者一个整数值。每个压缩列表节点都由 previous_entry_length 、 encoding 、 content 三个部分组成。 previous_entry_length记录了压缩列表中前一个节点的长度。encoding记录了节点所保存数据的类型以及长度。content 保存节点的值。 连锁更新 如果前一节点的长度小于 254字节， 那么 revious_entry_length需要用 1字节保存这个长度值。大于等于 254字节， 则需要5字节。 在一个压缩列表中， e1 至 eN的长度都介于250到253字节之间。如果e1中保存的revious_entry_length从一字节拓展为5字节，那么会引发e2到eN的拓展，需要不断对压缩列表执行空间充分配操作。 字典 Redis中字典使用哈希表作为底层实现。一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。 哈希表和哈希节点 左边是哈希表结构，table属性是一个dictEntry 数组， 每个元素保存着一个键值对。size属性记录了哈希表的大小， 也即是 table数组的大小。used记录了哈希表目前已有节点（键值对）的数量。sizemask等于 size - 1， 这个属性和哈希值一起决定一个键应该被放到 table数组的哪个索引上面。 右边是哈希表节点，next 是指向另一个哈希表节点的指针， 以此来解决键冲突的问题。并且将新节点添加到链表表头。 字典 ht是一个包含两个哈希表的数组， 字典只使用 ht[0]，ht[1]只在对 ht[0]进行 rehash 时使用。rehashidx记录了 rehash 目前的进度，-1表示没有在进行 rehash 。type保存了一组操作健值对的函数，如计算hash值，复制值的函数等。 rehash 哈希表的负载因子：load_factor = ht[0].used / ht[0].size 哈希表进行拓展：没有执行 BGSAVE 或 BGREWRITEAOF 命令， 负载因子大于等于 1；正在执行 BGSAVE 或 BGREWRITEAOF 命令， 负载因子大于等于 5 。 哈希表收缩：负载因子小于 0.1。 rehash步骤如下： 为字典的ht[1]分配空间。如果执行的是扩展操作， ht[1]的大小为第一个大于等于 ht[0].used * 2 的 2^n。如果执行的是收缩操作， 那么 ht[1]的大小为第一个大于等于 ht[0].used的 2^n 。 将保存在 ht[0]中的所有键值对 rehash 到 ht[1]上面。rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 释放 ht[0] ， 将 ht[1]设置为 ht[0]， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。 渐进式rehash 为 ht[1]分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0]哈希表在 rehashidx索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 将 rehashidx 属性的值增一。 ht[0]的所有键值对被 rehash 至 ht[1]后， 将 rehashidx属性的值设为 -1 ， 表示 rehash 操作已完成。 在渐进式 rehash 进行期间， 字典的删除、查找、更新等操作会在两个哈希表上进行。新添加的键值对一律会被保存到 ht[1] 里面。 整数集合 用于保存整数值的数据结构。 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。 每个整数集合包含了编码方式，元素个数，保存元素的数组。 快速列表quicklist quicklist(快速列表)是 ziplist 和 linkedlist 的结合体。 typedef struct quicklist { quicklistNode *head; /* 指向双向列表的表头 */ quicklistNode *tail; /* 指向双向列表的表尾 */ unsigned long count;/* 所有的 ziplist 中一共存了多少个元素 */ unsigned long len; /* 双向链表的长度，node 的数量 */ int fill : 16; unsigned int compress : 16; /* 压缩深度，0:不压缩; */ } quicklist; typedef struct quicklistNode { struct quicklistNode *prev; /* 前一个节点 */ struct quicklistNode *next; /* 后一个节点 */ unsigned char *zl; /* 指向实际的 ziplist */ unsigned int sz; /* 当前 ziplist 占用多少字节 */ unsignedintcount:16;/* 当前ziplist中存储了多少个元素，占16bit*/ unsigned int encoding : 2; //是否采用LZF压缩算法压缩节点 unsigned int recompress : 1; //ziplist是否被解压出来临时使用 } quicklistNode; 数据类型 键空间 Redis 基于数据结构创建了字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象。 Redis 可以在执行命令之前， 根据对象的类型来判断一个对象是否可以执行给定的命令。同时针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率。 Redis 中的每个数据库都由一个 redis.h/redisDb 结构表示。 其中， redisDb 结构的 dict 字典保存了数据库中的所有键值对， 我们将这个字典称为键空间（key space）。 键空间的键也就是数据库的键， 每个键都是一个字符串对象。键空间的值也就是数据库的值，可以是任意一种 Redis 对象。通过 redisObject 来存储 。 typedef struct redisObject { unsigned type:4; // 对象的类型 unsigned encoding; // 编码，具体的数据结构 unsigned lru:LRU_BITS; //对象最后一次被访问的时间，与内存回收有关 int refcount; // 引用计数。 refcount为0的时可以进行垃圾回收了 void *ptr; // 指向对象实际的数据结构的指针 } robj; 字符串 字符串类型的内部编码有三种； int，存储long类型的整数 embstr。存储小于 44 个字节的字符串。通过调用一次内存分配获得一块连续的空间， 依次包含 redisObject和 sdshdr 两个结构。是只读的，在对 embstr 对象进行修改时，先转化为 raw。 raw。存储大于 44 个字节的字符串。调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构。 列表 在早期的版本中，数据量较小时用 ziplist 存储，达到临界值时转换为 linkedlist 进行存储，3.2 版本之后，统一用 quicklist 来存储。quicklist 存储了一个双向链表，每个节点 都是一个 ziplist。 哈希 哈希对象的编码可以是 ziplist 或者 hashtable 。 压缩列表 哈希 编码转换 当哈希对象可以同时满足以下两个条件时，哈希对象使用 ziplist 编码 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节； 哈希对象保存的键值对数量小于 512 个； 集合 集合对象的编码可以是 intset 或者 hashtable 。 使用哈希作为底层实现时，key就是集合的值， value为null 。 intset编码：所有元素都是整数值或者保存的元素数量不超过 512 个 有序集合 有序集合的编码可以是 ziplist 或者 skiplist 。 使用压缩列表时，每个集合元素使用两个压缩列表节点来保存， 第一个节点保存元素的值，第二个节点保存元素的分值。 使用跳跃表时，采用 zset 结构作为底层实现， 一个 zset 结构同时包含一个哈希表和一个跳跃表。这样查找和范围型操作都能快速执行。 使用 压缩列表：元素数量小于 128 个或者所有元素成员的长度都小于 64 字节。 BitMaps Bitmaps 是在字符串类型上面定义的位操作。一个字节由 8 个二进制位组成。 Hyperloglogs 提供了一种不太准确的基数统计方法，比如统计网站的 UV，存在一定的误差。 "},"content/Redis/基本功能.html":{"url":"content/Redis/基本功能.html","title":"基本功能","keywords":"","body":"Memcached对比 Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。Memcached只支持key-value。 在 Redis3.x 版本中，便能支持 cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 由于 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis 持久化机制 RDB RDB 是 Redis 默认的持久化方案。当满足一定条件的时候，会把当前内存中的数据写入磁盘，生成一个快照文件 dump.rdb。RDB文件是一个经过压缩的二进制文件，通过保存数据库中的键值对来记录。 RDB文件的载入会在服务器启动时自动执行，载入RDB时处于阻塞状态。AOF开启时服务器会优先使用AOF文件。 手动创建 save：生成快照的时候会阻塞，不能处理其他命令。 bgsave：通过 fork 操作创建子进程，持久化过程由子进程负责，不会记录 fork 之后后续的命令。服务器进程继续处理命令请求。 自动执行 redis.conf中配置save选项，shutdown 触发，flushall。 Redis服务器的serverCron函数默认执行时会检查save选项设置的条件，如果满足则会执行bgsave命令。 AOF AOF采用日志记录每个写操作，并追加到文中的形式来记录数据库状态。Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据恢复。AOF默认不开启。 AOF实现 AOF持久化实现可以分为命令追加、文件写入、文件同步三个步骤。 命令追加：Redis在执行一完一个写命令后，会将该命令追加到aof_buf缓冲区的末尾。 写入与同步：由于操作系统的缓存机制，AOF 数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。什么时候写入由配置决定 appendfsync everysec配置 说明 no 不执行同步，由操作系统保证来同步 always 表示每次写入都执行同步 everysec 表示每秒执行一次同步， 载入还原 创建一个不带网络连接的伪客户端来执行AOF文件保存的写命令。 从AOF文件中分析并读取出一条写命令 使用伪客户端执行被读出的写命令 一直执行步骤2和3，直到AOF文件中的所有写命令都被处理完毕 AOF重写 为了解决AOF文件体积膨胀问题，Redis 增加了重写机制。当 AOF 文件的大小超过所设定的阈值时，就会启动重写机制。AOF 重写直接读取服务器现有的键值对， 然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换。 AOF后台重写。将AOF重写放到子进程中执行。同时设置一个重写缓冲区，在重写过程中，执行的写命令会放入重写缓冲区中。在重写完成后将重写缓冲区中所有内容写入到新AOF文件。 总结 RDB 非常紧凑，保存了 redis 在某个时间点上的数据集。恢复大数据集的速度比 AOF 快，适合用于进行备份和灾难恢复。 RDB 方式数据没办法做到实时持久化/秒级持久化。 AOF 提供了多种的同步频率，即使使用默认的同步频率每秒同步，Redis 最多也就丢失 1 秒的数据而已。 AOF 文件通常会比 RDF 文件体积更大。 内存回收 内存回收主要分为两类，一类是 key 过期，一类是内存使用达到上限触发内存淘汰。 过期策略 redisDb结构的expires字典保存了数据库中所有键的过期时间，这个字典为过期字典。过期字典的键是一个指针，指向键空间中的某个对象。值是一个UNIX时间戳。 Redis 中同时使用了惰性过期和定期过期两种过期策略。 定时过期（主动淘汰） 每个设置过期时间的 key 都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据。对内存友好，但是会占用大量的 CPU 资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期（被动淘汰） 只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。该策略可以最 大化地节省 CPU 资源，却对内存非常不友好。极端情况可能出现大量的过期 key 没有再 次被访问，从而不会被清除，占用大量内存。 定期过期 每隔一定的时间，会扫描expires 字典中一定数量的 key，并清除其中已过期的 key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和 每次扫描的限定耗时，可以在不同情况下使得 CPU 和内存资源达到最优的平衡效果。 淘汰策略 Redis 的内存淘汰策略，是指当内存使用达到最大内存极限时，需要使用淘汰算法来 决定清理掉哪些数据，以保证新数据的存入。 LRU LRU，Least Recently Used。最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。 Redis LRU 对传统的 LRU 算法进行了改良，通过随机采样来调整算法的精度。 如果淘汰策略是 LRU，则根据配置的采样值 maxmemory_samples(默认是 5 个)，随机从数据库中选择 m 个 key， 淘汰其中热度最低的 key 对应的缓存数据。所以采样参数m配置的数值越大, 就越能精确的查找到待淘汰的缓存数据，但是也消耗更多的CPU计算，执行效率降低。 Redis 中所有对象结构都有一个 lru 字段, 对象被读写会记录 lru 值。设置为全局变量 server.lruclock 的值。默认每 100 毫秒调用函数更新一次全局变量的 server.lruclock 。 传统的LRU使用哈希表+双向链表的方式实现，需要额外的数据结构，消耗资源。同时访问次数多的可能因为访问时间晚会被先回收。 LFU lru 字段用作 LFU 时， 高16位用来记录访问时间，低8位用来记录访问频率。对象被读写的时候，lfu 的值会被更新。 访问频率是用基于概率的对数计数器实现的，8 位可以表示百万次的访问频率。减少的值由衰减因子 lfu-decay-time(分钟)来控制，如果值是 1 的话，N 分钟没有访问就要减少。 事务 Redis 的事务有两个特点：按进入队列的顺序执行。不会受到其他客户端的请求的影响。 Redis 的事务涉及到四个命令：multi(开启事务)，exec(执行事务)，discard (取消事务)，watch(监视)。 我们可以用 watch 监视一个或者多个 key，如果开启事务之后，至少有一个被监视 key 键在 exec 执行之前被修改了， 那么整个事务都会被取消(key 提前过期除外)。可以用 unwatch 取消。 事务执行遇到的问题分成两种，一种是在执行 exec 之前发生错误，一种是在执行 exec 之后发生错误。 在执行 exec 之前发生错误，比如入队的命令存在语法错误，包括参数数量，参数名等等编译器错误，在这种情况下事务会被拒绝执行，也就是队列中所有的命令都不会得到执行。 在执行 exec 之后发生错误，比如，类型错误，比如对 String 使用了 Hash 的命令等运行时错误，这种发生了运行时异常的情况下， 只有错误的命令没有被执行，但是其他命令没有受到影响。 Redis 的这种事务机制不能用来实现原子性，保证数据的一致。 事件 Redis 基于Reactor 模式开发了自己的网络事件处理器： 这个处理器被称为文件事件处理器。文件事件处理器由套接字、 I/O 多路复用程序、 文件事件分派器以及事件处理器四部分组成。 文件事件是对套接字操作的抽象， 每当一个套接字准备好执行连接应答、写入、读取、关闭等操作时， 就会产生一个文件事件。 I/O 多路复用程序负责监听多个套接字， 将所有产生事件的套接字都入队到一个队列里面， 然后通过这个队列向文件事件分派器传送套接字。 文件事件分派器接收 I/O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。这些处理器是一个个函数， 它们定义了某个事件发生时， 服务器应该执行的动作。 I/O多路复用 在select/poll时代，服务器进程每次都把所有连接告诉操作系统(从用户态复制句柄数据结构到内核态)。让操作系统内核去查询这些套接字(socket)上是否有事件发生，轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只 能处理几千的并发连接。 redis利用epoll来实现IO多路复用。epoll是poll的一种优化 。 epoll会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。 "},"content/Redis/集群.html":{"url":"content/Redis/集群.html","title":"集群","keywords":"","body":"主从复制 配置 从节点不能写入数据(只读)，只能从 master 节点同步数据。 每个 slave 节点的 redis.conf 配置文件增加一行 slaveof 192.168.8.203 6379 原理 连接阶段 slave node 启动时(执行 slaveof 命令)，会在自己本地保存 master node 的信息。同时跟 master node 建立 socket 网络连接，如果连接成功，从节点为该 socket 建立一个专门处理复制工作的文件 事件处理器，负责后续的复制工作，如接收 RDB 文件、接收命令传播等。 slave node 内部有个定时任务每隔一秒钟检查是否有新的 master node 要连接和复制。当从节点变成了主节点的一个客户端之后，会给主节点发送 ping 请求。 数据同步阶段 完整重同步 通过 bgsave 命令在本地生成一份 RDB快照，将RDB快照文件发给slave node。 slave node 首先清除自己的旧数据，然后用 RDB 文件加载数据。开始生成 RDB 文件时，master 会把所有新的写命令缓存在内存中。在 slave node保存了RDB之后，再将新的写命令复制给 slave node。 部分重同步 主服务器和从服务器会分别维护一个复制偏移量。同时主服务器进行命令传播时还会将命令写入复制积压缓冲区中。 如果从服务器的复制偏移量仍然存在于复制积压缓冲区中，执行部分重同步，否则执行完整重同步。 命令传播 master node 持续将写命令，异步复制给 slave node。 缺点 主从模式解决了数据备份和性能(通过读写分离)的问题。但是RDB文件过大时同步非常耗时。如果主服务器挂了，对外提供的服务就不可用了，单点问题没有得到解决。 Sentinel哨兵 Sentinel可以监视任意多个主服务器，并在主服务器下线时自动将下线主服务器下的某个从服务器升级为新的主服务器。 同时Sentinel之间也互相监控。Sentinel本质上是一个运行在特殊模式之下的 Redis。 Sentinel初始化 redis-sentinel /path/to/your/sentinel.conf启动服务，将服务中代码替换成Sentinel专有代码。初始化Sentinel状态 根据给定的配置文件， 初始化 Sentinel 的监视主服务器列表。创建命令连接和订阅连接。通过INFO命令获取主服务器和从服务器的信息 通过接收其他Sentinel发送的信息，更新其他Sentinel信息。 故障转移 服务下线 Sentinel 默认以每秒钟 1 次的频率向 Redis 服务节点发送 PING 命令。如果在 down-after-milliseconds 内都没有收到有效回复，Sentinel 会将该服务器标记为下线。 这个时候 Sentinel 节点会继续询问其他的 Sentinel 节点，确认这个节点是否下线， 如果多数 Sentinel 节点都认为 master 下线，master 才真正确认被下线(客观下线)， 这个时候就需要重新选举 master。 Sential选举 Sentinle 通过 Raft 算法，实现 Sentinel 选举。Raft 的核心思想是先到先得，少数服从多数。步骤如下： Sentinel要求其他Sentinel将自己设置为局部领头Sentinel。即向目标Sentinel发送命令，包含自身的runID 目标Sentinel将最先发送命令的Sentinel设置为局部领头Sentinel，并回复leader_runid参数和leader_epoch。 源Sentinel在接收到命令回复之后，检查配置纪元和运行ID一致，如果相同表示目标 Sentinel将自己设置成了局部领头Sentinel。 如果某个Sentinel被半数以上的Sentinel设置成了局部领头Sentinel，那么这个Sentinel成为领头Sentinel。 如果在给定时限内，没有一个Sentinel被选举为领头Sentinel，那么各个Sentinel将在一段时间之后再次进行选举，直到选出领头Sentinel。 故障转移 选出 Sentinel Leader 之后，由 Sentinel Leader 向某个节点发送 slaveof no one 命令，让它成为主服务器。 向其他节点发送slaveof 命令去复制新的主服务器 将旧的主服务器变为从服务器。 主节点选举，一共有四个因素影响选举的结果，分别是断开连接时长、优先级排序、复制偏移量、进程 id。 缺点 主从切换的过程中会丢失数据，因为只有一个 master。 只能单点写，没有解决水平扩容的问题。 Redis Cluster 数据结构 clusterNode 结构保存了一个节点的当前状态， 比如节点的创建时间， 节点的名字，节点当前的配置纪元，节点的IP和地址。每个节点都会使用一个 clusterNode 结构来记录自己的状态， 并为集群中的所有其他节点（包括主节点和从节点）都创建一个相应的 clusterNode 结构。 每个节点都保存着一个 clusterState 结构， 这个结构记录了在当前节点的视角下， 集群目前所处的状态 —— 比如集群是在线还是下线， 集群包含多少个节点， 集群当前的配置纪元 槽（slot） 集群的整个数据库被分为16384个槽（slot），数据库中的每个键都属于其中一个槽。如果数据库中有任何一个槽没有得到处理，集群就处于下线状态。 Redis集群通过clusterState结构中的slots数组属性记录槽指派信息。slots数组包含18365个项，每一项都是一个指向clusterNode结构的指针。 clusterNode结构的slots属性和numslot属性记录了自己负责处理哪些槽。其中slots属性是二进制数组，长度是16384个二进制位。每个二进制位都代表一个槽位置，根据对应索引上的二进制为的值来判断节点是否处理该槽（0表示不处理，1表示处理）。节点会将自己的slots数组发送给其他节点来通知其他节点自己负责处理哪些槽。 节点利用跳跃表来保存槽和键之间的关系。跳跃表每个节点的分值都是一个槽号，每个节点的成员都是一个数据库键。 对象分布到 Redis 节点上时，对 key 用 CRC16 算法计算再%16384，得到一个 slot 的值，数据落到负责这个 slot 的 Redis 节点上。在 key 里面加入{hash tag}即可让某些数据分布到一个节点上。 重新分片 因为 key 和 slot 的关系是永远不会变的，当新增了节点的时候，需要把原有的 slot 分配给新的节点负责，并且把相关的数据迁移过来。 重新分片由redis-trib负责执行，redis向源节点和目标节点发送命令来进行重新分片。 复制 向一个节点发送 cluser replicae ，成为node_id所指定节点的从节点。然后进行主从复制。 故障转移 服务下线 集群中每个节点会定期的向集群中的其他节点发送PING消息，如果没有在规定时间内返回PONG消息，那么节点会被标记为疑似下线。 半数以上的主节点都将某个主节点标记为疑似下线，那么这个主节点将会被标记为已下线，并且会通过集群广播的方式发送主节点X被FAIL的消息，所有收到消息的节点都会将主节点X标记为已下线。 故障转移 Master选举 "},"content/Redis/应用.html":{"url":"content/Redis/应用.html","title":"应用","keywords":"","body":"缓存 缓存雪崩 缓存雪崩就是 Redis 的大量热点数据同时过期(失效)，因为设置了相同的过期时 间，刚好这个时候 Redis 请求的并发量又很大，就会导致所有的请求落到数据库。 解决方案： 加互斥锁或者使用队列，针对同一个 key 只允许一个线程到数据库查询 缓存定时预先更新，避免同时失效 通过加随机数，使 key 在不同的时间过期 缓存永不过期 缓存穿透 缓存穿透是指查询一个根本不存在的数据， 导致每次请求都要到存储层去查询。 解决方案： 缓存空对象 布隆过滤器 布隆过滤器 布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。 向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash。得到一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就 完成了 add 操作。 向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位 置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在 缓存击穿 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，大并发的请求可能会瞬间把后端DB压垮。 用分布式锁控制访问的线程。 缓存一致性 解决方案一： 先删除缓存，再操作数据库。操作数据库成功之后再删除缓存。 如果是主从数据库，使用从库binlog删除，一主多从，每个从库都要采集binlog，消费端收到最后一个binlog才删除缓存。 解决方案二： 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 分布式锁 Redission实现 RLock lock = Redisson.get(\"myLock\"); lock.lock(); lock.unlock(); 使用Lua脚本进行加锁。如果锁不存在，hset myLock \"客户端id\" ：重入次数。接着设置锁过期时间。如果锁存在，则比较客户端id，不包含则返回剩余生存时间。 watch dog启动一个后台线程，每隔10秒检查客户端是否还持有锁，会不断延长锁的时间。 RedLock RedLock 的思想是使用多台 Redis Master ，节点完全独立，节点间不需要进行数据同步，因为 Master-Slave 架构一旦 Master 发生故障时数据没有复制到 Slave，被选为 Master 的 Slave 就丢掉了锁，另一个客户端就可以再次拿到锁。锁通过 setNX（原子操作） 命令设置，在有效时间内当获得锁的数量大于 (n/2+1) 代表成功，失败后需要向所有节点发送释放锁的消息。 高并发优化 分布式锁的方案在高并发场景下，分布式锁一旦加了之后，对同一个商品的下单请求，会导致所有客户端都必须对同一个商品的库存锁key进行加锁。可以分段加锁，将库存拆成多个库存段，类似stock_01，stock_02。用随机算法，将请求随机在20个分段库存里，选择一个进行加锁。 redis 分布式锁和 zk 分布式锁的对比 redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。 zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。 另外一点就是，如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。 redis 分布式锁麻烦，遍历上锁，计算时间等等。zk 的分布式锁语义清晰实现简单。 "},"content/Dubbo/基本概念及使用.html":{"url":"content/Dubbo/基本概念及使用.html","title":"基本概念及使用","keywords":"","body":"Dubbo架构 负载均衡 随机权重 权重随机算法，根据权重值进行随机负载。 最少活跃调用 活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求。每个服务提供者对应一个活跃数 active。初始情况下，所有服务提供者活跃数均为 0。 每收到一个请求，活跃数加 1，完成请求后则将活跃数减 1。 hash一致性 hash 一致性算法，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者， 不会引起剧烈变动。 加权轮询 经过加权后，每台服务器能够得到的请求数比例，接近他们的权重比。 集群容错 Failover Cluster 缺省为 failover 重试。失败自动切换，当出现失败，重试其它服务器。可通过 retries=\"2\" 来设置重试次数(不含第一次)。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。 通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 可通过 forks=\"2\" 来设置最大并行数。 服务降级 当某个非关键服务出现错误时，可以通过降级功能来临时屏蔽这个服务。降级可以有几个层面的分类: 自动降级和人工降级; 按照功能可以分为:读服务降级和写服务降级。 对一些非核心服务进行人工降级，在大促之前通过降级开关关闭哪些推荐内容、评 价等对主流程没有影响的功能 故障降级，比如调用的远程服务挂了，网络故障、或者 RPC 服务返回异常。 那么可以直接降级，降级的方案比如设置默认值、兜底数据。 限流降级，流量特别大的情况下，因为突发访问量特别大可能会导致系统支撑不了。可以采用限流来限制访问量。当达到阀值时，后续的请求被降级，比如进入排队页面，比如跳转到错误页。 服务降级策略分为两种，mock=force:return+null，mock=fail:return+null。 mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。 @Reference( loadbalance = \"random\", mock = \"com.springboot.practice.springbootdubboclient.MockSayHelloService\", timeout =1000, cluster = \"failfast\") IHelloService helloService; 启动时检查 Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认check=\"true\"。可以通过 check=\"false\" 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。 多版本支持 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。 Dubbo配置 服务端配置客户端来使用。其参数传递机制是服务端所有配置都会封装到URL参数，在通过注册中心传递到客户端。 超时总共有6处可以配置。如果6处都配置了不同的值，最后肯定只会有一个超时值生效，其优先级如下： 异步调用 异步调用是指发起远程调用之后获取结果的方式。 请求分为三种类型。同步等待结果返回(默认)。异步等待结果返回。不需要返回结果。Dubbo 中关于异步等待结果返回的实现流程如下图： //配置如下 //*异步调用结果获取Demo* demoService.sayHello1(\"han\"); Future future1 = RpcContext.getContext().getFuture(); demoService.sayHello2(\"han2\"); Future future2 = RpcContext.getContext().getFuture(); Object r1 = null, r2 = null; // wait 直到拿到结果或超时 r1 = future1.get(); // wait 直到拿到结果或超时 r2 = future2.get(); 性能调优相关参数 1、当consumer发起一个请求时，首先经过active limit(参数actives)进行方法级别的限制，其实现方式为CHM中存放计数器(AtomicInteger)，请求时加1，请求完成(包括异常)减1,如果超过actives则等 待有其他请求完成后重试或者超时后失败。 2、从多个连接(connections)中选择一个连接发送数据，对于默认的netty实现来说，由于可以复用连接，默认一个连接就可以。不过如果你在压测，且只有一个consumer,一个provider，此时适当的加大 connections确实能够增强网络传输能力。但线上业务由于有多个consumer多个provider，因此不建议增加connections参数。 3、连接到达provider时(如dubbo的初次连接)，首先会判断总连接数是否超限(acceps)，超过限制连接将被拒绝。 4、连接成功后，具体的请求交给io thread处理。io threads虽然是处理数据的读写，但io部分为异步， 更多的消耗的是cpu，因此iothreads默认cpu个数+1是比较合理的设置，不建议调整此参数。 5、数据读取并反序列化以后，交给业务线程池处理，默认情况下线程池为fixed，且排队队列为 0(queues)，这种情况下，最大并发等于业务线程池大小(threads)，如果希望有请求的堆积能力，可以调整queues参数。如果希望快速失败由其他节点处理(官方推荐方式)，则不修改queues，只调整 threads。 6、execute limit(参数executes)是方法级别的并发限制，原理与actives类似，只是少了等待的过 程，即受限后立即失败。 优雅下线 为了实现优雅停机，Dubbo 需要解决一些问题：新的请求不能再发往正在停机的 Dubbo 服务提供者。若关闭服务提供者，已经接收到服务请求，需要处理完毕才能下线服务。若关闭服务消费者，已经发出的服务请求，需要等待响应返回。 我们服务下线过程中，AbstractConfig中的DubboShutdownHook，是JVM退出时的钩子线程，会在JVM退出之前执行。 以 ZK 为例，Dubbo 将会删除其对应服务节点，然后取消订阅。由于 ZK 节点信息变更，ZK 服务端将会通知 dubbo 消费者下线该服务节点，最后再关闭服务与 ZK 连接。通过注册中心，Dubbo 可以及时通知消费者下线服务，新的请求也不再发往下线的节点，也就解决上面提到的第一个问题：新的请求不能再发往正在停机的 Dubbo 服务提供者。注销Protocol，首先关闭 Server ，停止接收新的请求，然后再关闭 Client。 2.7.X 版本新增 ShutdownHookListener，继承 Spring ApplicationListener 接口，用以监听 Spring 相关事件。这里 ShutdownHookListener 仅仅监听 Spring 关闭事件，当 Spring 开始关闭，将会触发 ShutdownHookListener 内部逻辑。 序列化 dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。 Hessian 的对象序列化机制有 8 种原始类型：boolean、 int、string。3 种递归类型：lists and arrays、maps 、object ，ref：用来表示对共享对象的引用。 "},"content/Dubbo/SPI.html":{"url":"content/Dubbo/SPI.html","title":"Dubbo SPI","keywords":"","body":"SPI spi，简单来说，就是 service provider interface，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要根据指定的配置或者是默认的配置，去找到对应的实现类加载进来，然后用这个实现类的实例对象。 举个栗子。 你有一个接口 A。A1/A2/A3 分别是接口A的不同实现。你通过配置 接口 A = 实现 A2，那么在系统实际运行的时候，会加载你的配置，用实现 A2 实例化一个对象来提供服务。 spi 机制一般用在哪儿？插件扩展的场景，比如说你开发了一个给别人使用的开源框架，如果你想让别人自己写个插件，插到你的开源框架里面，从而扩展某个功能，这个时候 spi 思想就用上了。 Java SPI 需要在 classpath 下创建一个目录，该目录命名必须是:META-INF/service 在该目录下创建一个 properties 文件，文件名是扩展的接口的全路径名称，文件内部描述的是该扩展接口的所有实现类 通过 java.util.ServiceLoader 的加载机制来发现 缺点 JDK 标准的 SPI 会一次性加载实例化扩展点的所有实现，有的扩展点初始化很耗时或者如果有些实现类并没有用到， 会很浪费资源。 如果扩展点加载失败，会导致调用方报错，而且这个错误很难定位。 获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 Dubbo SPI 能够被扩展的接口，必须要有@SPI()，Dubbo自定义的注解 @SPI(\"value\") ， 表示当前扩展点的默认实现 静态扩展点 需要在 resource 目录下配置 META-INF/dubbo 或者 META-INF/dubbo/internal 或者 META-INF/services，并基于 SPI 接口去创建一个文件。 文件名称和接口名称保持一致，文件内容和 SPI 有差异，内容是 KEY 对应 Value 调用 ExtensionLoader.getExtensionLoader(xxx.class).getExtension(\"\"); @SPI注解，被此注解标记的接口，就表示是一个可扩展的接口，并标注默认值 实现原理 Adaptive 自适应扩展点 @Adaptive。是一个自适应扩展点的标识。它可以修饰在类上，也可以修饰在方法上面。 放在类上，说明当前类是一个确定的自适应扩展点的类。如果是放在方法级别，那么需要生成一个动态字节码（使用javassi），来进行转发。 比如Protocol 这个接口，定义了 export 和 refer 两个抽象方法，这两个方法分别带有@Adaptive 的标识，标识是一个自适应方法。实现取决于在使用 dubbo 的时候所配置的协议名称。方法层面的 Adaptive 就决定了当前这个方法会采用何种协议来发布服务。 Compiler compiler=ExtensionLoader.getExtensionLoader(Compiler.class).getAdaptiveExtension(); //我们传入一个 Compiler 接口，它会返回一个 AdaptiveCompiler。这个就叫自适应。 实现原理 getAdaptiveExtension()--> createAdaptiveExtension()--> getAdaptiveExtensionClass()--> getExtensionClasses()--> loadExtensionClasses() public T getAdaptiveExtension() { //获取 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { //创建自适应扩展 instance = createAdaptiveExtension(); //设置缓存 cachedAdaptiveInstance.set(instance); } return (T) instance; } private T createAdaptiveExtension() { //获取自适应扩展类，通过反射实例化 ，实现依赖注入 return injectExtension((T) gtAdaptiveExtensionClass().newInstance()); } private Class getAdaptiveExtensionClass() { //getExtensionClasses->loadFile直接从配置文件中解析加载 //会加载当前传入的类型的所有扩展点，保存在一个 hashmap 中 getExtensionClasses(); //如果缓存中已经找到自适应类的话直接返回，意思也就是这个spi有 //aptive的注解类 if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } //否则需要代理类生成相关代理 return cachedAdaptiveClass = createAdaptiveExtensionClass(); } private Class createAdaptiveExtensionClass() { //具体就是生成代理类 String code = createAdaptiveExtensionClassCode(); ClassLoader classLoader = findClassLoader(); com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.com piler.Compiler.class).getAdaptiveExtension(); //来编译上面生成的类并返回 return compiler.compile(code, classLoader); } 激活拓展点 自动激活扩展点，类似springboot 的时候用到的 conditional，根据条件进行自动激活。但是这里设计的初衷是，对于一个类会加载多个扩展点的实现，这个时候可以通过自动激活扩展点进行动态加载， 从而简化配置我们的配置工作 @Activate 提供了一些配置来允许我们配置加载条件，比如 group 过滤，比如 key 过滤。 group 表示客户端和和服务端都会加载，value 表示 url 中有 cache_key 的时候。 "},"content/Dubbo/服务发布和注册源码.html":{"url":"content/Dubbo/服务发布和注册源码.html","title":"服务发布及注册","keywords":"","body":"服务发布过程 配置文件解析或者注解解析 服务暴露 服务注册 启动 netty 服务实现远程监听 解析配置文件 Spring通过两个接口来解析自定义的标签。NamespaceHandler，注册一堆 BeanDefinitionParser。BeanDefinitionParser，用于解析每个 element 的内容。 spring框架初始化时会扫描所有classpath的spring.handlers文件，加载NamespaceHandler到Map中。Spring在解析自定义的标签的时候，会在这个Map中查找对应NamespaceHandler进行解析工作。 dubbo定义了DubboNamespaceHandler ，继承了NamespaceHandlerSupport。不需要实现所有的解析工作，只要将自定义schema中的元素解析器注册进来就可以。 DubboBeanDefinitionParser类去解析标签，每个标签会解析到对应的实体上，每个实体中的属性对应标签中的属性。 涉及到服务发布和服务调用的两个配置的解析，使用的是 ServiceBean 和 referenceBean ServiceBean解析 在 ServiceBean 中，我们暂且只需要关注两个方法，分别是 在初始化 bean 的时候会执行该方法 afterPropertiesSet, spring 容器启动后会发一个事件通知 onApplicationEvent afterPropertiesSet 这个方法里面，就是把 dubbo 中配置的 application、registry、service、protocol 等信息，加载到对应的 config 实体中，便于后续的使用。 onApplicationEvent spring 容器启动之后，会收到一个这样的事件通知，这里面做了两个事情。 判断服务是否已经发布过。如果没有发布，则调用 export 进行服务发布的流程(这里就是入口)。 public void onApplicationEvent(ContextRefreshedEvent event) { if (!isExported() && !isUnexported()) { if (logger.isInfoEnabled()){ logger.info(\"The service ready on spring started. service: \" + getInterface()); } export(); } } 服务暴露 export() serviceBean 中，重写了 export 方法，实现了 一个事件的发布。并且调用了 super.export() ，也就是会调用父类的 export 方法。调用ServiceConfig.export()。 public synchronized void export() { checkAndUpdateSubConfigs(); //检查并且更新配置信息 if (!shouldExport()) { //当前的服务是否需要发布, 通过配置实现:@Service(export = false) return; } if (shouldDelay()) { //检查是否需要延时发布,@Service(delay=)实现，通过定时器来实现 delayExportExecutor.schedule(this::doExport, getDelay(), TimeUnit.MILLISECONDS); } else { doExport(); //如果没有配置 delay，则直接调用 export 进行发布 } } //这里仍然还是在实现发布前的各种判断 protected synchronized void doExport() { //前面各种判断 doExportUrls(); } doExportUrls() 最终调用doExportUrls()，加载所有配置的注册中心地址，遍历所有配置的协议protocols，针对每种协议发布一个对应协议的服务。 private void doExportUrls() { //加载所有配置的注册中心的地址，组装成一个URL //(registry://ip:port/org.apache.dubbo.registry.RegistryService List registryURLs = loadRegistries(true); for (ProtocolConfig protocolConfig : protocols) { doExportUrlsFor1Protocol(protocolConfig, registryURLs); } } doExportUrlsFor1Protocol() 把配置的参数进行解析，保存到 map 集合中 获得当前服务需要暴露的 ip 和端口 把解析到的所有数据，组装成一个 URL，大概应该是: dubbo://192.168.13.1:20881/ISayHelloService private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List registryURLs) { //获得当前服务要发布的目标 ip 和 port //组装 URL，url地址包含了版本号，接口名，方法列表，序列化方法，过期时间 URL url = new URL(name, host, port, getContextPath(protocolConfig).map(p -> p + \"/\" + path).orElse(path), map); String scope = url.getParameter(SCOPE_KEY); if (!SCOPE_NONE.equalsIgnoreCase(scope)) { //injvm 发布到本地 if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) { exportLocal(url); } //发布远程服务 if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) { for (URL registryURL : registryURLs) { //Invoker 是一个代理类，代表一个可执行体，可向它发起invoke 调 //用 Invoker invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded (EXPORT_KEY, url.toFullString())); //对 invoker 做了委托，把 invoker 交给 //DelegateProviderMetaDataInvoker 来处理 DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); //调用 protocol.export(invoker)来发布这个代理 Exporter exporter = protocol.export(wrapperInvoker); //添加到 exporters 集合 exporters.add(exporter); } } } protocol.export 它是一个自适应扩展点，一个在方法层面上的自适应扩展，意味着它实现了对于 export 这个方法的适配。Protocol 是一个动态代理类，会根据 url 中配置的 protocol name 来实现对应协议的适配。当前的场景中，protocol 会是调用谁呢?目前发布的 invoker(URL)，实际上是一个 registry://协议，所以 Protocol$Adaptive，会通过 getExtension(extName)得到一个 RegistryProtocol RegistryProtocol.export RegistryProtocol 是用来实现服务注册的。实现对应协议的服务发布。实现服务注册。实现订阅服务重写。 public Exporter export(final Invoker originInvoker) throws RpcException { //这里获得的是 zookeeper 注册中心的 url: zookeeper://ip:port URL registryUrl = getRegistryUrl(originInvoker); //这里是获得服务提供者的 url, dubbo://ip:port... URL providerUrl = getProviderUrl(originInvoker); //这里就交给了具体的协议去暴露服务(很重要) final ExporterChangeableWrapper exporter = doLocalExport(originInvoker, providerUrl); //===========下面是服务注册的代码============= // 根据 invoker 中的url获取Registry实例: zookeeperRegistry final Registry registry = getRegistry(originInvoker); //获取要注册到注册中心的 URL: dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper providerInvokerWrapper = ProviderConsumerRegTable.registerProvider( originInvoker,registryUrl, registeredProviderUrl); boolean register = registeredProviderUrl.getParameter(\"register\", true); if (register) { //是否配置了注册中心，如果是， 则需要注册 //注册到注册中心的 URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); } //设置注册中心的订阅 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); //保证每次 export 都返回一个新的 exporter 实例 return new DestroyableExporter<>(exporter); } doLocalExport 先通过 doLocalExport 来暴露一个服务，本质上应该是启动一个通信服务,主要的步骤是将本地 ip 和端口打开，进行监听. private ExporterChangeableWrapper doLocalExport(final Invoker originInvoker, URL providerUrl) { //originInvoker 中获得发布协议的 url:dubbo://ip:port/... String key = getCacheKey(originInvoker); return (ExporterChangeableWrapper) //bounds: 一个 prviderUrl 服务 export 之后，缓存到 bounds 中， //所以一个 providerUrl 只会对应一个 exporter bounds.computeIfAbsent(key, s -> { //对原有的 invoker,委托给了 InvokerDelegate Invoker invokerDelegate = new InvokerDelegate<> (originInvoker, providerUrl); return new ExporterChangeableWrapper<>((Exporter) protocol.export(invokerDelegate), originInvoker); }); } DubboProtocol.export 基于动态代理的适配，过渡到了 DubboProtocol 这个协议类。 同时Wrapper 对 Protocol 进行装饰，装饰器分别为: QosProtocolWrapper。如果当前配置了注册中心，则会启动一个 Qos server.qos 是 dubbo 的在线运维命令 ProtocolListenerWrapper ProtocolFilterWrapper。使用责任链模式，对 invoker 进行 filter 的包装，实现请求的过滤。 public Exporter export(Invoker invoker) { URL url = invoker.getUrl(); //获取服务标识，由服务组名，服务名，服务版本号以及端口组成。比如 //${group}/ISayHelloService:${version}:20880 String key = serviceKey(url); //创建 DubboExporter DubboExporter exporter = new DubboExporter(invoker, key, exporterMap); // 将 键值对放入缓存中 exporterMap.put(key, exporter); //启动服务 openServer(url); //优化序列化 optimizeSerialization(url); return exporter; } openServer() 去开启一个服务，并且放入到缓存中 ，同一个端口上仅允许启动一个服务器实例。 private void openServer(URL url) { // 获取 host:port，并将其作为服务器实例的key，用于标识当前的服务器实例 String key = url.getAddress(); //client 也可以暴露一个只有 server 可以调用的服务 boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true); if (isServer) { //是否在 serverMap 中缓存了 ExchangeServer server = serverMap.get(key); if (server == null) { synchronized (this) { server = serverMap.get(key); if (server == null) { // 创建服务器实例 serverMap.put(key, createServer(url)); } } } else { //服务器已创建，则根据 url 中的配置重置服务器 server.reset(url); } } } createServer() 创建服务,开启心跳检测，默认使用 netty。组装 url. private ExchangeServer createServer(URL url) { //组装 url，在 url 中添加心跳时间、编解码参数 url = URLBuilder.from(url) // 当服务关闭以后，发送一个只读的事件，默认是开启状态 .addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY,Boolean.TRUE.toString()) // 启动心跳配置 .addParameterIfAbsent(Constants.HEARTBEAT_KEY,String.valueOf(Constants.DEFAULT_HEARTBEAT)) .addParameter(Constants.CODEC_KEY, DubboCodec.NAME) .build(); String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); //通过 SPI 检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常 if (str != null && str.length() > 0 && !ExtensionLoader.getExtensionLoader(Transporter.class).hasExten sion(str)) { throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url); } //创建 ExchangeServer. ExchangeServer server; try { server = Exchangers.bind(url, requestHandler); } catch (RemotingException e) { throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); } //Exchangers.bind public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } if (handler == null) { throw new IllegalArgumentException(\"handler == null\"); } //获取 Exchanger，默认为 HeaderExchanger。 //调用 HeaderExchanger 的 bind 方法创建 ExchangeServer 实例 url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).bind(url, handler); } headerExchanger.bind 这里面包含多个逻辑 new DecodeHandler(new HeaderExchangeHandler(handler)) Transporters.bind new HeaderExchangeServer public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(han dler)))); } //Transporters.bind public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } if (handlers == null || handlers.length == 0) { throw new IllegalArgumentException(\"handlers == null\"); } ChannelHandler handler; if (handlers.length == 1) { handler = handlers[0]; } else { // 如果 handlers 元素数量大于1，则创建 ChannelHandler 分发器 handler = new ChannelHandlerDispatcher(handlers); } // 获取自适应 Transporter 实例，并调用实例方法 return getTransporter().bind(url, handler); } getTransporter getTransporter 是一个自适应扩展点，它针对 bind 方法添加了自适应注解，意味着bind 方法的具体实现，会基于 Transporter$Adaptive 方法进行适配，这里面默认的通信协议是 netty，所以它会采用 netty4 的实现，也就是 org.apache.dubbo.remoting.transport.netty4.NettyTransporter public static Transporter getTransporter() { return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension(); } //NettyTransporter.bind //创建一个 nettyserver public Server bind(URL url, ChannelHandler listener) throws RemotingException { return new NettyServer(url, listener); } NettyServer 初始化一个 nettyserver，并且从 url 中获得相应的 ip/ port。然后调用 doOpen()。doOpen()是服务发布的最终逻辑。 protected void doOpen() throws Throwable { bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(\"NettyServerBoss\", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants. DEFAULT_IO_THREADS), new DefaultThreadFactory(\"NettyServerWorker\", true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer() { @Override protected void initChannel(NioSocketChannel ch) throws Exception { // FIXME: should we use getTimeout()? int idleTimeout = UrlUtils.getIdleTimeout(getUrl()); NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(\"logging\",new LoggingHandler(LogLevel.INFO))//for debug .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) .addLast(\"server-idle-handler\", new IdleStateHandler(0, 0, idleTimeout, MILLISECONDS)) .addLast(\"handler\", nettyServerHandler); } }); //bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); } 这里用到了一个handler来处理客户端传递过来的请求。nettyServerHandler，这个 handler 是一个链路，它的正确组成应该是 MultiMessageHandler(heartbeatHandler(AllChannelHandler(DecodeHandler(HeaderExchangeHeadler(dubboProtocol 后续接收到的请求，会一层一层的处理。 总结 一个service标签的serviceBean生成了一个代理好的Invoker，这个invoker放在一个叫exporter的对象下，然后这个exporter放在了serviceBean的一个exporterMap中，准备被调用。然后创建的nettyServer放在了serviceBean的变量protocol下的一个变量serverMap里面，这样一个serverBean的netty服务，方法代理类都生成好了。注意protocol是单例生成的，所以如果有bean打开过nettyServer，别的bean就不会再打开。 服务注册 从protocol.export()中抽离服务注册的代码 final Registry registry = getRegistry(originInvoker); //获取要注册到注册中心的 URL: dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper providerInvokerWrapper = ProviderConsumerRegTable.registerProvider( originInvoker,registryUrl, registeredProviderUrl); boolean register = registeredProviderUrl.getParameter(\"register\", true); if (register) { //是否配置了注册中心，如果是， 则需要注册 //注册到注册中心的 URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); } 服务注册流程 >getRegistry //获得指定的注册中心实现 >ZookeeperRegistryFactory#getRegistry// >createRegistry// 创建注册中心 >ZookeeperRegistry//CuratorZookeeperTransport实现zk的连接 > register// 服务注册 >registry.register // >FailbackRegistry.register//失败重试注册 >ZookeeperRegistry.doRegister //调用curator服务地址注册到zk getRegistry 把url转化为对应配置的注册中心的具体协议 根据具体协议，从registryFactory中获得指定的注册中心实现 private Registry getRegistry(final Invoker originInvoker) { //把url转化为配置的具体协议，比如zookeeper://ip:port. 这样后续获得的注册中心就会是基于zk的实现 URL registryUrl = getRegistryUrl(originInvoker); return registryFactory.getRegistry(registryUrl); } 根据RegistryFactory的实现，getRegistry是一个自适应的方法，根据url中protocol传入的值进行适配。由于在前面的代码中，url中的protocol已经改成了zookeeper，那么这个时候根据zookeeper获得的spi 扩展点应该是ZookeeperRegistryFactory。 ZookeeperRegistryFactory 这个方法中并没有 getRegistry 方法，而是在父类 AbstractRegistryFactory。从缓存 REGISTRIES 中，根据 key 获得对应的 Registry。如果不存在，则创建 Registry。 createRegistry 创建一个 zookeeperRegistry，把 url 和 zookeepertransporter 作为参数传入。zookeeperTransporter 这个属性也是基于依赖注入来赋值的，，这个的值应该是CuratorZookeeperTransporter，表示具体使用什么框架来和 zk 产生连接。 register public void register(URL registryUrl, URL registeredProviderUrl) { Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl); } registry.register 将 dubbo://的协议地址注册到 zookeeper 上。 这个方法会调用 FailbackRegistry 类中的 register。因ZookeeperRegistry 类中并没有 register 这个方法。其父类FailbackRegistry 中存在 register 方法，而这个类又重写了 AbstractRegistry 类中的 register 方法。可以直接定位到FailbackRegistry 这个类中的 register 方法中。最终调用curator的客户端把服务地址注册到zk Invoker //----- 1.代理工程，用来生成invoker。自适应扩展点，调用JavassisProxyFactory Invoker invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); //----- 2.一个动态类库，用来实现动态代理。构建好了代理类之后，返回一个AbstractproxyInvoker,并且它实现了doInvoke方法。 JavassistProxyFactory.getInvoker Invoke本质上应该是一个代理，经过层层包装最终进行了发布。当消费者发起请求的时候，会获得这个invoker进行调用。 最终发布出去的invoker, 也不是单纯的一个代理，也是经过多层包装 InvokerDelegate(DelegateProviderMetaDataInvoker(AbstractProxyInvoker())) 发布活动图 "},"content/Dubbo/服务消费源码.html":{"url":"content/Dubbo/服务消费源码.html","title":"服务消费","keywords":"","body":"服务消费过程 服务消费主要有以下几个功能：生成远程服务的代理。获得目标服务的url地址。实现远程网络通信。实现负载均衡。实现集群容错。 服务消费者初始化 //消费端的代码解析是从下面这段代码开始的 //注解的方式的初始化入口 ReferenceAnnotationBeanPostProcessor->ReferenceBeanInvocationHandler.init- >ReferenceConfig.get() //获得一个远程代理类 ReferenceConfig.get public synchronized T get() { checkAndUpdateSubConfigs(); //检查和修改配置 if (destroyed) { throw new IllegalStateException; } if (ref == null) { //如果当前接口的远程代理引用为空，则进行初始化 init(); } return ref; } init() 初始化的过程，和服务发布的过程类似，会有特别多的判断以及参数的组装。需要关注 createProxy，创建代理类的方法。map是所有前面相关变量的参数和参数值。 private void init() { //省略... ref = createProxy(map); //省略... } createProxy 判断是否为本地调用，如果是则使用injvm协议进行调用 判断是否为点对点调用，如果是则把url保存到urls集合中，如果url为1，进入步骤4，如果urls>1，则执行5 如果是配置了注册中心，遍历注册中心，把url添加到urls集合，url为1，进入步骤4，如果urls>1，则执行5 直接构建invoker 构建invokers集合，通过cluster合并多个invoker 最后调用 ProxyFactory 生成代理类 private T createProxy(Map map) { //如果只配置了一个注册中心或者一个服务提供者，直接使用refprotocol.refer if (urls.size() == 1) { invoker = refprotocol.refer(interfaceClass, urls.get(0)); } else { List> invokers = new ArrayList>(); URL registryURL = null; for (URL url : urls) { //遍历urls生成多个invoker invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { registryURL = url; // use last registry url } } if (registryURL != null) { //如果registryUrl不为空，构建静态directory // 使用RegistryAwareCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY,RegistryAwareCluster.NAME); // 通过Cluster将多个invoker合并 //RegistryAwareClusterInvoker(StaticDirectory) ->FailoverClusterInvoker(RegistryDirectory, will execute route) -> Invoker } } invoker = cluster.join(new StaticDirectory(u, invokers)); } else { invoker = cluster.join(new StaticDirectory(invokers)); } // create service proxy return (T) proxyFactory.getProxy(invoker); } protocol.refer 这里通过指定的协议来调用refer生成一个invoker对象，invoker是一个代理对象。那么在当前的消费端而言，invoker主要用于执行远程调用。 这个protocol，又是一个自适应扩展点，它得到的是Protocol$Adaptive。根据当前的协议url，得到一个指定的扩展点，传递进来的参数中，协议地址为 registry://，所以，我们可以直接定位到RegistryProtocol.refer代码。 RegistryProtocol.refer 组装注册中心协议的url 。 判断是否配置了group，如果有，则cluster=getMergeableCluster()，构建invoker 。 doRefer构建invoker public Invoker refer(Class type, URL url) throws RpcException { //根据配置的协议，生成注册中心的url: zookeeper:// url = URLBuilder.from(url) .setProtocol(url.getParameter(REGISTRY_KEY, DEFAULT_REGISTRY)) .removeParameter(REGISTRY_KEY) .build(); Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) { return proxyFactory.getInvoker((T) registry, type, url); } // 解析group参数，根据group决定cluster的类型 Map qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null && group.length() > 0) { if ((COMMA_SPLIT_PATTERN.split(group)).length > 1 ||\"*\".equals(group)) { return doRefer(getMergeableCluster(), registry, type, url); } } //只有一个组或者没有组配置，直接执行 return doRefer(cluster, registry, type, url); } doRefer 构建一个RegistryDirectory 构建一个consumer://协议的地址，注册到注册中心 订阅zookeeper中节点的变化。监听providers，configuraion等节点数据 调用cluster.join方法。Cluster将多个服务节点合并为一个，并生成一个invoker。 private Invoker doRefer(Cluster cluster, Registry registry, Classtype, URL url) { //RegistryDirectory初始化 RegistryDirectory directory = new RegistryDirectory(type, url); //设置注册中心 directory.setRegistry(registry); //设置协议 directory.setProtocol(protocol); // all attributes of REFER_KEY Map parameters = new HashMap(directory.getUrl().getParameters()); //注册consumer://协议的url URL subscribeUrl = new URL(CONSUMER_PROTOCOL,parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &&url.getParameter(REGISTER_KEY, true)) { directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl,url)); //注册服务消费者 registry.register(directory.getRegisteredConsumerUrl()); } directory.buildRouterChain(subscribeUrl); //订阅事件监听(providers，configuraion等节点数据) directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY,PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" +ROUTERS_CATEGORY)); //构建invoker。一个注册中心可能有多个服务提供者，将多个服务合并为一个invoker Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl,directory); return invoker; } cluster.join cluster其实是在RegistryProtocol中通过set方法完成依赖注入的，它是一个Cluster扩展点的定义并且做了包装，实际是调用MockClusterWrapper(FailOverCluster.join)。返回的invoker应该是MockClusterWrapper(FailOverCluster(directory))。 proxyFactory.getProxy 拿到invoker之后，会调用获得一个动态代理类 return (T) proxyFactory.getProxy(invoker); //proxyFactory又是一个自适应扩展点 public T getProxy(Invoker invoker, Class[]interfaces) { return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); } 通过这个方法生成了一个动态代理类，并且对invoker再做了一层处理，InvokerInvocationHandler。 意味着后续发起服务调用的时候，会由InvokerInvocationHandler来进行处理。 @Reference注入的一个对象实例本质上就是一个动态代理类，通过调用这个类中的方法，会触发 handler.invoke(), 而这个handler就是InvokerInvocationHandler。 服务订阅 directory.subscribe doRefer这个方法中，directory.subscribe这个方法，它是实现服务的目标服务订阅。 订阅注册中心指定节点的变化，如果发生变化，则通知到RegistryDirectory。Directory和服务的注册以及服务的发现有非常大的关联。 public void subscribe(URL url) { setConsumerUrl(url); //设置consumerUrl //把当前RegistryDirectory作为listener，去监听zk上节点的变化 consumerConfigurationListener.addNotifyListener(this); serviceConfigurationListener = new ReferenceConfigurationListener(this,url); registry.subscribe(url, this);//订阅 -> 这里的registryzookeeperRegsitry //监听providers，configuraion,rouers节点下面子节点变化 } FailbackRegistry.subscribe 移除失效的listener，调用doSubscribe进行订阅。listener为RegistryDirectory，后续要用到。 ZookeeperRegistry.doSubscribe 这个方法是订阅，逻辑实现比较多，可以分两段来看，这里的实现把所有Service层发起的订阅以及指定 的Service层发起的订阅分开处理。所有Service层类似于监控中心发起的订阅。指定的Service层发起的 订阅可以看作是服务消费者的订阅。我只需要关心指定service层发起的订阅即可。 public void doSubscribe(final URL url, final NotifyListener listener) { try { if (Constants.ANY_VALUE.equals(url.getServiceInterface())) { //省略部分代码 } else { List urls = new ArrayList<>(); for (String path : toCategoriesPath(url)) { ConcurrentMap listeners =zkListeners.get(url); // 如果之前该路径没有添加过listener，则创建一个map来放置listener if (listeners == null) { zkListeners.putIfAbsent(url, new ConcurrentHashMap<>()); listeners = zkListeners.get(url); } ChildListener zkListener = listeners.get(listener); if (zkListener == null) { // 如果没有添加过对于子节点的listener，则创建,通知服务变化 回调NotifyListener listeners.putIfAbsent(listener, (parentPath,currentChilds) -> ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url,parentPath, currentChilds))); zkListener = listeners.get(listener); } //添加path节点的当前节点及子节点监听，并且获取子节点信息 //也就是dubbo://ip:port/... zkClient.create(path, false); List children = zkClient.addChildListener(path,zkListener); if (children != null) { urls.addAll(toUrlsWithEmpty(url, path, children)); } } //调用notify进行通知，对已经可用的列表进行通知 notify(url, listener, urls); } } catch (Throwable e) { throw new RpcException(); } } FailbackRegistry.notify 调用FailbackRegistry.notify， 对参数进行判断。 然后调用AbstractRegistry.notify方法。 AbstractRegistry.notify会针对每一个category，调用listener.notify进行通知，然后更新本地的缓存文件。 消费端的listener是最开始传递过来的RegistryDirectory，这里会触发RegistryDirectory.notify。 RegistryDirectory.notify Invoker的网络连接以及后续的配置变更，都会调用这个notify方法。urls表示zk的path数据，这里表示的是dubbo://。 public synchronized void notify(List urls) { //对url列表进行校验、过滤，然后分成 config、router、provider 3个分组map Map> categoryUrls = urls.stream() .filter(Objects::nonNull) .filter(this::isValidCategory) .filter(this::isNotCompatibleFor26x) .collect(Collectors.groupingBy(url -> { if (UrlUtils.isConfigurator(url)) { return CONFIGURATORS_CATEGORY; } else if (UrlUtils.isRoute(url)) { return ROUTERS_CATEGORY; } else if (UrlUtils.isProvider(url)) { return PROVIDERS_CATEGORY; } return \"\" })); List configuratorURLs = categoryUrls.getOrDefault(CONFIGURATORS_CATEGORY, Collections.emptyList()); this.configurators = Configurator.toConfigurators(configuratorURLs).orElse(this.configurators); // 如果router 路由节点有变化，则从新将router 下的数据生成router List routerURLs = categoryUrls.getOrDefault(ROUTERS_CATEGORY,Collections.emptyList()); toRouters(routerURLs).ifPresent(this::addRouters); // 获得provider URL，然后调用refreshOverrideAndInvoker进行刷新 List providerURLs = categoryUrls.getOrDefault(PROVIDERS_CATEGORY,Collections.emptyList()); refreshOverrideAndInvoker(providerURLs); } 构建Invoker refreshOverrideAndInvoker 逐个调用注册中心里面的配置，覆盖原来的url，组成最新的url 放入overrideDirectoryUrl 存储。根据 provider urls，重新刷新Invoker private void refreshOverrideAndInvoker(List urls) { // mock zookeeper://xxx?mock=return null overrideDirectoryUrl(); refreshInvoker(urls); } refreshInvoker private void refreshInvoker(List invokerUrls) { Assert.notNull(invokerUrls, \"invokerUrls should not be null\"); if (invokerUrls.size() == 1&& invokerUrls.get(0) != null&& Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //省略部分代码，如果是空协议，则直接返回不允许访问 } else { this.forbidden = false; // Allow to access Map> oldUrlInvokerMap = this.urlInvokerMap; //local reference if (invokerUrls.isEmpty()) {//如果url为空，则直接返回 return; } //根据provider url，生成新的invoker Map> newUrlInvokerMap =toInvokers(invokerUrls); //转化为list List> newInvokers = Collections.unmodifiableList(newArrayList<>(newUrlInvokerMap.values())); routerChain.setInvokers(newInvokers); //如果服务配置了分组，则把分组下的provider包装成StaticDirectory,组成一个 invoker//实际上就是按照group进行合并 this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers; this.urlInvokerMap = newUrlInvokerMap; try { //旧的url 是否在新map里面存在，不存在，就是销毁url对应的Invoker destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); } catch (Exception e) { logger.warn(\"destroyUnusedInvokers error. \", e); } } } toInvokers 这个方法初始化了invoker。用到了protocol.refer来构建了一个invoker。 invoker = new InvokerDelegate<>(protocol.refer(serviceType, url),url,providerUrl); 构建完成之后，会保存在Map> newUrlInvokerMap这个集合中。 protocol.refer 调用指定的协议来进行远程引用。protocol是一个Protocol$Adaptive类 而真正的实现应该是: ProtocolListenerWrapper(ProtocolFilterWrapper(QosProtocolWrapper(DubboProtocol.refer) 。前面的包装过程，在服务发布的时候已经分析过了，我们直接进入DubboProtocol.refer方法。 DubboProtocol.refer 优化序列化，构建DubboInvoker。在构建DubboInvoker时，会构建一个ExchangeClient，通过getClients(url)方法，建立服务通信。 @Override public Invoker refer(Class serviceType, URL url) throwsRpcException { optimizeSerialization(url); // create rpc invoker. 构建DubboInvoker DubboInvoker invoker = new DubboInvoker(serviceType, url,getClients(url), invokers); invokers.add(invoker); return invoker; } 客户端连接 getClients //获得客户端连接的方法。判断是否为共享连接，默认是共享同一个连接进行通信。是否配置了多个连接通道 connections，默认只有一个。 >getClients(url) //获得一个共享连接。检查当前的key检查连接是否已经创建过并且可用，如果是则直接返回并且增加连接的个数。否则初始化连接并缓存。key = url.getAddress(); >getSharedClient() //根据连接数配置，来构建指定个数的链接。默认为1 >buildReferenceCountExchangeClientList //初始化客户端连接的方法了，根据url中配置的参数进行远程通信的构建 >initClient() //创建一个客户端连接 >Exchangers.connect() >HeaderExchange.connect //使用netty构建了一个客户端连接 >NettyTransport.connect >return new NettyClient(url, listener); Directory Directory 的用途是保存 Invoker，其实现类 RegistryDirectory 是一个动态服务目录，可感知注册中心配置的变化，它所持有的 Inovker 列表会随着注册中心内容的变化而变化。每次变化后，RegistryDirectory 会动态增删 Inovker。 在RegistryDirectory中有一个成员属性，保存了服务地方地址对应的invoke信息。 private volatile Map> urlInvokerMap; 这个invoker是动态的，基于注册中心的变化而变化的。它的初始化过程的链路是 RegistryDirectory.notify->refreshInvoker->toInvokers 西面的这段代码中。返回的是一个DubboInvoker对象。 总结 RegistryProtocol.refer 过程中有一个关键步骤，即在监听到服务提供者url时触发 RegistryDirectory.notify() 方法。 RegistryDirectory.notify() 方法调用 refreshInvoker() 方法将服务提供者urls转换为对应的远程invoker ，最终调用到 DubboProtocol.refer() 方法生成对应的 DubboInvoker 。 DubboInvoker 的构造方法中有一项入参 ExchangeClient[] clients ，即对应网络客户端 Client 。DubboInvoker就是通过调用 client.request() 方法完成网络通信的请求发送和响应接收功能。 Client 的具体生成过程就是通过 DubboProtocol 的 initClient(URL url) 方法创建了一个HeaderExchangeClient。 服务调用 消费者初始化完成之后，会生成一个proxy，而这个proxy本质上是一个动态代理类。 avassistProxyFactory.getProxy public T getProxy(Invoker invoker, Class[] interfaces) { return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); } 这个invoker实际上是:MockClusterWrapper(FailoverCluster(directory)) 然后通过InvokerInvocationHandler做了一层包装变成了 InvokerInvocationHandler(MockClusterWrapper(FailoverCluster(directory)) proxy.getProxy 这个方法里面，会生成一个动态代理的方法。它代理了当前这个接口的方法，并且方法里面是使用handler.invoke进行调用的。 而handler又是这样一个实现: InvokerInvocationHandler(MockClusterWrapper(FailoverCluster(directory))) 调用流程 //这个方法主要判断当前调用的远程方法，如果是tostring、hashcode、equals，就直接返回 //否则，调用invoker.invoke,进入到 MockClusterWrapper.invoke 方法 InvokerInvocationHandler.invoke //是否客户端强制配置了mock调用，是否出现异常,使用Mock实现服务降级。正常则进入下一个invoke。 >MockClusterInvoker.invoke //下一个invoke，应该进入FailoverClusterInvoke。调用父类AbstractClusterInvoker.invoke。 //1.绑定attachments，Dubbo中，可以通过 RpcContext 上的 setAttachment 和 getAttachment 在 服务消费方和提供方之间进行参数的隐式传递 //2.从directory里面获得invoker列表，通过服务路由对invoker筛选 //3.initLoadBalance 初始化负载均衡机制 //4.执行doInvoke >AbstractClusterInvoker.invoke //获得重试的次数进行循环。通过负载均衡获得目标DubboInvoker。如果执行成功则返回结果,如果出现异常则抛出 >FailoverClusterInvoker.doInvoke //1.将目标方法以及版本好作为参数放入到Invocation中 //2.获得客户端连接 >DubboInvoker.doInvoker //创建请求对象,netty请求 >currentClient.request //NettyClient >channel.send(req); 总结 这里的 Invoker 是 Provider 的一个可调用 Service 的抽象， Invoker 封装了 Provider 地 址及 Service 接口信息。 Directory 代表多个 Invoker ，可以把它看成 List\\ 。它的值可能是动态变化的，比如注册中心推送变更 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker ，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 Router 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡 算法，调用失败后，需要重选。 最后调用DubboInvoker，通过Netty发送请求对象。 服务端消息接收处理 服务端通过Netty接收消息 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throwsException { NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url,handler); try { handler.received(channel, msg); } finally { NettyChannel.removeChannelIfDisconnected(ctx.channel()); } } // NettyHandler //复合消息处理,拆分成多个Message ->MultiMessageHandler //心跳消息处理，接收心跳并发送心跳响应 ->HeartbeatHandler //业务线程转化处理器，把接收到的消息封装成ChannelEventRunnable可执行任务给线程池处理。 //用来接收消息事件，并且根据事件的种类来分别执行不同的操作 ->AllChannelHandler //业务解码处理器 ->DecodeHandler //对消息进行分类，针对不同的消息类型做了不同的逻辑调用 ->HeaderExchangeHandler //正常双向请求消息调用 ->handleRequest ->DubboProtocol$requestHandler(receive) ->reply ExchangeHandler.reply 把message转化为Invocation 调用getInvoker获得一个Invoker对象 通过Resultresult=invoker.invoke(inv)，进行反射调用 public CompletableFuture reply(ExchangeChannel channel, Object message){ Invocation inv = (Invocation) message; Invoker invoker = getInvoker(channel, inv); RpcContext rpcContext = RpcContext.getContext(); rpcContext.setRemoteAddress(channel.getRemoteAddress()); Result result = invoker.invoke(inv); } getInvoker 获得一个invoker的实现。 Invoker getInvoker(Channel channel, Invocation inv){ String serviceKey = serviceKey(port, path,inv.getAttachments().get(Constants.VERSION_KEY), inv.getAttachments().get(Constants.GROUP_KEY)); DubboExporter exporter = (DubboExporter)exporterMap.get(serviceKey); return exporter.getInvoker(); } exporterMap是在服务发布的过程中，保存的Invoker。key就是对应的interface:port。在服务发布时，实际上是把invoker包装成了DubboExpoter。然后放入到exporterMap中。 "},"content/Zookeeper/节点.html":{"url":"content/Zookeeper/节点.html","title":"节点","keywords":"","body":"Znode节点 zookeeper 中数据基本单元叫节点，节点可以保存数据和包含子节点，最后以树级方式程现。每个节点拥有唯一的路径path。客户端基于PATH上传节点数据，zookeeper 收到后会实时通知对该路径进行监听的客户端。 znode结构包含如下： path:唯一路径 childNode：子节点 stat:状态属性 type:节点类型 节点类型 PERSISTENT（持久节点）。持久化保存的节点，也是默认创建的 PERSISTENT_SEQUENTIAL(持久序号节点)。创建时zookeeper 会在路径上加上序号作为后缀。 EPHEMERAL（临时节点）。临时节点会在客户端会话断开后自动删除。适用于心跳，服务发现等场景。 EPHEMERAL_SEQUENTIAL(临时序号节点)。与持久序号节点类似，不同之处在于EPHEMERAL_SEQUENTIAL是临时的会在会话断开后删除。 节点属性 #创建节点的事物ID cZxid = 0x385 #创建时间 ctime = Tue Sep 24 17:26:28 CST 2019 #修改节点的事物ID mZxid = 0x385 #最后修改时间 mtime = Tue Sep 24 17:26:28 CST 2019 # 子节点变更的事物ID pZxid = 0x385 #这表示对此znode的子节点进行的更改次数（不包括子节点） cversion = 0 # 数据版本，变更次数 dataVersion = 0 #权限版本，变更次数 aclVersion = 0 #临时节点所属会话ID ephemeralOwner = 0x0 #数据长度 dataLength = 17 #子节点数(不包括子子节点) numChildren = 0 节点监听 zookeeper 提供了分布式数据的发布/订阅功能，zookeeper 允许客户端向服务端注册一个 watcher 监听，当服务端的一 些指定事件触发了 watcher，那么服务端就会向客户端发送一个事件通知。 值得注意的是，Watcher 通知是一次性的，即一旦触发一次通知后，该 Watcher 就失效了，因此客户端需要反复注册 Watcher，即程序中在 process 里面又注册了 Watcher。否则， 将无法获取 c3 节点的创建而导致子节点变化的事件。 ACL权限设置 ACL全称为Access Control List（访问控制列表），用于控制资源的访问权限。ZooKeeper使用ACL来控制对其znode的防问。基于scheme:id permission的方式进行权限控制。scheme表示授权模式、id模式对应值、permission即具体的增删改权限位。 权限仅对当前节点有效，不会让子节点继承。如限制了IP防问A节点，但不妨碍该IP防问A的子节点 /A/B。 scheme:认证模型 方案 描述 world 开放模式，world表示全世界都可以访问（这是默认设置） ip ip模式，限定客户端IP防问 auth 用户密码认证模式，只有在会话中添加了认证才可以防问 digest 与auth类似，区别在于auth用明文密码，而digest 用sha-1+base64加密后的密码。在实际使用中digest 更常见。 permission权限位 权限位 权限 描述 c CREATE 可以创建子节点 d DELETE 可以删除子节点（仅下一级节点） r READ 可以读取节点数据及显示子节点列表 w WRITE 可以设置节点数据 a ADMIN 可以设置节点访问控制列表权限 "},"content/Zookeeper/集群.html":{"url":"content/Zookeeper/集群.html","title":"集群","keywords":"","body":"集群部署 配置语法：server.=:: 集群角色 角色 描述 leader 主节点，又名领导者。用于写入数据，通过选举产生，如果宕机将会选举新的主节点。 follower 子节点，又名追随者。用于实现数据的读取。同时他也是主节点的备选节点，并用拥有投票权。 observer 次级子节点，又名观察者。用于读取数据，与fllower区别在于没有投票权，不能选为主节点。并且在计算集群可用状态时不会将observer计算入内。 数据同步 ZAB(Zookeeper Atomic Broadcast) 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。 ZAB 协议包含两种基本模式，分别是崩溃恢复和原子广播。 ZXID zxid，也就是事务 id。zxid 是一个 64 位的数字，高32位是epoch，每次一个 leader 被选出来，它都会有一个新的epoch=(原来的 epoch+1)。低 32 位用于递增计数。 原子广播 zookeeper 中，客户端会随机连接到 zookeeper 集群中的一个节点，如果是读请求，就直接从当前节点中读取数据，如果是写请求，那么请求会被转发给 leader 提交事务，然后 leader 会广播事务，只要有超过半数节点写入成功， 那么写请求就会被提交(类 2PC 事务)。 leader 接收到消息请求后，将消息赋予一个全局唯一的64 位自增 id，叫:zxid，通过 zxid 的大小比较既可以实现因果有序这个特征。 leader 为每个 follower 准备了一个 FIFO 队列(通过 TCP协议来实现)将带有 zxid的消息作为一个提案(proposal)分发给所有的 follower。 当 follower 接收到 proposal，先把 proposal 写到磁盘，写入成功以后再向 leader 回复一个 ack 当 leader 接收到超过半数节点的 ACK 后，leader 就会向follower 发送 commit 命令，同时会在本地执行该消息 当 follower 收到消息的 commit 命令以后，会提交该消息。 和完整的 2pc 事务不一样的地方在于，zab 协议不能终止事务，follower 节点要么 ACK 给 leader，要么抛弃 leader，虽然在某一个时刻follower节点和 leader 节点的状态会不一致，zab 协议提供了一种恢复模式来进行数据恢复。 崩溃恢复 当整个集群在启动时，或者当 leader 节点出现网络中断、 崩溃等情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader。或者在 Leader 节点正常工作时，启动一台新的服务器加入到集群，那这个服务器会直接进入数据恢复模式，和leader 节点进行数据同步。 崩溃恢复下 zab 协议需要做两件事，选举出新的 leader和数据同步。 ZAB 协议要设计一个 leader 选举算法：能够确保已经被 leader 提交的事务 Proposal 能够提交、同时丢弃已经被跳过的事务 Proposal。 如果 leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群中所有机器最高编号(ZXID 最大)的事务 Proposal，那么就可以保证这个新选举出来的 Leader 一 定具有已经提交的提案。因为所有提案被 COMMIT 之 前必须有超过半数的 followerACK，即必须有超过半数节点的服务器的事务日志上有该提案的 proposal，因此， 只要有合法数量的节点正常工作，就必然有一个节点保 存了所有被 COMMIT 消息的 proposal 状态 另外一个，zxid 是 64 位，高 32 位是 epoch 编号，每经 过一次 Leader 选举产生一个新的 leader，新的 leader 会将 epoch 号+1，低 32 位是消息计数器，每接收到一 条消息这个值+1，新 leader 选举后这个值重置为 0.这样设计的好处在于老的 leader 挂了以后重启，它不会被选举为 leader，此时它的 zxid 肯定小于当前新的 leader。当老的 leader 作为 follower 接入新的 leader 后，新的 leader 会让它将所有的拥有旧的 epoch 号的 未被 COMMIT 的 proposal 清除 一致性 zookeeper 是一个顺序一致性模型。顺序一致性是针对单个操作，单个数据对象。一个数据被更新后，能够立马被后续的读操作读到。 zookeeper 不保证在每个实例中，两个不同的客户端具有相同zookeeper 数据视图。如果客户端 A 和 B 要读取必须要读取到相同的值，那么 client B 在读取操作之前执行 sync 方法。 同时client 会记录自己已经读取到的最大的 zxid，如果 client 重连到 server 发现 client 的 zxid 比自己大。连接会失败。 集群选举 服务启动时leader选举 每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为 Leader 服务器来进行投票，每次投票会包含所推举的服务器的myid 和 ZXID。 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判 断该投票的有效性，如检查是否是本轮投票(epoch)、是否来自 LOOKING 状态的服务器。 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投 票进行PK。优先比较 epoch，其次检查 ZXID，最后比较myid。根据规则进行重新投票。 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有 过半机器接受到相同的投票信息。 改变服务器状态。如果是 Follower，那么就变更为 FOLLOWING，如果是 Leader， 就变更为 LEADING。 运行过程中leader选举 当集群中的 leader 服务器出现宕机或者不可用的情况时，那么整个集群 将无法对外提供服务，而是进入新一轮的 Leader 选举，服务器运行期间 的 Leader 选举和启动时期的 Leader 选举基本过程是一致的。 变更状态。Leader 挂后，余下的非 Observer 服务器都会将自己的服务器状态变更为 LOOKING，然后开始进入 Leader 选举过程。 每个 Server 会发出一个投票。在运行期间，每个服务器上的 ZXID 可 能不同。将投票发送给集群中所有机器。接收来自各个服务器的投票。与启动时过程相同。 处理投票。与启动时过程相同。 统计投票。与启动时过程相同。 改变服务器的状态。与启动时过程相同 "},"content/Zookeeper/启动与选举源码.html":{"url":"content/Zookeeper/启动与选举源码.html","title":"启动及选举","keywords":"","body":"启动流程 代码堆栈 >QuorumPeerMain#main //启动main方法 >QuorumPeerConfig#parse // 加载zoo.cfg 文件 >QuorumPeerConfig#parseProperties // 解析配置 >DatadirCleanupManager#start // 启动定时任务清除日志 >QuorumPeerConfig#isDistributed // 判断是否为集群模式 >ServerCnxnFactory#createFactory() //创建服务默认为NIO,推荐netty //***创建 初始化集群管理器**/ >QuorumPeerMain#getQuorumPeer >QuorumPeer#setTxnFactory >new FileTxnSnapLog // 数据文件管理器，用于检测快照与日志文件 /** 初始化数据库*/ >new ZKDatabase >ZKDatabase#createDataTree //创建数据树，所有的节点都会存储在这 // 启动集群：同时启动线程 > QuorumPeer#start // > QuorumPeer#loadDataBase // 从快照文件以及日志文件 加载节点并填充到dataTree中去 > QuorumPeer#startServerCnxnFactory // 启动netty 或java nio 服务，对外开放2181 端口 > AdminServer#start// 启动管理服务，netty http服务，默认端口是8080 > QuorumPeer#startLeaderElection // 开始执行选举流程 > quorumPeer.join() // 防止主进程退出 main方法启动 加载zoo.cfg 配置文件 解析配置 创建服务工厂 创建集群管理线程 设置数据库文件管理器2. 设置数据库 3. ....设置设置 start启动集群管理线程 加载数据节点至内存2. 启动netty 服务，对客户端开放端口 3. 启动管理员Http服务，默认8080端口 4. 启动选举流程 join 管理线程，防止main 进程退出 快照与事务日志 ZK中所有的数据都是存储在内存中，即zkDataBase中。但同时所有对ZK数据的变更都会记录到事物日志中，并且当写入到一定的次数就会进行一次快照的生成。已保证数据的备份。其后缀就是ZXID（唯一事物ID）。 事物日志：每次增删改的记录日志都会保存在文件当中 快照日志：存储了在指定时间节点下的所有的数据 zkDdataBase 是zk数据库基类，所有节点都会保存在该类当中，而对Zk进行任何的数据变更都会基于该类进行。zk数据的存储是通过DataTree 对象进行，其用了一个map 来进行存储。 快照相关配置 dataLogDir 事物日志目录 zookeeper.preAllocSize 预先开辟磁盘空间，用于后续写入事务日志，默认64M zookeeper.snapCount 每进行snapCount次事务日志输出后，触发一次快照，默认是100,000 autopurge.snapRetainCount 自动清除时 保留的快照数 autopurge.purgeInterval 清除时间间隔，小时为单位 -1 表示不自动清除。 投票与选举 投票处理流程图 投票的网络通信流程 "},"content/Zookeeper/Watcher.html":{"url":"content/Zookeeper/Watcher.html","title":"监听Watch","keywords":"","body":"基本流程 ZooKeeper 的 Watcher 机制，总的来说可以分为三个过程。客户端注册 Watcher、服务器处理 Watcher 和客户端回调 Watcher。 客户端注册 watcher 有 3 种方式，getData、exists、getChildren。 客户端发起请求 在创建一个 ZooKeeper 客户端对象实例时，通过 new Watcher()向构造方法中传入一个默认的 Watcher。这个 Watcher 将作为整个 ZooKeeper 会话期间的默认 Watcher，会一直被保存在客户端 ZKWatchManager 的 defaultWatcher 中。 同时初始化 ClientCnxn，并且调用 cnxn.start()方法。 ClientCnxn是Zookeeper 客户端和 Zookeeper 服务器端进行通信和事件通知处理的主要类，它内部包含两个类， SendThread。负责客户端和服务器端的数据通信, 也包括事件信息的传输 EventThread。主要在客户端回调注册的 Watchers 进行通知处理 服务端接收请求 服务端有一个 NIOServerCnxn 类，用来处理客户端发送过来的请求。 zookeeper 启动的时候， 构建了一个NIOServerCnxnFactory，它实现了 Thread，所以在启动的时候，会在 run 方法中不断循环接收客户端的请求进行分发。 NIOServerCnxn //处理客户端传送过来的数据包 ->processPacket //封装对象请求，在服务端提交当前请求 ->Request,submitRequest //对请求做一个调用链处理 ->firstProcessor.processRequest //将请求添加到阻塞队列，并从队列中拿到请求进行处理预处理 ->PrepRequestProcessor //将请求添加到阻塞队列，并从队列中拿到请求触发快照操作 ->SyncRequestProcessor //根据客户端的 OP 类型进行处理 ->FinalRequestProcessor 客户端接收响应 服务端处理完成以后，会通过 NIOServerCnxn.sendResponse 发送返回的响应信息， 客户端会在 ClientCnxnSocketNIO.doIO 接收服务端的返回。 ClientCnxnSocketNIO.doIO //首先读取 header，如果其 xid == -2，表明是一个 ping 的 response， //如果 xid 是 -4 ，表明是一个 AuthPacket 的 response return //如果 xid 是 -1，表明是一个 notification,此时要继续读取并构造一个 enent，通过 EventThread.queueEvent 发送，return ->SendThread.readResponse //如果是-1，从Packet中取出对应的Watcher并注册到ZKWatchManager中去 ->finishPacket //当前的数据包添加到等待事件通知的队列中 ->eventThread.queuePacket static class ZKWatchManager implements ClientWatchManager { private final Map> dataWatches = new HashMap>(); private final Map> existWatches =new HashMap>(); private final Map> childWatches =new HashMap>(); 总的来说，当使用 ZooKeeper 构造方法或者使用 getData、exists 和 getChildren 三个接口来向 ZooKeeper 服务器注册 Watcher 的时候，首先将此消息传递给服务端，传递成功后，服务端会通知客户端，然后客户端将该路径和 Watcher 对应关系存储起来备用。 事件触发 事件的触发，还得需要通过事务型操作来完成。 服务端的事件响应 根据类型，触发对应节点的 NodeDataChanged 事件。根据事件类型、连接状态、节点路径创建WatchedEvent，并移除该事件。调用sendResponse(h, e, \"notification\")， 发送了一个事件，事件对象为 WatcherEvent。 客户端处理事件响应 SendThread 接收到服务端的通知事件后，会通过调用 EventThread 类的 queueEvent 方法将事件传给 EventThread 线程，queueEvent 方法根据该通知事件， 从 ZKWatchManager 中取出所有相关的 Watcher，如果获取到相应的 Watcher，就 会让 Watcher 移除失效。 通过 dataWatches 或者 existWatches 或者 childWatches 的 remove 取出对应的watch，waitingEvents 是一个待处理 Watcher 的队列，EventThread 的 run() 方法会不断从队列中取数据，交由 processEvent 方法处理。最后调用客户端的回调函数。 集群模式下处理流程 "},"content/Zookeeper/应用场景.html":{"url":"content/Zookeeper/应用场景.html","title":"应用场景","keywords":"","body":"分布式集群管理 主动查看线上服务节点 查看服务节点资源使用情况 服务离线通知 服务资源（CPU、内存、硬盘）超出阀值通知 数据生成与上报：创建临时节点和定时变更节点状态信息： 主动查询：实时查询 zookeeper 获取集群节点的状态信息。 被动通知：监听根节点下子节点的变化情况,如果CPU 等硬件资源低于警告位则发出警报。 分布式注册中心 一个完整的注册中心涵盖以下功能特性： 服务注册：提供者上线时将自提供的服务提交给注册中心。 服务注销：通知注册中心提供者下线。 服务订阅：动态实时接收服务变更消息。 可靠：注册服务本身是集群的，数据冗余存储。避免单点故障，及数据丢失。 容错：当服务提供者出现宕机，断电等极情况时，注册中心能够动态感知并通知客户端服务提供者的状态。 Dubbo注册中心存储结构 类别 属性 说明 Root 持久节点 根节点名称，默认是 \"dubbo\" Service 持久节点 服务名称，完整的服务类名 type 持久节点 可选值：providers(提供者)、consumers（消费者）、configurators(动态配置)、routers URL 临时节点 url名称包含服务提供者的 IP 端口 及配置等信息。 分布式JOB 多个服务节点只允许其中一个主节点运行JOB任务。 当主节点挂掉后能自动切换主节点，继续执行JOB任务 分布式锁 获得写锁 基于资源ID创建临时序号写锁节点 /lock/888.R0000000002 Write。获取 /lock 下所有子节点，判断其最小的节点是否为自己，如果是则获锁成功。最小节点不是自己，则阻塞等待。添加lock/ 子节点变更监听。当节点变更监听触发，执行第2步。 获得读锁 1、基于资源ID创建临时序号读锁节点 /lock/888.R0000000002 Read 。获取 /lock 下所有子节点，判断其最小的节点是否为读锁，如果是则获锁成功。最小节点不是读锁，则阻塞等待。添加lock/ 子节点变更监听。当节点变更监听触发，执行第2步 释放锁 读取完毕后，手动删除临时节点，如果获锁期间宕机，则会在会话失效后自动删除。 惊群效应 在等待锁获得期间，所有等待节点都在监听 Lock节点，一但lock 节点变更所有等待节点都会被触发，然后在同时反查Lock 子节点。如果等待对例过大会使用Zookeeper承受非常大的流量压力。 为了改善这种情况，可以采用监听链表的方式，每个等待对列只监听前一个节点，如果前一个节点释放锁的时候，才会被触发通知。这样就形成了一个监听链表。 Eureka区别 "},"content/Kafka/基本使用.html":{"url":"content/Kafka/基本使用.html","title":"基本使用","keywords":"","body":"架构 一个典型的 kafka 集群包含若干 Producer，若干个 Broker(kafka 支持水平扩展)、若干个 Consumer Group，以及一个 zookeeper 集群。kafka 通过 zookeeper 管理集群配置及服务协同。broker，producer 和 consumer三者通过 zookeeper 管理协调请求和转发。producer 发送消息到 broker 的过程是 push，而 consumer 从 broker 消费消息的过程是 pull，主动去拉数据。而不是 broker 把数据主动发送给 consumer。 服务端(brokers)和客户端(producer、consumer)通信通过TCP协议完成。 基本概念 Broker 消息中间件处理节点，一个Kafka节点就是 一个broker，一个或者多个Broker可以组 成一个Kafka集群 Topic Kafka根据topic对消息进行归类，发布到 Kafka集群的每条消息都需要指定一个topic Producer 消息生产者，向Broker发送消息的客户端 Consumer 消息消费者，从Broker读取消息的客户端 ComsumerGroup 每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的 Consumer Group消费，但是一个 Consumer Group中只能有一个Consumer 能够消费该消息 Partition 物理上的概念，一个topic可以分为多个 partition，每个partition内部消息是有序的 针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。 leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。 一个partition同一个时刻在一个consumer group中只有一个consumer instance在消费，从而保证顺序。 consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的 consumer消费不到消息。 Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的 consumer instance数量也设置为1。 Producer kafka对于消息的发送，可以支持同步和异步。 producer 先从 zookeeper 的 \"/brokers/.../state\" 节点找到该 partition 的 leader。 从本质上来说，kafka都是采用异步的方式来发送消息到broker，但是kafka并不是每次发送消息都会直接发送到broker上，而是把消息放到了一个发送队列中，然后通过一个后台线程不断从队列取出消息进行发送，发送成功后会触发callback。kafka客户端会积累一定量的消息统一组装成一个批量消息发送出 去，触发条件是前面提到的batch.size和linger.ms 而同步发送的方法，无非就是通过future.get()来等待消息的发送返回结果，但是这种方法会严重影响消息发送的性能。 batch.size 生产者发送多个消息到broker上的同一个分区时，为了减少网络请求带来的性能开销，通过批量的方式 来提交消息，可以通过这个参数来控制批量提交的字节数大小，默认大小是16384byte,也就是16kb， 意味着当一批消息大小达到指定的batch.size的时候会统一发送 linger.ms Producer默认会把两次发送时间间隔内收集到的所有Requests进行一次聚合然后再发送，以此提高吞 吐量，而linger.ms就是为每次发送到broker的请求增加一些delay，以此来聚合更多的Message请求。 消息路由 默认情况下，kafka采用的是hash取模的分区算法。如果Key为null，则会随机分配一个分区。这个随机是在这个参数”metadata.max.age.ms”的时间范围内随机选择一个。对于这个时间段内，如果key为 null，则只会发送到唯一的分区。这个值默认情况下是10分钟更新一次。 ACK 生产者把消息发送到leader副本，leader副本在成功写入到本地日志之后就告诉生产者 消息提交成功，但是如果isr集合中的follower副本还没来得及同步leader副本的消息， leader挂了，就会造成消息丢失 -1 ，消息不仅仅写入到leader副本，并且被ISR集合中所有副本同步完成之后才告诉生产者已 经提交成功，这个时候即使leader副本挂了也不会造成数据丢失。 0:表示producer不需要等待broker的消息确认。这个选项时延最小但同时风险最大(因为当server宕机时，数据将会丢失)。 Comsumer kafka中长轮询 像 Kafka 在拉请求中有参数，可以使得消费者请求在 “长轮询” 中阻塞等待。 简单的说就是消费者去 Broker 拉消息，定义了一个超时时间，也就是说消费者去请求消息，如果有的话马上返回消息，如果没有的话消费者等着直到超时，然后再次发起拉消息请求。 并且 Broker 也得配合，如果消费者请求过来，有消息肯定马上返回，没有消息那就建立一个延迟操作，等条件满足了再返回 enable.auto.commit 消费者消费消息以后自动提交，只有当消息提交以后，该消息才不会被再次接收到，还可以配合 auto.commit.interval.ms控制自动提交的频率。 当然，我们也可以通过consumer.commitSync()的方式实现手动提交 auto.offset.reset 这个参数是针对新的groupid中的消费者而言的，当有新groupid的消费者来消费指定的topic时，对于 该参数的配置，会有不同的语义 auto.offset.reset=latest，新的消费者将会从其他消费者最后消费的offset处开始消费Topic下的 消息 auto.offset.reset= earliest，新的消费者会从该topic最早的消息开始消费 auto.offset.reset=none，新的消费者加入以后，由于之前不存在offset，则会直接抛出异常。 max.poll.records 此设置限制每次调用poll返回的消息数，这样可以更容易的预测每次poll间隔要处理的最大值。通过调整此值，可以减少poll间隔 分区分配策略 在多个partition以及多个consumer的情况下，消费者是如何消费消息的 范围分区(Range) 假设n = 分区数/消费者数量 m= 分区数%消费者数量 那么前m个消费者每个分配n+l个分区，后面的(消费者数量-m)个消费者每个分配n个分区 轮询分区(RoundRobin) 轮询分区策略是把所有partition和所有consumer线程都列出来，然后按照hashcode进行排序。最后通过轮询算法分配partition给消费线程。如果所有consumer实例的订阅是相同的，那么partition会均匀分布。 使用轮询分区策略必须满足两个条件：每个主题的消费者实例具有相同数量的流。每个消费者订阅的主题必须是相同的 粘滞策略(StrickyAssignor) 主要有两个目的：分区的分配尽可能的均匀。分区的分配尽可能和上次分配保持相同。当两者发生冲突时， 第 一 个目标优先于第二个目标。 消费位置0ffset 每个topic可以划分多个分区(每个Topic至少有一个分 区)，同一topic下的不同分区包含的消息是不同的。每个消息在被添加到分区时，都会被分配一个 offset(称之为偏移量)，它是消息在此分区中的唯一编号，kafka通过offset保证消息在分区内的顺序，offset的顺序不跨分区，即kafka只保证在同一个分区内的消息是有序的; 对于应用层的消费来说，每次消费一个消息并且提交以后，会保存当前消费到的最近的一个offset 在kafka中，提供了一个consumer_offsets_的一个topic，把offset信息写入到这个topic中。 consumer_offsets_保存了每个consumer group某一时刻提交的offset信息。 consumer_offsets 默认有50个分区，副本数量只有1。当前的consumer_group的位移信息保存分区通过如下公式进行计算： Math.abs(“groupid”.hashCode())%groupMetadataTopicPartitionCount 具体内容如下 [consumer_offsets_group/消费组ID/,consumer_offsets_test/topic/,1/partition/]::OffsetAndMetadata(offset=4/提交的消费位移信息/, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1543567461031, expireTimestamp=None) 消息的存储 kafka是使用日志文件的方式来保存生产者和发送者的消息，每条消息都有一 个offset值来表示它在分区中的偏移量。日志并不是直接对应在一个磁盘上的日志文件，而是对应磁盘上的一个目录，这个目录的命名规则是_。 对于一个 topic，在集群中创建多个 partition，partition 分布规则如下： 将所有 N Broker 和待分配的 i 个 Partition 排序 将第 i 个 Partition 分配到第(i mod n)个 Broker 上 将第 i 个 Partition 的第 j 个副本分配到第((i + j) mod n)个 Broker 上 文件存储机制 kafka 以 segment 为 单位又把 partition 进行细分。每个 partition 相当于一个巨型文件被平均分配到多个大小相等的 segment 数据文件中 segment file由2大部分组成，分别为.index和.log，分别表示为索引文件和日志文件。index中存储了索引以及物理偏移量。 log存储了消息的内容。 一个日志文件对应两个索引文件：OffsetIndex 和 TimeIndex。TimeIndex索引文件格式：它是映射时间戳和相对offset。 segment文件命名：partion全局的第一个segment从0开始，后续每个segment文件名为上一个 segment文件最后一条消息的offset值进行递增。 查找过程 根据offset的值，查找segment段中的index索引文件。由于索引文件命名是以上一个文件的最后 一个offset进行命名的，所以，使用二分查找算法能够根据offset快速定位到指定的索引文件。 找到索引文件后，根据offset进行定位，找到索引文件中的符合范围的索引。(kafka采用稀疏索引的方式来提高查找性能) 得到position以后，再到对应的log文件中，从position出开始查找offset对应的消息，将每条消息的offset与目标offset进行比较，直到找到消息 日志清除 日志的清理策略有两个 根据消息的保留时间，当消息在kafka中保存的时间超过了指定的时间，就会触发清理过程 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阀值，则可以开始删除最旧的消息。 kafka会启动一个后台线程，定期检查是否存在可以删除的消息。通过log.retention.bytes和log.retention.hours这两个参数来设置，当其中任意一个达到要求，都会执行删除。 默认的保留时间是7天 日志压缩 服务端会在后台启动启动Cleaner线程池，定期将相同的key进行合并，只保留最新的value值。 高性能 顺序读写 每个分区下包含若干个只能追加写的提交日志：新消息被追加到文件的最末端。 零拷贝 在消费者获取消息时，服务器先从 硬盘读取数据到内存，然后把内存中的数据原封不动的通 过 socket 发送给消费者。 传统的模式，及到 4 次上下文切换以及 4 次数据复制，并且有两次复制操作是由 CPU 完成。但是这个过程中，数据完全没有 进行变化，仅仅是从磁盘复制到网卡缓冲区。 零拷贝，在 Linux 中，是通过 sendfile 系统调用来完成的。使用 sendfile，只需要一次拷贝就行，允许操作系统将数据直接从页缓存发送网卡缓存中。 页缓存 Kafka中大量使用了页缓存， 消息都是先被写入页缓存， 然后由操作系统负责具体的刷盘任务。Kafka中同样提供了同步刷盘及间断性强制刷盘(fsync), 可以通过 log.flush.interval.messages 和 log.flush.interval.ms 参数来控制。 MMAP也就是内存映射文件，它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射，完成映射之后对物理内存的操作会被同步到硬盘上。通过MMAP技术进程可以像读写硬盘一样读写内存（逻辑内存），不必关心内存的大小，因为有虚拟内存兜底。这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销。 Kafka提供了一个参数：producer.type 来控制是不是主动 flush，如果Kafka写入到MMAP之后就立即flush然后再返回Producer叫同步(sync)；写入MMAP之后立即返回Producer不调用flush叫异步(async)。 批量数据处理 Kafka 把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候 Kafka 直接把文件发送给消费者。发送文件还有一个好处就是可以对文件进行批量压缩，减少网络IO损耗。 "},"content/Kafka/集群.html":{"url":"content/Kafka/集群.html","title":"集群","keywords":"","body":"控制器Controller 在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个 集群中所有分区和副本的状态。 当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。 选举 在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker 就会成为集群的总控器controller。 当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，zookeeper又会保证有一个broker 成为新的controller。 功能 监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker 增减的变化。 监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减 的变化。为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。 从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic 所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的 分区分配变化。 更新集群的元数据信息，同步到其他普通的broker节点中。 Partition副本 消息的读写操作都只会由leader节点来接收和处理。follower副本只负责同步数据以及当 leader副本所在的broker挂了以后，会从follower副本中选取新的leader。 LEO：即日志末端位移(log end offset)，记录了该副本底层日志(log)中下一条消息的位移值。 HW：取一个partition对应的ISR中最小的LEO作为HW， leader会等待该消息被所有ISR中的replicas同步后更新HW， 此时消息才能被consumer消费。对于同一个副本，HW值不会大于LEO值。小于等于HW值的所有消息都被认为是“已备份”的(replicated)。 ISR副本:包含了leader副本和所有与leader副本保持同步的follower副本 副本协同 kafka通过ISR集合来维护一个分区副本信息。ISR集合中的副本必须满足两个条件： 副本所在节点必须维持着与zookeeper的连接 replica.lag.time.max.ms:该follower在此时间间隔内需要追上leader的offset，则该follower就会被剔除isr列表。kafk副本管理器会启动一个副本过期检查的定时任务 副本同步 初始状态下，leader和follower的HW和LEO都是0，leader副本会保存remote LEO，表示所有follower LEO，也会被初始化为0。follower会不断地个leader发送FETCH 请求，这个请求会被leader寄存，当在指定的时间之后会强制完成请求，或有消息发送会唤醒 fetch请求。 leader收到请求，把消息追加到log文件，同时更新leader副本的LEO。 leader会比较自己的LEO以及remote LEO的最小值，与HW的值相比进行更新。 follower 发送fetch请求，leader读取log数据、把消息内容和当前分区的HW值发送给follower副本。 follower收到response，将消息写入到本地log，同时更新follower的LEO。HW为本地的LEO和leader返回的HW进行比较取小的值。 follower发第二次fetch请求，leader读取log数据，根据follower的offset更新remote LEO。更新当前分区的HW。把数据和当前分区的HW值返回给follower副本，这个时候如果没有数据，则返回为空。 follower收到response，如果有数据则写本地日志，并且更新LEO，更新follower的HW值。 数据丢失 min.insync.replicas=1，即ISR中的最小副本数是1。一旦消息被写入leader端log即被认为是“已提交”，而延迟一轮FETCH RPC更新HW值的设计使 得follower HW值是异步延迟更新的，倘若在这个过程中leader发生变更，那么成为新leader的 follower的HW值就有可能是过期的，使得clients端认为是成功提交的消息被删除。 在kafka0.11.0.0版本之后，引入了一个leader epoch来解决这个问题，所谓的leader epoch实际上是 一对值(epoch，offset)。当leader发生过变更，epoch 就+1，而offset则是对应这个epoch版本的leader写入第一条消息的offset。这个信息会持久化在对应的分区的leader-epoch-checkpoint文件中。 副本选举 KafkaController会监听ZooKeeper的/brokers/ids节点路径，一旦发现有broker挂了，执行下面的逻辑 leader副本在该broker上的分区就要重新进行leader选举，目前的选举策略是 优先从isr列表中选出第一个作为leader副本， 如果isr列表为空，则查看该topic的unclean.leader.election.enable配置。为true则代表允许选用非isr列表的副本作为leader。false的话，则表示不允许，直接抛出NoReplicaOnlineException异常，造成leader副本选举失败。 一旦选举成功，则将选举后的leader和isr和其他副本信息写入到该分区的对应的zk路径上。 消费端Rebalance Kafka提供了一个角色coordinator来执行对于consumer group的管理。 如下情况可能会触发消费者rebalance 同一个consumer group内消费者数量发生变化 动态给topic增加了分区 消费组订阅了更多的topic 选择组协调器 每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控 这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker 就是这个consumer group的coordinator。 GroupCoordinator会在zookeeper上添加watcher，当消费者加入或者退出consumer group时，会修改zookeeper上保存的数据，触发Rebalance操作 JOIN GROUP 所有的成员都会向coordinator发送joinGroup的请 求。一旦所有成员都发送了joinGroup请求，那么coordinator会选择一个consumer担任leader角色， 并把组成员信息和订阅信息发送消费者 leader选举算法比较简单，如果消费组内没有leader，那么第一个加入消费组的消费者就是消费者 leader，如果这个时候leader消费者退出了消费组，那么重新选举一个leader，这个选举很随意，类似于随机算法。 每个消费者都可以设置自己的分区分配策略，对于消费组而言，会从各个消费者上报过来的分区分配略中通过投票来决定。 SYNC GROUP 每个消费者都会向coordinator发送syncgroup请求，不过只有leader节点会发送分配方案。当leader把方案发给coordinator以后，coordinator会把结果设置到 SyncGroupResponse。成员处理SyncGroupResponse响应，知道自己应该消费哪个分区。 MetaData 对于集群中的每一个broker都保存着相同的完整的整个集群的metadata信息 metadata信息里包括了每个topic的所有partition的信息，broker信息， Kafka客户端从任一broker都可以获取到需要的metadata信息 集群中有broker或分区数据发生了变更就需要更新，通过发送异步更新请求(UpdateMetadata request)来维护一致性。 Zookeeper作用 Broker注册 在Zookeeper上会有一个专门用来进行Broker服务器列表记录的节点：/brokers/ids。每个Broker在启动时，都会到Zookeeper上进行注册，即到/brokers/ids下创建属于自己的节点。创建完节点后，每个Broker就会将自己的IP地址和端口信息记录到该节点中去。其中，Broker创建的节点类型是临时节点，一旦Broker宕机，则对应的临时节点也会被自动删除。 Topic注册 同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护，由专门的节点来记录。 如/brokers/topics/login/3->2，这个节点表示Broker ID为3的一个Broker服务器，对于\"login\"这个Topic的消息，提供了2个分区进行消息存储，同样，这个分区节点也是临时节点。 生产者负载均衡 使用Zookeeper进行负载均衡，由于每个Broker启动时，都会完成Broker注册过程，生产者会通过该节点的变化来动态地感知到Broker服务器列表的变更，这样就可以实现动态的负载均衡机制。 控制器选举 "},"content/Kafka/MQ设计.html":{"url":"content/Kafka/MQ设计.html","title":"MQ设计","keywords":"","body":"消息中间件对比 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是 RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 可靠投递 1.消息落库（持久化至数据库），对消息状态进行打标，如若消息未响应，进行轮询操作。 2.消息的延迟投递，做二次确认，回调检查。 消费的幂等性 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。 消息顺序性 建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。 消费者从 partition 中取出来数据的时候，也一定是有顺序。写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可。 MQ消息积压 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。 "},"content/Netty/Netty.html":{"url":"content/Netty/Netty.html","title":"Netty","keywords":"","body":"I/O发展 BIO NIO 同步非阻塞，服务器实现模式为一个线程可以处理多个请求(连接)，客户端发送的连接请求都会注册到多路复用器selector上，多路复用 器轮询到连接有IO请求就进行处理。 I/O多路复用底层一般用的Linux API(select，poll，epoll)来实现，他们的区别如下表: select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 哈希表 IO效率 每次调用都进行线 性遍历，时间复杂 度为O(n 每次调用都进行 线性遍历，时间 复杂度为O(n) 事件通知方式，每当有IO事件 就绪，系统注册的回调函数就 会被调用 最大连接 有上限 无上限 无上限 NIO相对于BIO非阻塞的体现就在，BIO的后端线程需要阻塞等待客户端写数据(比如read方法)，如果客户端不写数据线程就要阻塞， NIO把等待客户端操作的事情交给了大总管 selector，selector 负责轮询所有已注册的客户端，发现有事件发生了才转交给后端线程处 理，后端线程不需要做任何阻塞等待，直接处理客户端事件的数据即可，处理完马上结束，或返回线程池供其他客户端事件继续使用。还 有就是 channel 的读写是非阻塞的。 AIO 异步非阻塞， 由操作系统完成后回调通知服务端程序启动线程去处理， 一般适用于连接数较多且连接时间较长的应用 同步、阻塞 阻塞、同步。针对的是磁盘的IO读写。 阻塞和非阻塞是进程在访问数据的时候，数据是否准备就绪的一种处理方式。阻塞需要等待缓冲区中的数据准备好过后才处理其他的事情。 同步和异步都是基于应用程序和操作系统处理 IO 事件所采用的方式。同步是应用程序要直接参与 IO 读写的操作。异步是所有的 IO 读写交给操作系统去处理，应用程序只需等待通知。 netty高性能 异步非阻塞通信 Netty 的 IO 线程 NioEventLoop 聚合了多路复用器 Selector，可以同时并发处理成百上千个客户端 Channel，由于读 写操作都是非阻塞的，这就可以充分提升 IO 线程的运行效率，避免由于频繁 IO 阻塞导致的线程挂起。另外，由于 Netty 采用了异步通信模式，一个 IO 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 IO 一 连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。 主从Reactor线程模型 服务端用于接收客户端连接的是一个独立的 NIO 线程池。Acceptor 接收到客户端 TCP 连接请求处理完成后(可能包含接入认证等)，将新创建的 SocketChannel 注册到 IO 线程池(sub reactor 线程池)的某个 IO 线程上，由它负责 SocketChannel 的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端 subReactor 线程池的 IO 线程上，由 IO 线程负责后续的 IO 操作。 Netty 的线程模型并非固定不变，通过在启动辅助类中创建不同的 EventLoopGroup 实例并通过适当的参数 配置，就可以支持上述三种 Reactor 线程模型 无锁串行化设计思想 Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。 Netty的NioEventLoop读取到消息之后，直接调用ChannelPipeline的fireChannelRead(Object msg)，只要用户不主动切换线程，一直 会由NioEventLoop调用到用户的Handler，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁的竞争，从性能角度 看是最优的。 支持高性能序列化协议 Netty 默认提供了对 Google Protobuf 的支持。同时通过扩展 Netty 的编解码接口，用户可以实现其它的高性能序列化框架。 零拷贝(直接内存的使用) Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲 区的二次拷贝。 Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffe Netty 的文件传输采用了 transferTo()方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过 循环 write()方式导致的内存拷贝问题 ByteBuf内存池设计 Netty 提供了基于内存池的缓冲区重用机制。 灵活的TCP参数配置能力 Netty在启动辅助类ChannelOption中可以灵活的配置TCP参数，满足不同的用户场景。 并发优化 volatile的大量、正确使用。 CAS和原子类的广泛使用。 线程安全容器的使用。通过读写锁提升并发性能。 Netty线程模型 EventLoopGroup NioEventLoopGroup，主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件，而一个 Channel 只对应于一个线程。 NioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务。 主从Reactor模型的设置 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup); 单线程Reactor模型的设置 EventLoopGroup bossGroup = new NioEventLoopGroup(1); ServerBootstrap server = new ServerBootstrap(); server.group(bossGroup); 多线程线程Reactor模型的设置 EventLoopGroup bossGroup = new NioEventLoopGroup(128); ServerBootstrap server = new ServerBootstrap(); server.group(bossGroup); ChannelPipeline 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作。 ChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互。 一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。 ChannelHandler 是一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业 务处理链)中的下一个处理程序。 read事件(入站事件)和write事件(出站事件)在一个双向链表中，入站事件会从链表 head 往后传递到最 后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。 粘包拆包 TCP粘包拆包是指发送方发送的若干包数据到接收方接收时粘成一包或某个数据包被拆开接收。解决方案： 格式化数据:每条数据有固定的格式(开始符、结束符)，这种方法简单易行，但选择开始符和结束符的时候一定要注意每条数据的内部一定不能出现开始符或结束符。 发送长度:发送每条数据的时候，将数据的长度一并发送，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以根据长度 来判断每条数据的开始和结束。 "},"content/ES/基本概念.html":{"url":"content/ES/基本概念.html","title":"基本概念","keywords":"","body":"版本 5.x。打分机制从TF-IDF改为BM 25。移除避免同一文档并发更新的竞争锁。支持分片上的聚合缓存。 6.x。跨集群复制，索引生命周期管理，sql支持。 7.0。移除单索引多type支持。默认主分片改为1。 基本概念 节点 Date Node：保存数据的节点 Coordinaing Node：负责接受Client的请求，将请求分发到合适的节点，最终把结果汇集到一起。每个节点默认起到该作用。 Maser-eligible nodes：可以参加选主流程的节点 Master Node Ingest Node：在数据被索引之前，通过预定义好的处理管道对数据进行预处理。默认情况下，所有节点都启用Ingest 分片 主分片：用以解决数据水平扩展，能将数据分布到集群所有节点上。索引创建时制定，后续不允许修改，除非reindex。 副本分片：是主分片的拷贝，提高可用性和读取的吞吐。 倒排索引 倒排索引包含两个部分 单词词典。记录所有文档的单词，记录单词到倒排列表的关联关系。 倒排列表。记录了单词对应的文档组合。由文档id，词频，单词在文档中的位置，单词开始结束的偏移量。 在 term dictionary 的基础上添加了 term index 来加速检索， term index 是一棵 trie 树（前缀树），缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access 次数。 分词器 基本操作 document是不可变的，如果要修改document的内容，更新时，将老的document标记为deleted，然后新增我们给定的一个document。 聚合分析 分类 Bucket Aggregaion：一些满足特定条件文档的集合 Metric Aggregaion：一些数学运算，可以对文档字段进行统计分析 Pipeline Aggregaion：对其他的聚合结果进行二次聚合 Matric Aggregaion：支持对多个字段的操作并提供一个结果矩阵 实现 Fielddate和Doc Values。Doc Values对Text无效。 Doc Values采用列式压缩存储。 Doc Values Field data 时间 索引时，和倒排索引一起创建 搜索时动态创建 位置 磁盘文件 JVM Heap 优点 避免大量内存占用 索引速度快 缺点 降低索引速度，占用磁盘空间 动态创建开销大，占用内存空间 行式存储 列式存储 优点 Ø 数据被保存在一起Ø INSERT/UPDATE容易 Ø 查询时只有涉及到的列会被读取Ø 投影(projection)很高效Ø 任何列都能作为索引 缺点 Ø 选择(Selection)时即使只涉及某几列，所有数据也都会被读取 Ø 选择完成时，被选择的列要重新组装Ø INSERT/UPDATE比较麻烦 精准度 调整shard size大小。从shard上额外多获取数据。 分页 简单from+size。必须小于10000。 search after。不支持制定页数，只能往下翻。 Scroll API。scoll搜索会在第一次搜索的时候，保存一个当时的视图快照，之后只会基于该旧的视图快照提供数据搜索。获得的结果会有一个scoll_id，下一次再发送scoll请求的时候，必须带上这个scoll_id。 重建索引 并发控制 ES采用的是乐观并发控制，第一次创建一个document的时候，它的_version内部版本号就是1；以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1；哪怕是删除，也会对这条数据的版本号加1 version_type=external，唯一的区别在于，_version，只有当你提供的version与es中的_version一模一样的时候，才可以进行修改，只要不一样，就报错；当version_type=external的时候，只有当你提供的version比es中的_version大的时候，才能完成修改 retry_on_conflict=5重试机制。 相关性算分 词频TF。检索词出现的次数除以文档的总字数。 逆文档频率IDF。log(全部文档数/检索词出现的文档总数) ES 5以后没人算法改为BM 25。 Boosting是控制相关度的一种手段，在索引、字段、查询子条件。 boost>1，相关度提升，0到1，权重降低，小于0，贡献负分 "},"content/ES/集群.html":{"url":"content/ES/集群.html","title":"集群","keywords":"","body":"集群状态 green 健康状态，指所有主副分片都正常分配 yellow 指所有主分片都正常分配，但是有副本分片未正常分配 red 有主分片未分配 三种状态只是代表分片的工作状态，并不是代表整个es集群是否能够对外提供服务 故障转移 集群由三个节点组成。node1所在机器宕机导致服务终止。node2和node3发现node1无法响应一段时间后会发起maser选举。此时由于主分片P0下线，集群状态变为red master发现主分片P0未分配，将R0提升为主分片，集群状态变为yello 脑裂问题。 node2与node3会重新选举master，比如node2成为了新master，此时会更新cluster state。node1自己组成集群后，也会更新cluster state。同一个集群有两个master，而维护不同的cluster state，网络恢复后无法选择正确的maste。 解决方案为仅在可选举master-eligible节点数据大于等于quorum时才可以进行master选举。quorum = master-eligible 节点数/2 + 1。 设置config/elasticsearch.yml参数配置 discovery.zen.mininum_master_nodes为quorum即可避免脑裂。 分布式存储 存储算法 通过如下公式计算 shard = hash(routing)%number_of_primary_shards， routing默认是文档id，number_of_primary_shards是主分片数 这也是分片数一旦确定后不能更改的原因。 原理 倒排索引不能更改，如果重新再替换实时性受到影响。所以新文档直接生成新的倒排索引文件，查询的时候同时查询所有的倒排文件，然后对查询结果做汇总计算即可。 Lucene构建的单个倒排索引称为segment，合在一起称为Index(Lucene中的名称)，ES中的一个Shard对应一个Lucene Index。Lucene会有一个专门的文件来记录所有的segment信息，称为 Commit Point segment写入磁盘的过程依然很耗时，先将segment在缓存中创建并开放查询来进一步提升实时性，该过程在es中被称为refresh。在refresh之前文档会先存储在一个buffer中，refresh时将buffer中的所有文档清空并生成segmentes。默认每1秒执行一次refresh，因此文档的实时性被提高到1秒，这也是es被称为近实时（Near Real Time）的真正原因 如果在内存中的segment还没有写入磁盘前发生了宕机，那么内存中的文档就无法恢复了。es引入translog机制。写入文档到buffer时，同时将该操作写入translog。translog 文件会即时写入磁盘（fsync），6.x默认每个请求都会落盘，可以修改为每5秒写一次，这样风险便是丢失5秒内的数据，相关配置为index.translog.*es重新启动时会自动检查translog文件，并从中恢复数据。　 lush负责将内存中的segment写入磁盘，主要做如下的工作：将translog写入磁盘。将index buffer清空，其中的文档生成一个新的segment，相当于一个refrsh操作。更新commit point并写入磁盘。执行fsync操作，将内存中的segment写入磁盘。删除旧的translog文件　 refresh发生的时机主要有以下几种情况：间隔时间达到时，通过index.settings.refresh_interval来设定，默认是1秒。index.buffer占满时，其大小通过indices.memory.index_buffer_size设置，默认为jvm heap的10%，所有shard共享flush发生时也会发生refresh。间隔时间达到时，默认是30分钟。translog占满时。 segment一旦生成就不能更改，那么如果要删除文档，lucene会专门维护一个.del的文件，记录所有已经删除的文档，注意.del上记录的是文档在Lucene的内部id,在查询结果返回前会过滤掉.del中所有的文档 更新文档，首先删除文档，然后再创建新的文档　　 随着segment的增多，由于一次查询的segment数增多，查询速度会变慢,es会定时在后台进行segment merge的操作，减少segment的 数量，通过force_merge api可以手动强制做segment merge的操作。 集群选举 发起 master选举当然是由master-eligible节点发起，当一个master-eligible节点发现满足以下条件时发起选举： 该master-eligible节点的当前状态不是master。 该master-eligible节点通过ZenDiscovery模块的ping操作询问其已知的集群其他节点，没有任何节点连接到master。 包括本节点在内，当前已有超过minimum_master_nodes个节点没有连接到master。 总结一句话，即当一个节点发现包括自己在内的多数派的master-eligible节点认为集群没有master时，就可以发起master选举。 选举规则 先根据节点的clusterStateVersion比较，clusterStateVersion越大，优先级越高。clusterStateVersion相同时，进入compareNodes，其内部按照节点的Id比较(Id为节点第一次启动时随机生成)。节点的Id越小，优先级越高。 过程 筛选activeMasters列表：的master就是从activeMasters列表或者masterCandidates列表选举出来，所以选举之前es首先需要得到这两个列表。Elasticsearch节点成员首先向集群中的所有成员发送Ping请求，elasticsearch默认等待discovery.zen.ping_timeout时间，然后elasticsearch针对获取的全部response进行过滤，筛选出其中activeMasters列表，activeMaster列表是其它节点认为的当前集群的Master节点 筛选masterCandidates列表：masterCandidates列表是当前集群有资格成为Master的节点。 从activeMasters列表选举Master节点：activeMaster列表是其它节点认为的当前集群的Master节点列表，如果activeMasters列表不为空，elasticsearch会优先从activeMasters列表中选举，也就是对应着流程图中的蓝色框，选举的算法是Bully算法 从masterCandidates列表选举Master节点：如果activeMaster列表为空，那么会在masterCandidates中选举，masterCandidates选举也会涉及到优先级比较 经过上述选举之后，会选举出一个准master节点。准master节点会等待其它节点的投票。 分布式搜索 ES的搜索会分两阶段进行，query和fetch。 query阶段。用户发出搜索请求到ES，节点收到请求后，会随机选择主副分片，发送查询请求。被选中的分片执行查询，然后排序。每个分片返回From+Size个排序后的文档id和排序值给节点。 fetch阶段。将query阶段从每个分片获取到的排序后文档id列表，重新排序，选取From到From+Size过文档的id。以mutli get请求的方式，到相应的分片获取详细的文档数据 每个分片都需要取form+size个文档，协调节点需要处理shard*(from+size)。每个分片都基于自己的分片上的数据进行相关性算法，导致打分偏移。 数据量不大时将主分片设置为1。数据量大时保证文档均匀分散在各个分片上。使用DFS Query Then Fetch，到每个分片把词频和文档频率进行搜集，进行完成的一次相关性算分。 联合查询 给定查询过滤条件 age=18 的过程就是先从 term index 找到 18 在 term dictionary 的大概位置，然后再从 term dictionary 里精确地找到 18 这个 term，然后得到一个 posting list 或者一个指向 posting list 位置的指针。然后再查询 gender= 女 的过程也是类似的。最后得出 age=18 AND gender= 女 就是把两个 posting list 做一个“与”的合并。 使用 skip list 数据结构。同时遍历 gender 和 age 的 posting list，互相 skip； 使用 bitset 数据结构，对 gender 和 age 两个 filter 分别求出 bitset，对两个 bitset 做 AN 操作。 Elasticsearch 支持以上两种的联合索引方式，如果查询的 filter 缓存到了内存中（以 bitset 的形式），那么合并就是两个 bitset 的 AND。如果查询的 filter 没有缓存，那么就用 skip list 的方式去遍历两个 on disk 的 posting list。 "},"content/Spring/IOC.html":{"url":"content/Spring/IOC.html","title":"IOC","keywords":"","body":"基本概念 IOC(Inversion of Control)控制反转。所谓控制反转，就是把原先我们代码里面需要实现的对象创建、依赖的代码，反转给容器来帮忙实现。那么必然的我们需要创建一个容器，同时需要一种描述来让容器知道需要创建的对象与对象的关系。这个描述最具体表现就是我们所看到的配置文件。 核心类 BeanFactory BeanFactory 作为最顶层的一个接口类，它定义了 IOC 容器的基本功能规范。只对 IOC 容器的基本行为作了定义。同时Spring 提供了许多 IOC 容器的实 现 ，ClasspathXmlApplication。 BeanFactory 有三 个重要的子类:ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory。主要是为了区分在 Spring 内部在操作过程中对象的传递和转化过程时，对对象的数据访问所做的限制。 BeanDefinition SpringIOC 容器管理了我们定义的各种 Bean 对象及其相互的关系，Bean 对象在 Spring 实现中是 以 BeanDefinition 来描述的。 BeanDefinitionReader Bean 的解析主要就是对 Spring 配置文件的解析。这个解析过程主要通过 BeanDefintionReader 来完成。 基于Xml的IOC容器初始化 IOC 容器的初始化包括定位、加载和注册这三个基本的过程。 定位。定位配置文件和扫描相关的注解。 加载。将配置信息 载入到内存中。 注册。根据载入的信息，将对象初始化到IOC容中。 1.获得配置路径 Spring IOC容器在初始化时将配置的 Bean 配置信息定位为 Spring 封装的 Resource。 2.开始启动 ClassPathXmlApplicationContext、XmlWebApplicationContext 等都继承自父容器 AbstractApplicationContext。主要用到了装饰器模式和策略模式，最终都是调用同一个refresh()方法。 refresh()是一个模板方法，规定了 IOC 容器的启动流程。 public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { //STEP 1、调用容器准备刷新的方法，获取容器的当时时间，同时给容器设置同步标识 prepareRefresh(); // STEP 2: //a) 创建IoC容器(DefaultListableBeanFactory) //b) 加载解析XML文件(最终存储到Document对象中) //c) 读取Document对象，并完成BeanDefinition的加载和注册工作 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // STEP 3: 为 BeanFactory 配置容器特性，例如类加载器、事件处理器等 prepareBeanFactory(beanFactory); // STEP 4:为容器的某些子类指定特殊的 BeanPost 事件处理器 postProcessBeanFactory(beanFactory); // STEP 5: 调用BeanFactoryPostProcessor后置处理器对BeanDefinition处理 //@ invokeBeanFactoryPostProcessors(beanFactory); // STEP 6: 注册BeanPostProcessor后置处理器 registerBeanPostProcessors(beanFactory); // STEP 7: 初始化一些消息源(比如处理国际化的i18n等消息源) initMessageSource(); // STEP 8: 初始化容器事件传播器 initApplicationEventMulticaster(); // STEP 9: 初始化一些特殊的bean onRefresh(); // STEP 10: 注册一些监听器 registerListeners(); // STEP 11: 实例化剩余的单例bean(非懒加载方式) finishBeanFactoryInitialization(beanFactory); // STEP 12: 完成刷新时，需要发布对应的事件 finishRefresh(); } 3.创建容器 在这个方法中，先判断 BeanFactory 是否存在，如果存在则先销毁 beans 并关闭 beanFactory，接着创建 DefaultListableBeanFactory，并调用 loadBeanDefinitions(beanFactory)装载 bean 定义。 4.载入配置路径 5.解析配置文件路径 6.读取配置内容 载入 Bean 配置信息，将 Bean 配置信息转换为 Document 对象 7.解析配置文件 在完成通用的 XML 解析之后，按照 Spring Bean 的定义规则对 Document 对象进行解析。首先解析\\元素，然后解析\\、\\等元素。 在解析\\元素过程中没有创建和实例化 Bean 对象，只是创建了 Bean 对象的定义类 BeanDefinition，将\\元素中的配置信息设置到 BeanDefinition 中。 8.向容器注册 DefaultListableBeanFactory 中使用一个 HashMap 的集合对象存放 IOC 容器中注册解析的 BeanDefinition。 现在 IOC 容器中已经建立了整个 Bean 的配置信息，这些 BeanDefinition 信息已经可以使用，并且可以被检索，IOC 容器的作用就是对这些注册的 Bean 定义信息进行处理和维护。 基于 Annotation 的 IOC 初始化 包括定位bean扫描路径、读取元数据、解析、注册这四个步骤 解析主要内容为 Bean 中关于作用域的配置、处理注解 Bean 定义类中通用的注解、创建对于作用域的代理对象 "},"content/Spring/DI.html":{"url":"content/Spring/DI.html","title":"DI","keywords":"","body":"基本概念 DI(Dependency Injection)依赖注入：就是指对象是被动接受依赖类而不是自己主动去找，换句话说就是指对象不是从容器中查找它依赖的类，而是在容器实例化对象的时候主动将它依赖的类注入给它。 发生时间 当 Spring IOC 容器完成了 Bean 定义资源的定位、载入和解析注册以后，IOC 容器中已经管理类 Bean 定义的相关数据，但是此时 IOC 容器还没有对所管理的 Bean 进行依赖注入，依赖注入在以下两种情况 发生: 用户第一次调用 getBean()方法时，IOC 容器触发依赖注入。 当用户在配置文件中将\\元素配置了 lazy-init=false 属性，即让容器在解析注册 Bean 定义时进行预实例化，触发依赖注入。 getBean方式流程 1.入口 getBean()---->doGetBean()----->createBean()----->createBeanInstance()方法，生成 Bean 所包含的 java 对象实例。populateBean()方法，对 Bean 属性的依赖注入进行处理。 如果 Bean 定义的单例模 式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象。如果 Bean 定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。 2.选择初始化策略 使用工厂方法和自动装配特性的 Bean 的实例化调用相应的工厂方法或者参数匹配的构造方法即可完成实例化对象的工作。 最常使用的默认无参构造方法就需要使用相应的初始化策略(JDK 的反射机制或者 CGLib)来进行初始化了 3.执行实例化 如果 Bean 有方法被覆盖了，则使用 JDK 的反射机制进行实例化，否 则使用 CGLib 进行实例化。 4.准备依赖注入 属性值类型不需要强制转换时，不需要解析属性值，直接准备进行依赖注入。 属性值需要进行类型强制转换时，如对其他对象的引用等，首先需要解析属性值，然后对解析后的属性值进行依赖注入。 5.解析属性 解析引用类型的属性值时，首先获取引用的 Bean 名称。如果引用的对象在父类容器中则从父类容器中获取指定的引用对象。 从当前的容器中获取指定的引用 Bean 对象，如果指定的 Bean 没有被实例化，则会递归调用getbean()触发引用 Bean 的初始化和依赖注入 6.依赖注入 对容器中完成初始化的 Bean 实例对象进行属性的依赖注入，即把 Bean 对象设置到它所依赖的另一个 Bean 的属性中去。 对于集合类型的属性，将其属性值解析为目标类型的集合后直接赋值给属性。 对于非集合类型的属性，大量使用了 JDK 的反射机制，通过属性的 getter()方法获取指定属性注入以前的值，同时调用属性的 setter()方法为属性设置注入后的值。 @Autowired 在bean实例化之后，调用MergedBeanDefinitionPostProcessor 后处理器，Autowire等注解信息就是在这一步完成预解析，并且将注解需要的信息放入缓存。 在依赖注入阶段，IOC 容器根据 Bean 名称或者类型进行自动依赖注入 延时加载 当 Bean 定义资源的\\元素中配置了 lazy-init=false 属性时，容器将会在初始化的时候对所配置 的 Bean 进行预实例化，Bean 的依赖注入在容器初始化的时候就已经完成。 容器在完成 Bean 定义的注册之后，在refresh()方法中调用finishBeanFactoryInitialization(beanFactory)，通过 getBean 方法，触发对指定 Bean 的初始化和依赖注入过程。 循环依赖 先从一级缓存singletonObjects中去获取。如果获取到就直接return。 如果获取不到或者对象正在创建中(isSingletonCurrentlyInCreation())，那就再从二级缓存earlySingletonObjects中获取。如果获取到就直接return。 如果还是获取不到，且允许singletonFactories(allowEarlyReference=true)通过getObject()获取。就从三级缓存singletonFactory.getObject()获取。如果获取到了就从singletonFactories中移除，并且放进earlySingletonObjects。其实也就是从三级缓存移动到了二级缓存 加入singletonFactories三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决 三级缓存的目的 singletonFactories这个三级缓存，里面都是ObjectFactory。先实例化的bean会通过ObjectFactory半成品提前暴露在三级缓存中。 如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题，如果加上AOP，两级缓存是无法解决的，不可能每次执行singleFactory.getObject()方法都给我产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象 "},"content/Spring/AOP.html":{"url":"content/Spring/AOP.html","title":"AOP","keywords":"","body":"基本概念 面向切面编程。可以通过预编译方式和运行期动态代理实现在不修改源代码的情况下给程序动态统一添加功能的一种技术。 切面(Aspect)：切面是通知和切点的结合 连接点(Joinpoint)：程序执行过程中的某一行为，例如，MemberService .get 的调用 通知(Advice)：切面对于某个连接点所产生的动作 切入点(Pointcut)：匹配连接点的断言，在 AOP 中通知和一个切入点表达式关联 AOP 代理：TargetObject 实现了接口时采用 JDK 动态代理，反之，采用 CGLib 代理 AOP生成 1.入口 Spring 的 AOP 是通过接入 BeanPostProcessor 后置处理器开始的。 后置处理器是一个监听器，可以监听容器触发的 Bean 声明周期事件。后置处 理器向容器注册以后，容器中管理的 Bean 就具备了接收 IOC 容器事件回调的能力。 public interface BeanPostProcessor { //为在 Bean 的初始化前提供回调入口 @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } //为在 Bean 的初始化之后提供回调入口 @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } } BeanPostProcessor 后置处理器的调用发生在 Spring IOC 容器完成对 Bean 实例对象的创建和属性的依赖注入完成之后。 createBeanInstance()实例化----->populateBean()依赖注入---->initializeBean()初始化 initializeBean()实现了初始化前回调、调用 Bean 实例对象初始化方法(可以用init-Method指定)、初始化后回调。 AOP代理对象在初始化后回调中生成。 2.选择代理策略 最终调用的是 proxyFactory.getProxy()，proxyFactory 有 JDK 和 CGLib。 AOP调用 InvocationHandler 是 JDK 动态代理的核心，生成的代理对象的方法调用都会委托到 InvocationHandler.invoke()方法。 主要实现思路可以简述为：首先获取应用到此方法上的通知链(Interceptor Chain)。如果有通知，则应用通知，并执行 JoinPoint。如果没有通知，则直接反射执行 JoinPoint 通知链 从提供的配置中获取 advisor列表，遍历处理这些 advisor。判断此 Advisor能否应用到目标类上。如果是 PointcutAdvisor，则判断此 Advisor能否应用到目标方法 Method上。将满足条件的 Advisor 通过 AdvisorAdaptor 转化成 Interceptor 列表返回，同时会被缓存起来。 如果得到的拦截器链为空，则直接反射调用目标方法，否则创建 MethodInvocation，递归调用其 proceed()方法，触发拦截器链的执行。 "},"content/Spring/事务.html":{"url":"content/Spring/事务.html","title":"事务","keywords":"","body":"事务的传播属性 spring 事务的传播属性，就是定义在存在多个事务同时存在的时候，spring 应该如 何处理这些事务的行为。这些属性在 TransactionDefinition 中定义。 常量名称 常量解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务，Spring 默认的事务的传播 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务 挂起。新建的事务将和被挂起的事务没有任 何关系，是两个独立的事务，外层事务失败 回滚之后，不能回滚内层事务执行的结果， 内层事务失败抛出异常，外层事务捕获，也 可以不处理回滚操作 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按 REQUIRED 属性执行。它使用了一个单独的 事务，这个事务拥有多个可以回滚的保存 点。内部事务的回滚不会对外部事务造成影 响。它只对 DataSourceTransactionManager 事务管 理器起效。 Spring隔离级别 常量 解释 ISOLATION_DEFAULT 默认的隔离级别，使用数据库的事务隔离级别。 ISOLATION_READ_UNCOMMITTED 允许另外一个事务可以看到这个事务未提交的数据 ISOLATION_READ_COMMITTED 保证一个事务修改的数据提交后才能被另 外一个事务读取 ISOLATION_REPEATABLE_READ 这种事务隔离级别可以防止脏读，不可重复 读。但是可能出现幻像读。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离 级别。事务被处理为顺序执行。 事务不生效 调用的方法必须是public，否则事务不起作用。这一点由Spring的AOP特性决定的。 Spring的事务管理默认只对出现运行期异常(java.lang.RuntimeException及其子类)进行回滚 在同一个类中一个无事务的方法调用另一个有事务的方法，事务是不会起作用的。没有通过代理去走此方法，从而没有开启事务. propagation 设置错误 Spring事务的三大接口 实现原理 创建 Spring 在初始化时候，如果遇到诸如 开头的配置后，将会使用 AnnotationDrivenBeanDefinitionParser 解析器的 parse 方法进行解析。 与 AOP 一样，在解析时，会创建一个自动创建代理器，在事务 TX 模块中，使用的是 InfrastructureAdvisorAutoProxyCreator。 Spring 中的事务默认是以 AOP 为基础。 bean 实例化时，Spring都会保证调用其postProcessAfterInitialization 方法。在匹配 match操作中，区别的是 AOP 识别的是 @Before 、@After，而我们的事务 识别的是 @Transactional标签。 调用 获取拦截器链时，判断是否调用事务拦截器。进行invokeWithinTransaction反射调用 反射调用过程中，获取事务的属性，加载事务管理器，获取事务信息。然后执行目标方法，最后提交或者回滚。 "},"content/Spring/MVC.html":{"url":"content/Spring/MVC.html","title":"MVC","keywords":"","body":"Spring MVC 请求处理流程 客户端发起request请求 转发至对应的controller 业务逻辑处理，设置Model和返回页面 转发至视图处理器，基于模版和模型转化输出 基于response返回 源码分析 1.初始化 IOC 容器初始化之后，最后调用了onRefresh()方法，初始化 Spring MVC 的九大组件。 //多文件上传的组件 initMultipartResolver(context); //初始化本地语言环境 initLocaleResolver(context); //初始化模板处理器 initThemeResolver(context); //handlerMapping initHandlerMappings(context); //初始化参数适配器 initHandlerAdapters(context); //初始化异常拦截器 initHandlerExceptionResolvers(context); //初始化视图预处理器 initRequestToViewNameTranslator(context); //初始化视图转换器 initViewResolvers(context); //FlashMap 管理器 initFlashMapManager(context); 2.HandlerMapping 获取 ApplicationContext 容器中所有 bean 的 Name，遍历 beanNames,并找到这些 bean 对应的 url，保存 urls 和 beanName 的对应关系，Map。 3.调用 从 Map中取得 Controller 后，经过拦截器的预处理方法，再通过反射获取该方法上的注解和参数，解析方法和参数上的注解，然后反射调用方法获取ModelAndView 结果视图。最后，调用的就是 RequestMappingHandlerAdapter 的 handle()中的核心逻辑由 handleInternal(request, response, handler)实现。 整个处理过程中最核心的逻辑其实就是拼接 Controller 的 url 和方法的 url，与 Request 的 url 进行匹配，找到匹配的方法 Spring MVC 中提供两种 Request 参数到方法中参数的绑定方式 通过注解进行绑定，@RequestParam。 通过参数名称进行绑定。 使用注解进行绑定，我们只要在方法参数前面声明@RequestParam(\"name\")，就可以 将 request 中参数 name 的值绑定到方法的该参数上。使用参数名称进行绑定的前提是 必须要获取方法中参数的名称，Java 反射只提供了获取方法的参数的类型，并没有提供 获取参数名称的方法。SpringMVC 解决这个问题的方法是用 asm 框架读取字节码文件， 来获取方法的参数名称。 "},"content/Spring/spring.html":{"url":"content/Spring/spring.html","title":"Spring","keywords":"","body":"生命周期 设计模式 "},"content/SpringCloud/Eureka.html":{"url":"content/SpringCloud/Eureka.html","title":"Eureka","keywords":"","body":"架构图 核心功能 服务注册 Eureka Client会通过发送REST请求的方式向Eureka Server注册自己的服务，提供自身的元数据，比如ip地址、端口、运行状况指标的url、主页地址等信息。Eureka Server接收到注册请求后，就会把这些元数据信息存储在一个双层的Map中。 服务续约 在服务注册后，Eureka Client会维护一个心跳来持续通知Eureka Server，说明服务一直处于可 用状态，防止被剔除。Eureka Client在默认的情况下会每隔30秒(eureka.instance.leaseRenewallIntervalInSeconds)发送一次心跳来进行服务续约。 服务同步 Eureka Server之间会互相进行注册，构建Eureka Server集群，不同Eureka Server之间会进行服务同步，用来保证服务信息的一致性。 获取服务 服务消费者(Eureka Client)在启动的时候，会发送一个REST请求给Eureka Server，获取上面注册的服务清单，并且缓存在Eureka Client本地，默认缓存30秒 (eureka.client.registryFetchIntervalSeconds)。同时，为了性能考虑，Eureka Server也会维护一份只读的服务清单缓存，该缓存每隔30秒更新一次。 服务调用 服务消费者在获取到服务清单后，就可以根据清单中的服务列表信息，查找到其他服务的地址，从而进行远程调用。Eureka有Region和Zone的概念，一个Region可以包含多个Zone，在进行服务调用时，优先访问处于同 一个Zone中的服务提供者。 自我保护机制 Eureka Server每分钟的续约数量要大于85%，如果低于 85%，Eureka Server 会将这些实例保护起来，让这些实例不会过期，但是在保护期内如果服务刚好这个服务提供者非正常下线了，此时服务消费者就会拿到一个无效的服务实例，此时会调用失败 客户端源码 服务注册 在两种情况下客户端会主动向服务端发送自己的注册信息 当客户端刚刚启动的时候。 当客户端的instance信息发生改变时，Eureka-Client和Server端信息不一致时。定时线程，每40秒执行一次。当instance的状态发生变更的时候，会有statusChangeListener 这个监听器监听到去执行服务注册。 class InstanceInfoReplicator implements Runnable { public void start(int initialDelayMs) { if (started.compareAndSet(false, true)) { // 首次进来设置一下。 instanceInfo.setIsDirty(); // for initial register // 开启定时线程,每initialDelayMs秒执行一次该任务。服务注册也由这个任务完成 Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } public void run() { try { // 刷新实例信息。 discoveryClient.refreshInstanceInfo(); // 判断实例信息是否不一致 Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) { // 注册自己的服务 discoveryClient.register(); instanceInfo.unsetIsDirty(dirtyTimestamp); } } catch (Throwable t) { logger.warn(\"There was a problem with the instance info replicator\", t); } finally { Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } 服务拉取 TimedSupervisorTask是固定间隔的周期性任务，一旦遇到超时就会将下一个周期的间隔时间调大，如果连续超时，那么每次间隔时间都会增大一倍，一直到达外部参数设定的上限为止，一旦新任务不再超时，间隔时间又会自动恢复为初始值。TimedSupervisorTask的run方法里，run方法任务执行完最后，会再次调用schedule方法，在指定的时间之后执行一次相同的任务。 同时使用了CAS来控制多线程同步。 增量更新时从服务端获取了最近这段时间，新注册的客户端信息，有过修改的，被删除的， 这三大类的实例信息。然后通过覆盖本地的数据，移除数据，来达到数据合并的需求。 心跳发送 接口地址： apps/ + appName + /' + id ，如果接口返回值为404，就是说不存在，从来没有注册过，那么重新走注册流程。 当客户端的lastDirtyTimestamp大于服务端的instance的lastDirtyTimestamp时候，会认为服务端的信息是无效的，因此无法续约，需要重新发起注册请求。或者服务端的注册信息不存在。 服务端源码 注册请求 多级缓存 Eureka Server的缓存机制依赖于谷歌的gauva cache。 在拉取注册表的时候。 首先从ReadOnlyCacheMap里查缓存的注册表。 若没有，就找ReadWriteCacheMap里缓存的注册表。 如果还没有，就从内存中获取实际的注册表数据。 在注册表发生变更的时候。会在内存中更新变更的注册表数据，同时过期掉ReadWriteCacheMap。 此过程不会影响ReadOnlyCacheMap提供人家查询注册表。 默认每30秒Eureka Server会将ReadWriteCacheMap更新到ReadOnlyCacheMap里。默认每180秒Eureka Server会将ReadWriteCacheMap里是数据失效。下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各级缓存。 多级缓存尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高 当eureka服务实例有注册或下线或有实例发生故障，内存注册表虽然会及时更新数据，但是客户端不一定能及时感知到，可能会过30秒才能感知到，因为客户端拉取注册表实例这里面有一个多级缓存机制。还有服务剔除的不是默认90秒没心跳的实例，剔除的是180秒没心跳的实例(eureka的bug导致)。 自我保护机制 //每分钟续约数，注册和下线进行增减 expectedNumberOfRenewsPerMin = count * 2; //计算每分钟最小续约数的值 numberOfRenewsPerMinThreshold =expectedNumberOfRenewsPerMin * 0. 85 集群同步 SyncUp()这个方法并不会去其他Eureka Server节点复制信息，而是从本地内存里面获取注册信息。 ## 是否作为一个Eureka Client 注册到Eureka Server上去 eureka.client.register-with-eureka = true ## 是否需要从Eureka Server上拉取注册信息到本地。 eureka.client.fetch-registry = true 开启了上面两个配置，那么集群节点在启动的时候，会初始化Eureka Client端的配置 ，会从其他Eureka Server拉取注册信息到本地，同时在初始化Eureka Server的时候，会从本地内存里面读取 注册信息，自动注册到本身的服务上。 判断集群节点是否为空，为空则返回。isReplication 代表是否是一个复制请求， isReplication = true 表示是其他Eureka Server发过来的同步请求，这个时候是不需要继续往下同步的。否则会陷入同步死循环。循环集群节点，过滤掉自身的节点。发起同步请求 ，调用replicateInstanceActionsToPeers。 lastDirtyTimestamp 客户端的信息，如果发生改变则更新lastDirtyTimestamp的值，同时对Eureka Server 重新发起注册。 服务端在接收renew ， stateUpdate, deleteStatusUpdate 的时候，都会要求客户端传入lastDirtyTimestamp 这个参数 ，注册的时候也会对这个值做对比。 renew续约完成之后，会判断传入的lastDirtyTimestamp 和客户端本地的lastDirtyTimestamp 是否一致，如果客户端的值大，那么就会返回404错误，客户端就需要重新注册了。 注册时lastDirtyTimestamp 是客户端向服务端发请求的版本号 ， 一切请求都以版本号大的为准。 "},"content/SpringCloud/Ribbon.html":{"url":"content/SpringCloud/Ribbon.html","title":"Ribbon","keywords":"","body":"架构 负载均衡算法 随机选择 重试 对选定的负载均衡策略机上重试机制，在一个配置时间段内当选择Server不成功， 则一直尝试使用subRule的方式选择一个可用的server. 轮询 轮询index，选择index对应位置的Server AvailabilityFilteringRule 过滤掉一直连接失败的被标记为circuit tripped的后端Server，并过滤掉那些高并发的后端 Server或者使用一个AvailabilityPredicate来包含过滤server的逻辑，其实就就是检查 status里记录的各个Server的运行状态 BestAvailableRule 选择一个最小的并发请求的Server，逐个考察Server，如果Server被tripped了，则跳过。 WeightedResponseTimeRule 根据响应时间加权，响应时间越长，权重越小，被选中的可能性越低 ZoneAvoidanceRule(默认是) 复合判断Server所在Zone的性能和Server的可用性选择Server，在没有Zone的情况下类是 轮询。 源码 @LoadBalanced 经过以上的一堆注释可知，该类的主要作用就是给添加了@LoadBalanced注解的RestTemplate类，添加拦截器LoadBalancerInterceptor，该拦截器拦截到请求后将请求重新处理，就在这个拦截器中实现了负载均衡的相关功能。即在发出具体的HTTP请求时，拦截器会拦截该请求。 LoadBalancerClient是在初始化的时候，会向Eureka回去服务注册列表，并且向通过10s一次向EurekaClient发送“ping”，来判断服务的可用性，如果服务的可用性发生了改变或者服务数量和之前的不一致，则更新或者重新拉取。LoadBalancerClient有了这些服务注册列表，就可以根据具体的IRule来进行负载均衡。LoadBalancerClient具体交给了ILoadBalancer来处理 执行负载均衡拦截，执行的是loadBalancer.execute方法。根据用户请求的serviceId来获取具体的LoadBalanced。 getServer获取就的service，也就是定位到哪台服务器的哪个端口号的具体服务信息 执行http请求。 "},"content/SpringCloud/Feign.html":{"url":"content/SpringCloud/Feign.html","title":"Feign","keywords":"","body":"架构 流程 @EnableFeignClients 自动扫描。 @EnableFeignClients 引入 FeignClientsRegistrar， FeignClientsRegistrar 调用registerDefaultConfiguration，将默认配置注入到容器中 调用registerFeignClients，将 @FeignClient 标注的接口装配成 FeignClientFactoryBean 注入到容器中。 FeignClientFactoryBean。 通过getObject方法，判断URL不存在则用负载均衡，通过JDK动态代理生成代理。 实际调用LoadBalanceFeignClient.client，封装 RibbonRequest，包含 Client、Request、uri。通过executeWithLoadBalancer进行负载均衡，这是 Ribbon 提供了 API "},"content/SpringCloud/Hystrix.html":{"url":"content/SpringCloud/Hystrix.html","title":"Hystrix","keywords":"","body":"介绍 在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是依赖服务，有的时候某些依赖服务出现故障也是很正常的。 Hystrix 可以让我们在分布式系统中对服务间的调用进行控制，加入一些调用延迟或者依赖故障的容错机制。 Hystrix 通过将依赖服务进行资源隔离，进而阻止某个依赖服务出现故障时在整个系统所有的依赖服务调用中进行蔓延；同时Hystrix 还提供故障时的 fallback 降级机制。 总而言之，Hystrix 通过这些方法帮助我们提升分布式系统的可用性和稳定性。 设计原则 对依赖服务调用时出现的调用延迟和调用失败进行控制和容错保护。 在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延。比如某一个服务故障了，导致其它服务也跟着故障。 提供 fail-fast（快速失败）和快速恢复的支持。 提供 fallback 优雅降级的支持。 支持近实时的监控、报警以及运维操作。 阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。 避免请求排队和积压，采用限流和 fail fast 来控制故障。 提供 fallback 降级机制来应对故障。 使用资源隔离技术，比如 bulkhead（舱壁隔离技术）、swimlane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。 通过近实时的统计/监控/报警功能，来提高故障发现的速度。 通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度。 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。 资源隔离 Hystrix 实现资源隔离，主要有两种技术： 线程池 信号量 信号量机制 信号量的资源隔离只是起到一个开关的作用，比如，服务 A 的信号量大小为 10，那么就是说它同时只允许有 10 个 tomcat 线程来访问服务 A，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。 适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。 线程池 资源隔离，就是说，你如果要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了，这就叫资源隔离。哪怕对这个依赖服务，比如说商品服务，现在同时发起的调用量已经到了 1000，但是线程池内就 10 个线程，最多就只会用这 10 个线程去执行。此时再有请求过来，会先进入队列积压。如果说队列积压满了，再有请求过来，就直接 reject，拒绝请求，执行 fallback 降级的逻辑，快速返回。 command key ，代表了一类 command，一般来说，代表了底层的依赖服务的一个接口。 command group ，代表了某一个底层的依赖服务，这是很合理的，一个依赖服务可能会暴露出来多个接口，每个接口就是一个 command key。command group 在逻辑上去组织起来一堆 command key 的调用、统计信息、成功次数、timeout 超时次数、失败次数等，可以看到某一个服务整体的一些访问情况。一般来说，推荐根据一个服务区划分出一个线程池，command key 默认都是属于同一个线程池的。 如果你的 command key 要用自己的线程池，可以定义自己的 thread pool key 最大的好处，就是资源隔离，确保说任何一个依赖服务故障，不会拖垮当前的这个服务。线程池的健康状况随时会报告，比如成功/失败/拒绝/超时的次数统计，然后可以近实时热修改依赖服务的调用配置，而不用停机。当一个故障的依赖服务重新变好的时候，可以通过清理掉线程池，瞬间恢复该服务的调用 线程池机制最大的缺点就是增加了 CPU 的开销。每个 command 的执行都依托一个独立的线程，会进行排队，调度，还有上下文切换。 执行步骤 主要对加了@HystrixCommand注解的方法用AOP拦截实现类HystrixCommandAspect去拦截。 创建 command 调用 command 执行方法。 execute()：调用后直接 block 住，属于同步调用，直到依赖服务返回单条结果，或者抛出异常。 queue()：返回一个 Future，属于异步调用，后面可以通过 Future 获取单条结果。 observe()：订阅一个 Observable 对象，Observable 代表的是依赖服务返回的结果，获取到一个那个代表结果的 Observable 对象的拷贝对象。 toObservable()：返回一个 Observable 对象，如果我们订阅这个对象，就会执行 command 并且获取返回结果。 检查是否开启缓存。这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果。否则，继续往后的步骤。 检查线程池/队列/信号量是否已满。是否开启了断路器。这个 command 对应的依赖服务是否开启了断路器。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。 如果这个 command 线程池和队列已满，或者 semaphore 信号量已满，那么也不会执行 command，而是直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。 执行 command。 断路健康检查。Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker 断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。 调用 fallback 降级机制 断路器 Hystrix 经过断路器的流量超过了一定的阈值，才有可能触发断路。比如说，要求在 10s 内经过断路器的流量必须达到 20 个，而实际经过断路器的流量才 10 个，那么根本不会去判断要不要断路。 "},"content/DesignPatterns/设计模式.html":{"url":"content/DesignPatterns/设计模式.html","title":"设计模式","keywords":"","body":"软件设计原则 设计原则 解释 开闭原则 对扩展开放，对修改关闭 依赖倒置原则 通过抽象使各个类或者模块不相互影响，实现松耦合。 单一职责原则 一个类、接口、方法只做一件事。 接口隔离原则 尽量保证接口的纯洁性，客户端不应该依赖不需要的接口。 迪米特法则 又叫最少知道原则，一个类对其所依赖的类知道得越少越好。 里氏替换原则 子类可以扩展父类的功能但不能改变父类原有的功能。 合成复用原则 尽量使用对象组合、聚合，而不使用继承关系达到代码复用的目的 设计模式最重要的是解耦。 设计模式之间的关联关系和对比 单例模式和工厂模式 实际业务代码中，通常会把工厂类设计为单例。 策略模式和工厂模式 工厂模式包含工厂方法模式和抽象工厂模式是创建型模式，策略模式属于行为型模 式。 工厂模式主要目的是封装好创建逻辑，策略模式接收工厂创建好的对象，从而实现不 同的行为。 策略模式和委派模式 策略模式是委派模式内部的一种实现形式，策略模式关注的结果是否能相互替代。 委派模式更关注分发和调度的过程。 模板方法模式和工厂方法模式 厂方法是模板方法的一种特殊实现。 模板方法模式和策略模式 模板方法和策略模式都有封装算法。 策略模式是使不同算法可以相互替换，且不影响客户端应用层的使用。 模板方法是针对定义一个算法的流程，将一些有细微差异的部分交给子类实现。 模板方法模式不能改变算法流程，策略模式可以改变算法流程且可替换。策略模式通 常用来代替 if...else...等条件分支语句。 装饰者模式和代理模式 装饰者模式关注点在于给对象动态添加方法，而代理更加注重控制对对象的访问。 代理模式通常会在代理类中创建被代理对象的实例，而装饰者模式通常把被装饰者作 为构造参数。 装饰者模式和适配器模式 装饰者模式和适配器模式都是属于包装器模式(Wrapper Pattern)。 装饰者模式可以实现被装饰者与相同的接口或者继承被装饰者作为它的子类，而适配 器和被适配者可以实现不同的接口。 "},"content/DesignPatterns/代理模式.html":{"url":"content/DesignPatterns/代理模式.html","title":"代理模式","keywords":"","body":"静态代理 动态代理 JDK代理 public class JDKDynamic implements InvocationHandler{ //被代理的对象，把引用给保存下来 private Object target; public Object getInstance(Object target) throws Exception{ this.target = target; Class clazz = target.getClass(); return Proxy.newProxyInstance(clazz.getClassLoader(),clazz.getInterfaces(),this); } public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { before(); Object obj = method.invoke(this.target,args); after(); return obj; } private void before(){ System.out.println(\"动态代理前\"); } private void after(){ System.out.println(\"动态代理后\"); } } //调用方法 Object obj = (Object)new JDKDynamic().getInstance(new Object()); Object.method(); JDK Proxy 采用字节码重组，重新生成的对象来替代原始的对象以达到动态代理的目的。JDK Proxy 生成对象的步骤如下: 拿到被代理对象的引用，并且获取到它的所有的接口，反射获取。 JDK Proxy 类重新生成一个新的类，新的类要实现被代理类所有实现的所有的接 口。 动态生成 Java 代码，把新加的业务逻辑方法由一定的逻辑代码去调用(在代码中体 现)。 编译新生成的 Java 代码.class。 再重新加载到 JVM 中运行。 $Proxy0 继承了 Proxy 类，同时还实现了 接口，而且重写了方法。而且在静态块中用反射查找到了目标对象的所有方法，而且保存了所有方法的引用，在重写的方法通过invoke反射调用目标对象的方法。 CGLib代理 CGLib 代理的目标对象不需要实现任何接口，它是通过动态继承目标对象实现的动态代理 public class CGLibDynamic implements InvocationHandler{ public Object getInstance(Class clazz) throws Exception{ Enhancer enhancer = new Enhancer(); //要把哪个设置为即将生成的新类父类 enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); } public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { //业务的增强 before(); Object obj = methodProxy.invokeSuper(o,objects); after(); return obj; } private void before(){ System.out.println(\"动态代理前\"); } private void after(){ System.out.println(\"动态代理后\"); } } //调用方法 Object obj = (Object)new CGLibDynamic().getInstance(Object.class); Object.method(); 重写了 父类的所有方法。代理类会获得所有在父类继承来的方法，并且会有 MethodProxy 与之对应。 调用过程：代理对象调用this.setPerson方法->调用拦截器->methodProxy.invokeSuper->CGLIB$setPerson$0->被代理对象setPerson方法。 methodProxy.invokeSuper调用过程就是获取到代理类对应的FastClass。 CGLib 动态代理执行代理方法效率之所以比 JDK 的高是因为 Cglib 采用了 FastClass 机 制，它的原理简单来说就是:为代理类和被代理类各生成一个 Class，这个 Class 会为代理类或被代理类的方法分配一个 index(int 类型)。这个 index 当做一个入参，FastClass 就可以直接定位要调用的方法直接进行调用，这样省去了反射调用，所以调用效率比 JDK动态代理通过反射调用高。 对比 JDK 动态代理是实现了被代理对象的接口，CGLib 是继承了被代理对象。 JDK 和 CGLib 都是在运行期生成字节码，JDK 是直接写 Class 字节码，CGLib 使用 ASM 框架写 Class 字节码，Cglib 代理实现更复杂，生成代理类比 JDK 效率低。 JDK 调用代理方法，是通过反射机制调用，CGLib 是通过 FastClass 机制直接调用方法， CGLib 执行效率更高。 "},"content/DesignPatterns/单例模式.html":{"url":"content/DesignPatterns/单例模式.html","title":"单例模式","keywords":"","body":"饿汉式单例 饿汉式单例是在类加载的时候就立即初始化，并且创建单例对象。绝对线程安全，在线程还没出现以前就是实例化了，不可能存在访问安全问题。 public class HungrySingleton { //先静态、后动态 //先属性、后方法 //先上后下 private static final HungrySingleton hungrySingleton = new HungrySingleton(); private HungrySingleton(){} public static HungrySingleton getInstance(){ return hungrySingleton; } } 懒汉式 懒汉式单例的特点是:被外部类调用的时候内部类才会加载 public class LazySimpleSingleton { private LazySimpleSingleton(){} //静态块，公共内存区域 private static LazySimpleSingleton lazy = null; public static LazySimpleSingleton getInstance(){ if(lazy == null){ lazy = new LazySimpleSingleton(); } return lazy; } } 双重检查锁方式 public class LazyDoubleCheckSingleton { private volatile static LazyDoubleCheckSingleton lazy = null; private LazyDoubleCheckSingleton(){} public static LazyDoubleCheckSingleton getInstance(){ if(lazy == null){ synchronized (LazyDoubleCheckSingleton.class){ if(lazy == null){ lazy = new LazyDoubleCheckSingleton(); //1.分配内存给这个对象 //2.初始化对象 //3.设置 lazy 指向刚分配的内存地址 } } } return lazy; } } 静态内部类方式 //这种形式兼顾饿汉式的内存浪费，也兼顾 synchronized 性能问题 public class LazyInnerClassSingleton { //默认使用 LazyInnerClassGeneral 的时候，会先初始化内部类 //如果没使用的话，内部类是不加载的 private LazyInnerClassSingleton(){} //static 是为了使单例的空间共享，保证这个方法不会被重写，重载 public static final LazyInnerClassSingleton getInstance(){ //在返回结果以前，一定会先加载内部类 return LazyHolder.LAZY; } //默认不加载 private static class LazyHolder{ private static final LazyInnerClassSingleton LAZY = new LazyInnerClassSingleton(); } } 反射破坏单例 构造方法中加入限制 private LazyInnerClassSingleton(){ if(LazyHolder.LAZY != null){ throw new RuntimeException(\"不允许创建多个实例\"); } } 序列化破坏单例 当我们将一个单例对象创建好，有时候需要将对象序列化然后写入到磁盘，下次使用时 再从磁盘中读取到对象，反序列化转化为内存对象。反序列化后的对象会重新分配内存， 即重新创建。 保证序列化的情况下也能够实现单例，只需要增加 readResolve()方法即可 private Object readResolve(){ return INSTANCE; } ObjectInputStream 类的 readObject()中，反射调用了readResolve方法，实际上实例化了两 次，只不过新创建的对象没有被返回而已。 枚举式单例 public enum EnumSingleton { INSTANCE; private Object data; public Object getData() { return data; } public void setData(Object data) { this.data = data; } public static EnumSingleton getInstance(){ return INSTANCE; } } 解决了反射和序列化问题 容器式单例 public class ContainerSingleton { private ContainerSingleton(){} private static Map ioc = new ConcurrentHashMap(); public static Object getBean(String className){ synchronized (ioc) { if (!ioc.containsKey(className)) { Object obj = null; try { obj = Class.forName(className).newInstance(); ioc.put(className, obj); } catch (Exception e){ e.printStackTrace(); } return obj; } else { return ioc.get(className); } } } } "},"content/DesignPatterns/原型模式.html":{"url":"content/DesignPatterns/原型模式.html","title":"原型模式","keywords":"","body":"原型模式是指原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 浅克隆 浅克隆。只是完整复制了值类型数据，没有赋值引用对象。换言之，所有的引用对象仍然指向原来的对象。 深度克隆 序列化机制实现深度克隆 public Object deepClone(){ try{ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); QiTianDaSheng copy = (QiTianDaSheng)ois.readObject(); copy.birthday = new Date(); return copy; } catch (Exception e){ e.printStackTrace(); return null; } } 克隆破坏单例模式 单例类不实现 Cloneable 接口或者重写 clone()方法，在 clone 方法中返回单例对象即可 "},"content/DesignPatterns/工厂模式.html":{"url":"content/DesignPatterns/工厂模式.html","title":"工厂模式","keywords":"","body":"简单工厂 简单工厂模式是指由一个工厂对象决定创建出哪一种产品类的实例。 public ICourse create(Class clazz){ try { if (null != clazz) { return clazz.newInstance(); } }catch (Exception e){ e.printStackTrace(); } return null; } public static void main(String[] args) { CourseFactory factory = new CourseFactory(); ICourse course = factory.create(JavaCourse.class); course.record(); } 简单工厂模式在 JDK 源码中，例如 Calendar 类，Calendar.getInstance()方法。LoggerFactory 中有多个重载的方法 getLogger()。 简单工厂也有它的缺点:工厂类的职责相对过重，不易于扩展过于复杂的产品结构。 工厂方法模式 工厂方法模式是指定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行。在工厂方法模式中用户只需要关心所需产品对应的工厂，无须关心创建细节，而且加入新的产品符 合开闭原则。 public interface ICourseFactory { ICourse create(); } public class JavaCourseFactory implements ICourseFactory { public ICourse create() { return new JavaCourse(); } } public class PythonCourseFactory implements ICourseFactory { public ICourse create() { return new PythonCourse(); } } public static void main(String[] args) { ICourseFactory factory = new PythonCourseFactory(); ICourse course = factory.create(); course.record(); factory = new JavaCourseFactory(); course = factory.create(); course.record(); } 工厂方法适用于以下场景: 创建对象需要大量重复的代码。 客户端(应用层)不依赖于产品类实例如何被创建、实现等细节。 一个类通过其子类来指定创建哪个对象。 工厂方法也有缺点: 类的个数容易过多，增加复杂度。 增加了系统的抽象性和理解难度。 抽象工厂模式 抽象工厂模式是指提供一个创建一系列相关或相互依赖对象的接口，无须指定他们具体的类。客户端(应用层)不依赖于产品类实例如何被创建、实现等细节，强调的是一系列相关的产品对象(属于同一产品族)一起使用创建对象需要大量重复的代码。需要提供一个产品类的库，所有的产品以同样的接口出现，从而使客户端不依赖于具体实现。 public interface IVideo { void record(); } public interface INote { void edit(); } //创建一个抽象工厂 CourseFactory 类 public interface CourseFactory { INote createNote(); IVideo createVideo(); } //创建 Java 产品族 public class JavaVideo implements IVideo { public void record() { System.out.println(\"录制 Java 视频\"); } } public class JavaNote implements INote { public void edit() { System.out.println(\"编写 Java 笔记\"); } } //创建 Java 产品族的具体工厂 JavaCourseFactory public class JavaCourseFactory implements CourseFactory { public INote createNote() { return new JavaNote(); } public IVideo createVideo() { return new JavaVideo(); } } //客户端调用 public static void main(String[] args) { JavaCourseFactory factory = new JavaCourseFactory(); factory.createNote().edit(); factory.createVideo().record(); } 因此抽象工厂也是 有缺点的: 1、规定了所有可能被创建的产品集合，产品族中扩展新的产品困难，需要修改抽象工厂 的接口。不符合开闭原则。 2、增加了系统的抽象性和理解难度。 "},"content/DesignPatterns/其他设计模式.html":{"url":"content/DesignPatterns/其他设计模式.html","title":"其他设计模式","keywords":"","body":"策略模式 1、假如系统中有很多类，而他们的区别仅仅在于他们的行为不同。 2、一个系统需要动态地在几种算法中选择一种。 优点: 1、策略模式符合开闭原则。 2、避免使用多重条件转移语句，如 if...else...语句、switch 语句 3、使用策略模式可以提高算法的保密性和安全性。 缺点: 1、客户端必须知道所有的策略，并且自行决定使用哪一个策略类。 2、代码中会产生非常多策略类，增加维护难度。 委派模式 现实生活中也常有委派的场景发生，例如:老板(Boss)给项目经理(Leader)下达任务，项目经理会根据实际情况给每个员工派发工作任务。 客户请求(Boss)、委派者(Leader)、被被委派者(Target)，委派者要持有被委派者的引用。调用被委派者方法实现。 装饰者模式 装饰者模式是指在不改变原有对象的基础之上，将功能附加到对象上。装饰者在代码程序中适用于以下场景: 1、用于扩展一个类的功能或给一个类添加附加职责。 2、动态的给一个对象添加功能，这些功能可以再动态的撤销。 观察者模式 观察者模式(Observer Pattern)定义了对象之间的一对多依赖，让多个观察者对象同 时监听一个主体对象，当主体对象发生变化时，它的所有依赖者(观察者)都会收到通 知并更新，属于行为型模式 观察者模式的优缺点 优点：1、观察者和被观察者之间建立了一个抽象的耦合。 2、观察者模式支持广播通信。 缺点：1、观察者之间有过多的细节依赖、提高时间消耗及程序的复杂度。 2、使用要得当，要避免循环调用。 模板模式 模板模式通常又叫模板方法模式(Template Method Pattern)是指定义一个算法的骨 架，并允许子类为一个或者多个步骤提供实现。模板方法使得子类可以在不改变算法结 构的情况下，重新定义算法的某些步骤，属于行为性设计模式。 优点: 1、利用模板方法将相同处理逻辑的代码放到抽象父类中，可以提高代码的复用性。2、将不同的代码不同的子类中，通过对子类的扩展增加新的行为，提高代码的扩展性。 3、把不变的行为写在父类上，去除子类的重复代码，提供了一个很好的代码复用平台， 符合开闭原则。 缺点: 1、类数目的增加，每一个抽象类都需要一个子类来实现，这样导致类的个数增加。 2、类数量的增加，间接地增加了系统实现的复杂度。 3、继承关系自身缺点，如果父类添加新的抽象方法，所有子类都要改一遍。 适配器模式 适配器模式(Adapter Pattern)是指将一个类的接口转换成客户期望的另一个接口，使 原本的接口不兼容的类可以一起工作，属于结构型设计模式。 适配器适用于以下几种业务场景: 1、已经存在的类，它的方法和需求不匹配(方法结果相同或相似)的情况。 2、适配器模式不是软件设计阶段考虑的设计模式，是随着软件维护，由于不同产品、不同厂家造成功能类似而接口不相同情况下的解决方案。 优点:1、能提高类的透明性和复用，现有的类复用但不需要改变。 2、目标类和适配器类解耦，提高程序的扩展性。 3、在很多业务场景中符合开闭原则。 缺点: 1、适配器编写过程需要全面考虑，可能会增加系统的复杂性。 2、增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱。 "},"content/Distribution/分布式事务.html":{"url":"content/Distribution/分布式事务.html","title":"分布式事务","keywords":"","body":"分布式理论 CAP理论 WEB服务无法同时满足一下3个属性 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效) 可用性(Availability) ： 每个操作都必须以可预期的响应结束 分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成 BASE理论 用来对CAP定理进行进一步扩充的。BASE理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。 分布式事务 XA方案 两阶段提交，有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。 TCC方案 TCC 的全称是：Try、Confirm、Cancel。 Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。 Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。 Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚） 事务回滚实际上是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大。 本地消息表 A 系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着 A 系统将这个消息发送到 MQ 中去； B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息； B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态； 如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理； 这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。 这个方案最大的问题就在于严重依赖于数据库的消息表来管理事务 可靠消息最终一致性 A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息； 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务； mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。 最大努力通知 系统 A 本地事务执行完之后，发送个消息到 MQ； 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口； 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。 "},"content/Distribution/分布式ID.html":{"url":"content/Distribution/分布式ID.html","title":"分布式ID","keywords":"","body":"UUID 生成足够简单，本地生成无网络消耗，具有唯一性 无序的字符串，不具备趋势自增特性，没有业务含义 长度过长，作为数据库主键 UUID 的无序性会导致数据位置频繁变动，严重影响性能。 数据库自增ID 当我们需要一个ID的时候，向表中插入一条记录返回主键ID 实现简单，ID单调自增，数值类型查询速度快。 DB单点存在宕机风险，无法扛住高并发场景。 基于数据库集群模式 双主模式集群，也就是两个Mysql实例都能单独的生产自增ID。 设置起始值和自增步长 水平扩展的数据库集群，有利于解决数据库单点压力的问题，同时为了ID生成特性，将自增步长按照机器数量来设置。 增加第三台MySQL实例需要人工修改一、二两台MySQL实例的起始值和步长，把第三台机器的ID起始生成位置设定在比现有最大自增ID的位置远一些，但必须在一、二两台MySQL实例ID还没有增长到第三台MySQL实例的起始ID值的时候，否则自增ID就要出现重复了。 基于数据库的号段模式 号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下： CREATE TABLE id_generator ( id int(10) NOT NULL, max_id bigint(20) NOT NULL COMMENT '当前最大id', step int(20) NOT NULL COMMENT '号段的布长', biz_type int(20) NOT NULL COMMENT '业务类型', version int(20) NOT NULL COMMENT '版本号', PRIMARY KEY (`id`) ) 等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。 Redis模式 Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。 雪花算法 Snowflake生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。 Snowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。 根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。 强依赖时钟,如果主机时间回拨,则会造成重复ID 在单机上是递增的，但是在分布式环境下，每台机器的时钟不一定完全同步，所以不能满足严格递增，只能满足趋势递增。 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的。 不依赖数据库第三方系统（区别于 Redis 集群生成的分布式 ID），以服务的方式部署，稳定性更高，生成 ID 的性能也常高。 可以根据自身业务特性分配 bit 位，非常灵活。 "},"content/Distribution/Session一致性.html":{"url":"content/Distribution/Session一致性.html","title":"Session一致性","keywords":"","body":"session 服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文。Web开发中，web-server可以自动为同一个浏览器的访问用户自动创建session，提供数据存储功能。最常见的，会把用户的登录信息、用户信息存储在session中，以保持登录状态。 session同步 思路：多个web-server之间相互同步session，这样每个web-server之间都包含全部的session 优点：web-server支持的功能，应用程序不需要修改代码 不足：session的同步需要数据传输，占内网带宽，有时延。所有web-server都包含所有session数据，数据量受内存限制，无法水平扩展。有更多web-server时要歇菜 反向代理hash一致性 四层代理hash 反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个web-server上 七层代理hash 反向代理使用http协议中的某些业务属性来做hash，例如sid，city_id，user_id等，能够更加灵活的实施hash策略，以保证同一个浏览器用户的请求落在同一个web-server上 优点：只需要改nginx配置，不需要修改应用代码。负载均衡，只要hash属性是均匀的，多台web-server的负载是均衡的。可以支持web-server水平扩展（session同步法是不行的，受内存限制） 不足：如果web-server重启，一部分session会丢失，产生业务影响，例如部分用户重新登录。如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session 后端统一存储 将session存储在web-server后端的存储层，数据库或者缓存。 没有安全隐患。可以水平扩展，数据库/缓存水平切分即可。web-server重启或者扩容都不会有session丢失 增加了一次网络调用，并且需要修改应用代码 完全不用 Session 使用 JWT Token 储存用户身份，然后再从数据库或者 cache 中获取其他的信息。这样无论请求分配到哪个服务器都无所谓。 "},"content/Distribution/一致性hash.html":{"url":"content/Distribution/一致性hash.html","title":"一致性hash","keywords":"","body":"普通Hash hash计算方式为 hash = 请求%serverCount 当发生宕机或者扩容的时候，我们之前计算的所有hash都需要重新计算，在生产环境下我们后台服务器很多台，客户端也有很多，那么影响是很⼤的，缩容和扩容都会存在这样的问题，⼤量⽤户的请求会被路由到其他的⽬标服务器处理，⽤户在原来服务器中的会话都会丢失。 一致性Hash 一致性Hash的出现就解决了上述的问题，在发生宕机或者和扩容的时候尽可能少的影响请求的分发。 我们对服务器求hash然后把服务器放到hash环上的对应位置上，当有请求到来时，对请求进行计算，把请求放到hash环的对应位置，然后顺时针获得最近的服务器节点。 当发生服务宕机或者扩容是请求转发也是会发生变化的，当发生扩容或者宕机的时候只会影响极少数一部分的用户，最大限度上提高的体验。 当然一致性hash也可能存在一些问题的，比如如下图所示， 服务器分布及其不合理， 大量的请求都落在同一个服务器上，对服务的压力较大。针对这种情况我们可以用增加虚拟节点的方式来尽可能更合理的分发请求来，减轻对某一服务的压力。 "},"content/Distribution/序列化.html":{"url":"content/Distribution/序列化.html","title":"序列化","keywords":"","body":"意义 序列化是把对象的状态信息转化为可存储或传输的形式过程，也就是把对象转化为字节序列 的过程称为对象的序列化 反序列化是序列化的逆向过程，把字节数组反序列化为对象，把字节序列恢复为对象的过程 成为对象的反序列化 java序列化 serialVersionUID 有两种显示的生成方式: 一是默认的 1L，比如:private static final long serialVersionUID = 1L 二是根据类名、接口名、成员方法及属性等来生成一个 64 位的哈希字段。 当实现 java.io.Serializable 接口的类没有显式地定义一个 serialVersionUID 变量时候，Java 序列化机制会根据编译的 Class 自动生成一个 serialVersionUID 作序列化版本比较用，这种情况 下，如果 Class 文件(类名，方法明等)没有发生变化(增加空格，换行，增加注释等等)，就算 再编译多次，serialVersionUID 也不会变化的。 Transient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变 量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 分布式下序列化 XML 序列化框架介绍 XML 序列化的好处在于可读性好，方便阅读和调试。但是序列化以后的字节码文件比较大， 而且效率不高。同时 XML 又具有语言无关性，所以还可以用于异构系统之间的数据交换和协议。 JSON 序列化框架 JSON是一种轻量级的数据交换格式，相对于 XML 来说，JSON 的字节流更小，而且可读性也非常好。 Hessian 序列化框架 Hessian 是一个支持跨语言传输的二进制序列化协议，相对于 Java 默认的序列化机制来说， Hessian 具有更好的性能和易用性，而且支持多种不同的语言。 实际上 Dubbo 采用的就是 Hessian 序列化来实现，只不过 Dubbo 对 Hessian 进行了重构， 性能更高 Protobuf 序列化框架 Protobuf 是一个纯粹的表示层协议，可以和各种传输层协议一起使用。主要是空间开销小和性能比较好。解析性能比较高，序列化以后数据量相对较少。 Protobuf 有自己的语法和编译器。要传输的每一个类的结构都要生成对应的 proto 文件，如果某个类发生修改，还得重新生成该类对应的 proto 文件。 Protobuf序列化的原理 使用 protobuf 开发的一般步骤是 配置开发环境，安装 protocol compiler 代码编译器 编写.proto 文件，定义序列化对象的数据结构 基于编写的.proto 文件，使用 protocol compiler 编译器生成对应的序列化/反序列化工具类 基于自动生成的代码，编写自己的序列化应用 序列化速度快的原因: 编码/解码方式简单(只需要简单的数学运算 = 位移等等)，采用 Protocol Buffer 自身的框架代码和编译器共同完成 序列化后的数据量体积小(即数据压缩效果好)的原因：采用了独特的编码方式，如 Varint、Zigzag 编码方式等等，采用 T - L - V 的数据存储方式，减少了分隔符的使用 & 数据存储得紧凑 "},"content/Distribution/Http和Https.html":{"url":"content/Distribution/Http和Https.html","title":"HTTP和HTTPS","keywords":"","body":"HTTP 在最早的 http 协议中，每进行一次 http 通信，就需要做一次 tcp 的连接。而一次连接需要进 行 3 次握手，这种通信方式会增加通信量的开销。所以在 HTTP/1.1 中改用了持久连接，就是在一次连接建立之后，只要客户端或者服务端没有 明确提出断开连接，那么这个 tcp 连接会一直保持连接状态 特点 HTTP 协议本身不会对请求和响应之间的 通信状态做保存。 通过在请求和响应报文 中写入 Cookie 信息来控制客户端的状态;Cookie 会根据从服务器端发送的响应报文内的一 个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器 发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去 当程序需要为某个客户端的请求创建一个 session 的时候，如果不存在 Session，则尝试根据 requestedSessionId 查找 Session，如果存在 Session 的 话则直接返回，如果不存在的话，则创建新的 Session，并且把 sessionId 添加到 Cookie 中， 后续的请求便会携带该 Cookie，这样便可以根据 Cookie 中的 sessionId 找到原来创建的 Session 了 HTTPS https 是一种加密的超文本传输协议，它与 HTTP 在协议差异在于对数据传输的过程中，https 对数据做了完全加密。由于 http 协议或者 https 协议都是处于 TCP 传输层之上，同时网络协 议又是一个分层的结构，所以在 tcp 协议层之上增加了一层 SSL(Secure Socket Layer，安 全层)或者 TLS(Transport Layer Security) 安全层传输协议组合使用用于构造加密通道; 对称秘钥 对称加密算法来实现，密钥 S 扮演着加密和解密的角色。 协商过程，意味着又是基于一个网络传输的情况下去动态分配密钥，可是这个协商过程又是不安全的。 非对称加密 非对称加密算法的特点是：私钥加密后的密文，只要有公钥，都能解密，但是公钥加密后的密文，只有私钥可以解密。私钥只有一个人有，而公钥可以发给所有人。 这样就可以保证 A/B 向服务器端方向发送的消息是安全的。似乎我们通过非对称加密算法解决了密钥的协商的问题。 使用非对称加密算法，让 A、B 客户端安全地持有公钥，服务端把需要传递给客户端的公钥，通过第三方机构提供的私钥对公钥内容进行加密后，再传递给客户端。通过第三方机构私钥对服务端公钥加密以后的内容，就是一个简陋版本的 “数字证书”。这个证书中包含【服务器公钥】。户端拿到证书后根据证书上的方法自己生成一个证书编号，如果生成的证书编号与证书上的证书编号相同，那么说明这个证书是真实的。浏览器和操作系统都会维护一个权威的第三方机构列表(包括他们的公钥)。 证书就是 HTTPS 中的数字证书，证书编号就是数字签名，而第三方机构就是数字证书的签发机构(CA) HTTPS原理 "},"content/Distribution/TCP.html":{"url":"content/Distribution/TCP.html","title":"TCP","keywords":"","body":"特点 TCP是面向连接的传输层协议。 TCP连接是点对点的（套接字–IP:Port到套接字）。 TCP提供可靠交付的服务。 TCP提供全双工通信。 面向字节流。 三次握手 TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 握手两次不可以 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。 肯定是不可以的，三次握手主要是解决这样一个常见的问题，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。 四次挥手 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2*MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 一个很常见的问题，为何不能三次挥手呢？ 首先如果去掉最后一次挥手，那么服务器端就不知道自己要关闭的报文有没有传输成功，可能半路上就失败了，但是此时客户端不知道，导致客户端一直在等待服务器关闭，但是此时服务器端直接就关闭了； 如果中间的两次挥手合并，那是肯定不行的，因为此时服务器端可能还有很多报文未处理完，此时直接关闭肯定会对传输有很大影响。 为什么客户端在收到 服务器端发来的 FIN 包后要等 2 个最长报文段传输时间？ 防止最后自己发去的 ack 没传送到服务器，如果服务器没收到客户端的 ack，肯定会选择重发一次 FIN 包，那么此时如果客户端已经关闭了，客户端就不能再发 ack 确认收到了，至于为何是 2 个报文段传输时间，因为刚好一去一回嘛… 2 个最长报文传输时间没有 FIN 包发来，就说明服务器已经关闭了，客户端也就可以安心关闭了。 如果已经建立了连接，但是客户端突然出现故障了怎么办？ TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 "},"content/SystemDesign/设计一个高并发系统.html":{"url":"content/SystemDesign/设计一个高并发系统.html","title":"设计一个高并发系统","keywords":"","body":"概述 系统拆分 缓存 MQ 分库分表 读写分离 ElasticSearch 系统拆分 将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。 缓存 缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。 MQ MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。 分库分表 分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。 读写分离 读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。 ElasticSearch Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。 "},"content/SystemDesign/高可用.html":{"url":"content/SystemDesign/高可用.html","title":"高可用","keywords":"","body":"限流 令牌桶(Token Bucket)、漏桶(leaky bucket)和 计数器 算法是最常用的三种限流的算法。 计数器 计数器限流算法也是比较常用的，主要用来限制总并发数。比如限流 qps 为 100 ，算法的实现思路就是从第一个请求进来开始计时，在接下去的 1s 内，每来一个请求，就把计数加 1 ，如果累加的数字达到了 100 ，那么后续的请求就会被全部拒绝。等到 1s 结束后，把计数恢复成 0 ，重新开始计数。 这种实现方式有一个弊端：如果我在单位时间 1s 内的前 10ms ，已经通过了 100 个请求，那后面的 990ms ，只能眼巴巴的把请求拒绝，这种现象称为 突刺现象。 滑动窗口 滑动窗口是对计数器方式的改进, 增加一个时间粒度的度量单位 把一分钟分成若干等分(6 份,每份 10 秒), 在每一份上设置独立计数器,在 00:00-00:09 之间发生请求计数器累加 1.当等分数量越大限流统计就越详细 漏桶 为了消除 突刺现象，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。 不管服务调用方多么不稳定，通过漏桶算法进行限流，每 10 毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。 在算法实现方面，可以 准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。 这种算法，在使用过后也存在弊端：无法应对短时间的突发流量，同时它的优点也是可以平滑网络上的突发流量，请求可以被整形成稳定的流量。 令牌桶 从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。 在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。 放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置 qps 为 100 ，那么限流器初始化完成一秒后，桶中就已经有 100 个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的 100 个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。 熔断 降级一般是指我们自身的系统出现了故障而降级。而熔断一般是指依赖的外部接口出现故障的情况断绝和外部接口的关系。 例如你的A服务里的一个功能依赖B服务，这时B服务出现问题了，返回的很慢。而越是庞大的系统，上下游的调用链就会越长，而如果在一个很长的调用链中，某一个服务由于某种原因导致响应时间过长，或者完全无响应，那么就可能把整个分布式系统都拖垮。这种情况下可能会因为这个功能而拖慢A服务里面的所有功能，严重的时候会导致服务雪崩现象。 降级 降级也就是服务降级，当我们的服务器压力剧增为了保证核心功能的可用性 ，而选择性的降低一些功能的可用性，或者直接关闭该功能。这就是典型的丢车保帅了。 例如在双十一凌晨抢购的时候，流量压力是很大的，为了保证订单的正常支付，在凌晨1-2点左右的订单修改功能是关闭的。 一般而言都会建立一个独立的降级系统，可以灵活且批量的配置服务器的降级功能。当然也有用代码自动降级的，例如接口超时降级、失败重试多次降级等。具体失败几次，超时设置多久，由你们的业务等其他因素决定。开个小会，定个值，扔线上去看看情况。根据情况再调优。 "},"content/SystemDesign/1小时内访问频率最高的10个ip.html":{"url":"content/SystemDesign/1小时内访问频率最高的10个ip.html","title":"1小时内访问频率最高的10个ip","keywords":"","body":" QPS是 10万/秒，即一秒内最高有 10万个请求，那么一个小时内就有 100000*3600=360000000≈2^{28.4}228.4，向上取整，大概是 2^{29}229个请求，也不是很大。我们在内存中建立3600个HashMap，放在一个数组里，每秒对应一个HashMap，IP地址为key, 出现次数作为value。这样，一个小时内最多有2^{29}229个pair，每个pair占8字节，总内存大概是 2^{29} \\times 8=2^{32}229×8=232字节，即4GB，单机完全可以存下。 同时还要新建一个固定大小为10的小根堆，用于存放当前出现次数最大的10个IP。堆顶是10个IP里频率最小的IP。 每次来一个请求，就把该秒对应的HashMap里对应的IP计数器增1，并查询该IP是否已经在堆中存在， 如果不存在，则把该IP在3600个HashMap的计数器加起来，与堆顶IP的出现次数进行比较，如果大于堆顶元素，则替换掉堆顶元素，如果小于，则什么也不做 如果已经存在，则把堆中该IP的计数器也增1，并调整堆 需要有一个后台常驻线程，每过一秒，把最旧的那个HashMap销毁，并为当前这一秒新建一个HashMap，这样维持一个一小时的窗口。 每次查询top 10的IP地址时，把堆里10个IP地址返回来即可。 "},"content/SystemDesign/抽奖系统.html":{"url":"content/SystemDesign/抽奖系统.html","title":"抽奖系统","keywords":"","body":"业务需求 假设现在有一个抽奖的业务场景，用户在某个时间可以参与抽奖，比如一共有1万个奖，奖品就是某个礼物。 然后参与抽奖的用户可能有几十万，一瞬间可能几十万请求涌入过来，接着瞬间其中1万人中奖了，剩余的人都是没中奖的。然后中奖的1万人的请求会联动调用礼品服务，完成这1万中奖人的礼品发放。 负载均衡层的限流 防止用户重复抽奖 我们可以在负载均衡设备中做一些配置，判断如果同一个用户在1分钟之内多次发送请求来进行抽奖，就认为是恶意重复抽奖，或者是他们自己写的脚本在刷奖，这种流量一律认为是无效流量，在负载均衡设备那个层次就给直接屏蔽掉。 开奖后暴力拦截流量 可能50万请求涌入，但是前1万个请求就把奖品都抽完了，或者把红包都抢完了，后续的流量其实已经不需要放到Tomcat抽奖服务上去了，直接暴力拦截返回抽奖结束就可以了。 让抽奖服务跟负载均衡之间有一个状态共享的机制。就是说抽奖服务一旦全部开奖完毕，直接更新一个共享状态。然后负载均衡感知到了之后，后续请求全部拦截掉返回一个抽奖结束的标识就可以了。 可以基于Redis来实现这种共享抽奖状态。 Tomcate线程数量优化 Tomcat线程数量在200~500之间都是可以的，但是具体多少需要自己压测一下，不断的调节参数，看具体的CPU负载以及线程执行请求的一个效率。在CPU负载尚可，以及请求执行性能正常的情况下，尽可能提高一些线程数量。 基于Redis实现抽奖业务逻辑 把MySQL给替换成Redis，通常这种场景下，建议是基于Redis来实现核心的业务逻辑。Redis单机抗2万并发那是很轻松的一件事情 发放礼品环节进行限流削峰 抽奖服务把中奖信息发送到MQ，然后礼品服务假设就部署两个Tomcat，慢慢的从MQ中消费中奖消息，然后慢慢完成1完礼品的发放就可以了。 架构设计 "},"content/SystemDesign/积分系统.html":{"url":"content/SystemDesign/积分系统.html","title":"积分系统","keywords":"","body":"业务需求 用户在电商平台里平时通过购买商品、晒单评论可以有不断的积累积分 积累到足够的积分后，就可以在电商平台的积分兑换页面中，选择使用自己的积分来兑换一些礼品 业务流程 积分模块：积分表，积分兑换表， 仓储模块：发货申请表， 第三方物流公司：物流单号 消息中间件引入 积分兑换是一个用户执行的操作，积分服务是没有必要同步调用仓储服务的。引入消息中间件进行异步化的解耦，保证用户点击积分兑换按钮之后，尽快返回。 重试机制 积分服务发送消息给可靠消息服务，可靠消息服务在消息表中新增记录，然后发送消息到MQ（消息中间件） 然后仓储服务消费消息新增发货申请单，如果成功就回调可靠消息服务的一个接口说自己成功了，可靠消息服务就可以更新本地消息表中的记录状态为成功 如果仓储服务长时间没通知可靠消息服务自己成功了，可靠消息服务不停的重试再次发送消息 幂等性 如果仓储服务卡在第三方物流系统申请物流单的环节，长时间阻塞，所以没回调通知可靠消息服务。但是可靠消息服务过了一段时间，感觉没收到回调通知，就自己重试发送了消息。因此我们还要保证仓储服务新增发货申请单的幂等性。 只要在“积分兑换表的id”字段上建立一个唯一索引就可以了，保证每个积分兑换记录只能创建一条发货申请单，如果重复创建就会被唯一索引被阻止，这样就可以保证这个行为的幂等性了。 "},"content/Algorithm/二叉树后序遍历.html":{"url":"content/Algorithm/二叉树后序遍历.html","title":"二叉树前序遍历","keywords":"","body":"题目 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ //非递归 class Solution { public List postorderTraversal(TreeNode root) { LinkedList stack = new LinkedList<>(); LinkedList res = new LinkedList<>(); if (root == null) { return res; } stack.add(root); while (!stack.isEmpty()) { //从末尾取出并删除 TreeNode node = stack.pollLast(); res.addFirst(node.val);//每次在链表的头部插入元素 if (node.left != null) { //注意与前序对比着看 stack.add(node.left); } if (node.right != null) { stack.add(node.right); } } return res; } } //递归 class Solution { public List postorderTraversal(TreeNode root) { List res = new ArrayList(); Recursion(root,res); return res; } public void Recursion(TreeNode root,List res){ if (root == null){ return; } Recursion(root.left,res); Recursion(root.right,res); res.add(root.val); } } "},"content/Algorithm/二叉树的层序遍历.html":{"url":"content/Algorithm/二叉树的层序遍历.html","title":"二叉树的层序遍历","keywords":"","body":"题目 给你一个二叉树，请你返回其按层序遍历得到的节点值。（即逐层地，从左到右访问所有节点）。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ // 首先根元素入队 // 当队列不为空的时候，求当前队列的长度S，依次从队列中取s个元素进行拓展，然后进入下一次迭代 class Solution { public List> levelOrder(TreeNode root) { List> result = new ArrayList<>(); if (root == null){ return result; } Queue queue = new LinkedList<>(); queue.offer(root); while (!queue.isEmpty()){ int size = queue.size(); List list = new ArrayList<>(); for (int i = 0;i "},"content/Algorithm/二叉树的层序遍历倒序.html":{"url":"content/Algorithm/二叉树的层序遍历倒序.html","title":"二叉树的层序遍历倒序","keywords":"","body":"题目 给定一个二叉树，返回其节点值自底向上的层次遍历。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历） 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ /* add(int index，Object element)：此方法在列表中的指定索引处插入元素。它将当前位于该位置的元素(如果有)和任何后续元素右移(将在其索引处增加一个) */ class Solution { public List> levelOrderBottom(TreeNode root) { List> levelOrder = new LinkedList>(); if (root == null) { return levelOrder; } Queue queue = new LinkedList(); queue.offer(root); while (!queue.isEmpty()) { List level = new ArrayList(); int size = queue.size(); for (int i = 0; i "},"content/Algorithm/之字型打印二叉树.html":{"url":"content/Algorithm/之字型打印二叉树.html","title":"之字型打印二叉树","keywords":"","body":"题目 请实现一个函数按照之字形顺序打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右到左的顺序打印，第三行再按照从左到右的顺序打印，其他行以此类推。 解题思路 代码 class Solution { public List> levelOrder(TreeNode root) { Queue queue = new LinkedList<>(); List> res = new ArrayList<>(); if(root != null) queue.add(root); while(!queue.isEmpty()) { LinkedList tmp = new LinkedList<>(); for(int i = queue.size(); i > 0; i--) { TreeNode node = queue.poll(); if(res.size() % 2 == 0) tmp.addLast(node.val); // 偶数层 -> 队列头部 else tmp.addFirst(node.val); // 奇数层 -> 队列尾部 if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); } res.add(tmp); } return res; } } "},"content/Algorithm/二叉树的镜像.html":{"url":"content/Algorithm/二叉树的镜像.html","title":"二叉树的镜像","keywords":"","body":"题目 请完成一个函数，输入一个二叉树，该函数输出它的镜像。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ //递归方式 class Solution { public TreeNode mirrorTree(TreeNode root) { if(root == null){ return null; } TreeNode temp = root.left; root.left = mirrorTree(root.right); root.right = mirrorTree(temp); return root; } } //非递归方式。使用栈 class Solution { public TreeNode mirrorTree(TreeNode root) { if (root == null){ return root; } Stack stack = new Stack<>(); stack.push(root); while (!stack.isEmpty()){ TreeNode currentNode = stack.pop(); if(currentNode.left != null){ stack.push(currentNode.left); } if (currentNode.right != null){ stack.push(currentNode.right); } TreeNode temp = currentNode.left; currentNode.left = currentNode.right; currentNode.right = temp; } return root; } } "},"content/Algorithm/二叉树的最大路径和.html":{"url":"content/Algorithm/二叉树的最大路径和.html","title":"二叉树的最大路径和","keywords":"","body":"题目 给定一个非空二叉树，返回其最大路径和。 本题中，路径被定义为一条从树中任意节点出发，沿父节点-子节点连接，达到任意节点的序列。该路径至少包含一个节点，且不一定经过根节点。 解题思路 根据函数 maxGain 得到每个节点的最大贡献值。对于二叉树中的一个节点，该节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值，如果子节点的最大贡献值为正，则计入该节点的最大路径和，否则不计入该节点的最大路径和。维护一个全局变量 maxSum 存储最大路径和，在递归过程中更新 maxSum 的值，最后得到的 maxSum 的值即为二叉树中的最大路径和。 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int maxSum = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) { RecursionGain(root); return maxSum; } public int RecursionGain(TreeNode node){ if (node == null){ return 0; } int leftGain = Math.max(0,RecursionGain(node.left)); int rightGain = Math.max(0,RecursionGain(node.right)); int nodeSum = node.val + leftGain + rightGain; maxSum = Math.max(nodeSum,maxSum); return node.val + Math.max(leftGain, rightGain); } } "},"content/Algorithm/二叉树的最大深度.html":{"url":"content/Algorithm/二叉树的最大深度.html","title":"二叉树的最大深度","keywords":"","body":"题目 给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 解题思路 代码 //递归 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int maxDepth(TreeNode root) { if (root == null){ return 0; }else { int leftDepth = maxDepth(root.left); int rightDepth = maxDepth(root.right); return Math.max(leftDepth,rightDepth) + 1; } } } //非递归 // 此时我们广度优先搜索的队列里存放的是「当前层的所有节点」。每次拓展下一层的时候，不同于广度优先搜索的每次只从队列里拿出一个节点，我们需要将队列里的所有节点都拿出来进行拓展，这样能保证每次拓展完的时候队列里存放的是当前层的所有节点，即我们是一层一层地进行拓展，最后我们用一个变量ans 来维护拓展的次数，该二叉树的最大深度即为ans。 class Solution { public int maxDepth(TreeNode root) { int depth = 0; if (root == null){ return 0; }else { Queue queue = new LinkedList(); queue.offer(root); while (!queue.isEmpty()) { int size = queue.size(); for (int i=0;i "},"content/Algorithm/二叉树的最小深度.html":{"url":"content/Algorithm/二叉树的最小深度.html","title":"二叉树的最小深度","keywords":"","body":"题目 给定一个二叉树，找出其最小深度。 最小深度是从根节点到最近叶子节点的最短路径上的节点数量。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ //递归 class Solution { public int minDepth(TreeNode root) { if (root == null) { return 0; } if (root.left == null && root.right == null) { return 1; } int min_depth = Integer.MAX_VALUE; if (root.left != null) { min_depth = Math.min(minDepth(root.left), min_depth); } if (root.right != null) { min_depth = Math.min(minDepth(root.right), min_depth); } return min_depth + 1; } } //非递归，宽度搜索 class Solution { int minDepth(TreeNode root) { if (root == null) return 0; Queue q = new LinkedList<>(); q.offer(root); // root 本身就是一层，depth 初始化为 1 int depth = 1; while (!q.isEmpty()) { int size = q.size(); /* 将当前队列中的所有节点向四周扩散 */ for (int i = 0; i "},"content/Algorithm/二叉树的最近公共祖先.html":{"url":"content/Algorithm/二叉树的最近公共祖先.html","title":"二叉树的最近公共祖先","keywords":"","body":"题目 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { private TreeNode ans = null; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { dfs(root, p, q); return ans; } public boolean dfs(TreeNode root, TreeNode p, TreeNode q){ if (root == null) { return false; } boolean lson = dfs(root.left, p, q); boolean rson = dfs(root.right, p, q); if (lson && rson || ((root.val == p.val || root.val == q.val) && (lson || rson))){ ans = root; } return lson || rson || (root.val == p.val || root.val == q.val); } } "},"content/Algorithm/二叉树两个节点最短路径.html":{"url":"content/Algorithm/二叉树两个节点最短路径.html","title":"二叉树两个节点最短路径","keywords":"","body":"题目 给定一棵二叉树的根节点和两个任意节点，返回这两个节点之间的最短路径 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ public LinkedList helper(TreeNode n, TreeNode p, TreeNode q){ if(n == null){ return null; } LinkedList left = helper(n.left, p, q); LinkedList right = helper(n.right, p, q); // 当左右都为空时 if(left == null && right == null){ // 如果当前节点是目标节点，开启一条新路径 if(n == p || n == q){ LinkedList l = new LinkedList(); l.add(n); return l; } else { // 否则标记为空 return null; } // 如果左右节点都不为空，说明是最小公共祖先节点，合并两条路径 } else if(left != null && right != null){ finalPath.addAll(left); finalPath.add(n); Collections.reverse(right); finalPath.addAll(right); return left; // 如果当前节点是目标结点，且某一个子树不为空时，说明最小公共祖先是节点自身 } else if (left != null){ left.add(n); if(n == p || n == q){ finalPath.addAll(left); } return left; } else { right.add(n); if(n == p || n == q){ finalPath.addAll(right); } return right; } } "},"content/Algorithm/二叉树存在给定值路径.html":{"url":"content/Algorithm/二叉树存在给定值路径.html","title":"二叉树存在给定值路径","keywords":"","body":"题目 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 解题思路 根据函数 maxGain 得到每个节点的最大贡献值。对于二叉树中的一个节点，该节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值，如果子节点的最大贡献值为正，则计入该节点的最大路径和，否则不计入该节点的最大路径和。维护一个全局变量 maxSum 存储最大路径和，在递归过程中更新 maxSum 的值，最后得到的 maxSum 的值即为二叉树中的最大路径和。 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ //非递归 class Solution { public boolean hasPathSum(TreeNode root, int sum) { if (root == null) { return false; } Queue queNode = new LinkedList(); Queue queVal = new LinkedList(); queNode.offer(root); queVal.offer(root.val); while (!queNode.isEmpty()) { TreeNode now = queNode.poll(); int temp = queVal.poll(); if (now.left == null && now.right == null) { if (temp == sum) { return true; } continue; } if (now.left != null) { queNode.offer(now.left); queVal.offer(now.left.val + temp); } if (now.right != null) { queNode.offer(now.right); queVal.offer(now.right.val + temp); } } return false; } } //递归 class Solution { public boolean hasPathSum(TreeNode root, int sum) { if (root == null) { return false; } if (root.left == null && root.right == null) { return sum == root.val; } return hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val); } } "},"content/Algorithm/二叉树给定值路径.html":{"url":"content/Algorithm/二叉树给定值路径.html","title":"二叉树给定值路径","keywords":"","body":"题目 给定一个二叉树和一个目标和，找到所有从根节点到叶子节点路径总和等于给定目标和的路径。 说明: 叶子节点是指没有子节点的节点。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { List> ret = new LinkedList>(); Deque path = new LinkedList(); public List> pathSum(TreeNode root, int sum) { dfs(root, sum); return ret; } public void dfs(TreeNode root, int sum) { if (root == null) { return; } path.offerLast(root.val); sum -= root.val; if (root.left == null && root.right == null && sum == 0) { ret.add(new LinkedList(path)); } dfs(root.left, sum); dfs(root.right, sum); path.pollLast(); } "},"content/Algorithm/二叉树给定值所有路径.html":{"url":"content/Algorithm/二叉树给定值所有路径.html","title":"二叉树给定值所有路径","keywords":"","body":"题目 输入一棵二叉树和一个整数，打印出二叉树中节点值的和为输入整数的所有路径。从树的根节点开始往下一直到叶节点所经过的节点形成一条路径。 解题思路 pathSum(root, sum) 函数： 初始化： 结果列表 res ，路径列表 path 。 返回值： 返回 res 即可。 recur(root, tar) 函数： 递推参数： 当前节点 root ，当前目标值 tar 。 终止条件： 若节点 root 为空，则直接返回。 递推工作： 路径更新： 将当前节点值 root.val 加入路径 path ； 目标值更新： tar = tar - root.val（即目标值 tar 从 sum 减至 0 ）； 路径记录： 当 ① root 为叶节点 且 ② 路径和等于目标值 ，则将此路径 path 加入 res 。 先序遍历： 递归左 / 右子节点。 路径恢复： 向上回溯前，需要将当前节点从路径 path 中删除，即执行 path.pop() 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { LinkedList> res = new LinkedList<>(); LinkedList path = new LinkedList<>(); public List> pathSum(TreeNode root, int sum) { recur(root, sum); return res; } void recur(TreeNode root, int tar) { if(root == null) return; int nextSum = tar - root.val; path.add(root.val); if(root.left == null && root.right == null){ if (nextSum == 0) { res.add(new LinkedList(path)); } } recur(root.left, nextSum); recur(root.right, nextSum); path.removeLast(); } } "},"content/Algorithm/对称二叉树.html":{"url":"content/Algorithm/对称二叉树.html","title":"对称二叉树","keywords":"","body":"题目 给定一个二叉树，检查它是否是镜像对称的。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public boolean isSymmetric(TreeNode root) { if(root==null) { return true; } //调用递归函数，比较左节点，右节点 return dfs(root.left,root.right); } boolean dfs(TreeNode left, TreeNode right) { //递归的终止条件是两个节点都为空 //或者两个节点中有一个为空 //或者两个节点的值不相等 if(left==null && right==null) { return true; } if(left==null || right==null) { return false; } if(left.val!=right.val) { return false; } //再递归的比较 左节点的左孩子 和 右节点的右孩子 //以及比较 左节点的右孩子 和 右节点的左孩子 return dfs(left.left,right.right) && dfs(left.right,right.left); } } "},"content/Algorithm/翻转二叉树.html":{"url":"content/Algorithm/翻转二叉树.html","title":"翻转二叉树","keywords":"","body":"题目 翻转一棵二叉树。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public TreeNode invertTree(TreeNode root) { //递归函数的终止条件，节点为空时返回 if(root==null) { return null; } //下面三句是将当前节点的左右子树交换 TreeNode tmp = root.right; root.right = root.left; root.left = tmp; //递归交换当前节点的 左子树 invertTree(root.left); //递归交换当前节点的 右子树 invertTree(root.right); //函数返回时就表示当前这个节点，以及它的左右子树 //都已经交换完了 return root; } } "},"content/Algorithm/是否平衡二叉树.html":{"url":"content/Algorithm/是否平衡二叉树.html","title":"是否平衡二叉树","keywords":"","body":"题目 给定一个二叉树，判断它是否是高度平衡的二叉树。 本题中，一棵高度平衡二叉树定义为：一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public boolean isBalanced(TreeNode root) { return height(root) >= 0; } public int height(TreeNode treeNode){ if (treeNode == null){ return 0; } int leftHeight = height(treeNode.left); int rightHeight = height(treeNode.right); if (leftHeight == -1 || rightHeight == -1 || Math.abs(leftHeight - rightHeight) > 1) { return -1; } else { return Math.max(leftHeight, rightHeight) + 1; } } } "},"content/Algorithm/二叉树的所有路径.html":{"url":"content/Algorithm/二叉树的所有路径.html","title":"二叉树的所有路径","keywords":"","body":"题目 给定一个二叉树，返回所有从根节点到叶子节点的路径。 解题思路 根据函数 maxGain 得到每个节点的最大贡献值。对于二叉树中的一个节点，该节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值，如果子节点的最大贡献值为正，则计入该节点的最大路径和，否则不计入该节点的最大路径和。维护一个全局变量 maxSum 存储最大路径和，在递归过程中更新 maxSum 的值，最后得到的 maxSum 的值即为二叉树中的最大路径和。 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public List binaryTreePaths(TreeNode root) { List paths = new ArrayList(); constructPaths(root, \"\", paths); return paths; } public void constructPaths(TreeNode root, String path, List paths) { if (root != null) { StringBuffer pathSB = new StringBuffer(path); pathSB.append(Integer.toString(root.val)); if (root.left == null && root.right == null) { // 当前节点是叶子节点 paths.add(pathSB.toString()); // 把路径加入到答案中 } else { pathSB.append(\"->\"); // 当前节点不是叶子节点，继续递归遍历 constructPaths(root.left, pathSB.toString(), paths); constructPaths(root.right, pathSB.toString(), paths); } } } } "},"content/Algorithm/二叉树中和为某一值的路径.html":{"url":"content/Algorithm/二叉树中和为某一值的路径.html","title":"二叉树中和为某一值的路径","keywords":"","body":"题目 输入一棵二叉树和一个整数，打印出二叉树中节点值的和为输入整数的所有路径。从树的根节点开始往下一直到叶节点所经过的节点形成一条路径。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { LinkedList> res = new LinkedList<>(); LinkedList path = new LinkedList<>(); public List> pathSum(TreeNode root, int sum) { recur(root, sum); return res; } void recur(TreeNode root, int tar) { if(root == null) return; int nextSum = tar - root.val; path.add(root.val); if(root.left == null && root.right == null){ if (nextSum == 0) { res.add(new LinkedList(path)); } } recur(root.left, nextSum); recur(root.right, nextSum); path.removeLast(); } } "},"content/Algorithm/树的子结构.html":{"url":"content/Algorithm/树的子结构.html","title":"树的子结构","keywords":"","body":"题目 输入两棵二叉树A和B，判断B是不是A的子结构。(约定空树不是任意一个树的子结构) B是A的子结构， 即 A中有出现和B相同的结构和节点值。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public boolean isSubStructure(TreeNode A, TreeNode B) { if (A == null || B == null) return false; //先从根节点判断B是不是A的子结构，如果不是在分别从左右两个子树判断， //只要有一个为true，就说明B是A的子结构 return isSub(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B); } boolean isSub(TreeNode A, TreeNode B) { //这里如果B为空，说明B已经访问完了，确定是A的子结构 if (B == null) return true; //如果B不为空A为空，或者这两个节点值不同，说明B树不是 //A的子结构，直接返回false if (A == null || A.val != B.val) return false; //当前节点比较完之后还要继续判断左右子节点 return isSub(A.left, B.left) && isSub(A.right, B.right); } } "},"content/Algorithm/判断二叉树对称.html":{"url":"content/Algorithm/判断二叉树对称.html","title":"判断二叉树对称","keywords":"","body":"题目 请实现一个函数，用来判断一棵二叉树是不是对称的。如果一棵二叉树和它的镜像一样，那么它是对称的。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public boolean isSymmetric(TreeNode root) { if (root == null) return true; //从两个子节点开始判断 return isSymmetricHelper(root.left, root.right); } public boolean isSymmetricHelper(TreeNode left, TreeNode right) { //如果左右子节点都为空，说明当前节点是叶子节点，返回true if (left == null && right == null) return true; //如果当前节点只有一个子节点或者有两个子节点，但两个子节点的值不相同，直接返回false if (left == null || right == null || left.val != right.val) return false; //然后左子节点的左子节点和右子节点的右子节点比较，左子节点的右子节点和右子节点的左子节点比较 return isSymmetricHelper(left.left, right.right) && isSymmetricHelper(left.right, right.left); } } "},"content/Algorithm/二叉树展开为列表.html":{"url":"content/Algorithm/二叉树展开为列表.html","title":"二叉树展开为列表","keywords":"","body":"题目 给定一个二叉树，原地将它展开为一个单链表。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { // 定义：将以 root 为根的树拉平为链表 void flatten(TreeNode root) { // base case if (root == null) return; flatten(root.left); flatten(root.right); /**** 后序遍历位置 ****/ // 1、左右子树已经被拉平成一条链表 TreeNode left = root.left; TreeNode right = root.right; // 2、将左子树作为右子树 root.left = null; root.right = left; // 3、将原先的右子树接到当前右子树的末端 TreeNode p = root; while (p.right != null) { p = p.right; } p.right = right; } } "},"content/Algorithm/二叉搜索树第k大节点.html":{"url":"content/Algorithm/二叉搜索树第k大节点.html","title":"二叉搜索树第k大节点","keywords":"","body":"题目 给定一棵二叉搜索树，请找出其中第k大的节点。 解题思路 本文解法基于此性质：二叉搜索树的中序遍历为 递增序列 。 根据以上性质，易得二叉搜索树的 中序遍历倒序 为 递减序列 。 因此，求 “二叉搜索树第 k 大的节点” 可转化为求 “此树的中序遍历倒序的第 k 个节点”。 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { int res, k; public int kthLargest(TreeNode root, int k) { this.k = k; dfs(root); return res; } void dfs(TreeNode root) { if(root == null) return; dfs(root.right); k=k-1; if(k == 0) { res = root.val; return ; } dfs(root.left); } } "},"content/Algorithm/前序与中序构造二叉树.html":{"url":"content/Algorithm/前序与中序构造二叉树.html","title":"前序与中序构造二叉树","keywords":"","body":"题目 根据一棵树的前序遍历与中序遍历构造二叉树。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { private Map indexMap; public TreeNode buildTree(int[] preorder, int[] inorder) { int n = preorder.length; // 构造哈希映射，帮助我们快速定位根节点 indexMap = new HashMap(); for (int i = 0; i preorder_right) { return null; } // 前序遍历中的第一个节点就是根节点 int preorder_root = preorder_left; // 在中序遍历中定位根节点 int inorder_root = indexMap.get(preorder[preorder_root]); // 先把根节点建立出来 TreeNode root = new TreeNode(preorder[preorder_root]); // 得到左子树中的节点数目 int size_left_subtree = inorder_root - inorder_left; // 递归地构造左子树，并连接到根节点 // 先序遍历中「从 左边界+1 开始的 size_left_subtree」个元素就对应了中序遍历中「从 左边界 开始到 根节点定位-1」的元素 root.left = myBuildTree(preorder, inorder, preorder_left + 1, preorder_left + size_left_subtree, inorder_left, inorder_root - 1); // 递归地构造右子树，并连接到根节点 // 先序遍历中「从 左边界+1+左子树节点数目 开始到 右边界」的元素就对应了中序遍历中「从 根节点定位+1 到 右边界」的元素 root.right = myBuildTree(preorder, inorder, preorder_left + size_left_subtree + 1, preorder_right, inorder_root + 1, inorder_right); return root; } } "},"content/Algorithm/填充每个节点的下一个右侧节点.html":{"url":"content/Algorithm/填充每个节点的下一个右侧节点.html","title":"填充每个节点的下一个右侧节点","keywords":"","body":"题目 给定一个 完美二叉树 ，其所有叶子节点都在同一层，每个父节点都有两个子节点。二叉树定义如下： struct Node { int val; Node left; Node right; Node *next; } 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。 初始状态下，所有 next 指针都被设置为 NULL。 解题思路 代码 /* // Definition for a Node. class Node { public int val; public Node left; public Node right; public Node next; public Node() {} public Node(int _val) { val = _val; } public Node(int _val, Node _left, Node _right, Node _next) { val = _val; left = _left; right = _right; next = _next; } }; */ class Solution { Node connect(Node root) { if (root == null) return null; connectTwoNode(root.left, root.right); return root; } // 辅助函数 void connectTwoNode(Node node1, Node node2) { if (node1 == null || node2 == null) { return; } /**** 前序遍历位置 ****/ // 将传入的两个节点连接 node1.next = node2; // 连接相同父节点的两个子节点 connectTwoNode(node1.left, node1.right); connectTwoNode(node2.left, node2.right); // 连接跨越父节点的两个子节点 connectTwoNode(node1.right, node2.left); } } class Solution { public Node connect(Node root) { if (root == null) { return root; } // 初始化队列同时将第一层节点加入队列中，即根节点 Queue queue = new LinkedList(); queue.add(root); // 外层的 while 循环迭代的是层数 while (!queue.isEmpty()) { // 记录当前队列大小 int size = queue.size(); // 遍历这一层的所有节点 for (int i = 0; i "},"content/Algorithm/最大二叉树.html":{"url":"content/Algorithm/最大二叉树.html","title":"最大二叉树","keywords":"","body":"题目 给定一个不含重复元素的整数数组。一个以此数组构建的最大二叉树定义如下： 二叉树的根是数组中的最大元素。 左子树是通过数组中最大值左边部分构造出的最大二叉树。 右子树是通过数组中最大值右边部分构造出的最大二叉树。 通过给定的数组构建最大二叉树，并且输出这个树的根节点。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { TreeNode constructMaximumBinaryTree(int[] nums) { return build(nums, 0, nums.length - 1); } /* 将 nums[lo..hi] 构造成符合条件的树，返回根节点 */ TreeNode build(int[] nums, int lo, int hi) { // base case if (lo > hi) { return null; } // 找到数组中的最大值和对应的索引 int index = -1, maxVal = Integer.MIN_VALUE; for (int i = lo; i "},"content/Algorithm/左叶子之和.html":{"url":"content/Algorithm/左叶子之和.html","title":"左叶子之和","keywords":"","body":"题目 计算给定二叉树的所有左叶子之和。 解题思路 代码 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int sumOfLeftLeaves(TreeNode root) { return check(root); } private int check(TreeNode root) { if (root == null) { return 0; } int sum = 0; if(root.left !=null && root.left.left == null && root.left.right == null) { sum+=root.left.val; } return sum + check(root.left) + check(root.right); } } "},"content/Algorithm/最大子序和.html":{"url":"content/Algorithm/最大子序和.html","title":"最大子序和","keywords":"","body":"题目 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 解题思路 代码 class Solution { public int maxSubArray(int[] nums) { //特判 if(nums == null || nums.length == 0) return 0; //初始化 int curSum = 0; int maxSum = Integer.MIN_VALUE; int startIndex = 0; int endIndex = 0; int tempIndex = 0; //遍历 int len = nums.length; for(int i = 0; i maxSum){ //更新maxSum maxSum = curSum; endIndex = i; startIndex = tempIndex; } if(curSum "},"content/Algorithm/和为S长度最小子数组.html":{"url":"content/Algorithm/和为S长度最小子数组.html","title":"和为S长度最小子数组","keywords":"","body":"题目 给定一个含有 n 个正整数的数组和一个正整数 s ，找出该数组中满足其和 ≥ s 的长度最小的 连续 子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。 解题思路 代码 class Solution { public int minSubArrayLen(int s, int[] nums) { int n = nums.length; if (n == 0) { return 0; } int ans = Integer.MAX_VALUE; int start = 0; int sum = 0; for (int end = 0;end = s) { ans = Math.min(ans, end - start + 1); sum = sum - nums[start]; start = start + 1; } } return ans == Integer.MAX_VALUE ? 0 : ans; } } "},"content/Algorithm/数组中的第K个最大元素.html":{"url":"content/Algorithm/数组中的第K个最大元素.html","title":"数组中的第K个最大元素","keywords":"","body":"题目 在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。 解题思路 快排 代码 class Solution { Random random = new Random(); public int findKthLargest(int[] nums, int k) { return quickSelect(nums, 0, nums.length - 1, nums.length - k); } public int quickSelect(int[] a, int l, int r, int index) { int q = randomPartition(a, l, r); if (q == index) { return a[q]; } else { return q "},"content/Algorithm/搜索插入位置.html":{"url":"content/Algorithm/搜索插入位置.html","title":"搜索插入位置","keywords":"","body":"题目 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 你可以假设数组中无重复元素。 解题思路 代码 class Solution { public int searchInsert(int[] nums, int target) { int n = nums.length; int left = 0, right = n - 1, ans = n; while (left > 1) + left; if (target "},"content/Algorithm/寻找数组的中心位置.html":{"url":"content/Algorithm/寻找数组的中心位置.html","title":"寻找数组的中心位置","keywords":"","body":"题目 给定一个整数类型的数组 nums，请编写一个能够返回数组 “中心索引” 的方法。 我们是这样定义数组 中心索引 的：数组中心索引的左侧所有元素相加的和等于右侧所有元素相加的和。 如果数组不存在中心索引，那么我们应该返回 -1。如果数组有多个中心索引，那么我们应该返回最靠近左边的那一个。 解题思路 代码 class Solution { public int pivotIndex(int[] nums) { int sum = 0, leftsum = 0; for (int x: nums) sum += x; for (int i = 0; i "},"content/Algorithm/颜色分类-分类排序.html":{"url":"content/Algorithm/颜色分类-分类排序.html","title":"颜色分类-分类排序","keywords":"","body":"题目 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。 此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。 解题思路 双指针 如果找到了 1，进行交换，并将 p_1向后移动一个位置， 如果找到了 0，将其进行交换，如果 p_0 代码 class Solution { public void sortColors(int[] nums) { int n = nums.length; int p0 = 0, p1 = 0; for (int i = 0; i "},"content/Algorithm/有序数组两数之和.html":{"url":"content/Algorithm/有序数组两数之和.html","title":"有序数组两数之和","keywords":"","body":"题目 给定一个已按照升序排列 的有序数组，找到两个数使得它们相加之和等于目标数。 函数应该返回这两个下标值 index1 和 index2，其中 index1 必须小于 index2。 解题思路 代码 class Solution { public int[] twoSum(int[] numbers, int target) { int low = 0, high = numbers.length - 1; while (low "},"content/Algorithm/二分查找.html":{"url":"content/Algorithm/二分查找.html","title":"二分查找","keywords":"","body":"题目 给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。 解题思路 代码 class Solution { public int search(int[] nums, int target) { int mid, left = 0, right = nums.length - 1; while (left "},"content/Algorithm/合并两个有序数组.html":{"url":"content/Algorithm/合并两个有序数组.html","title":"合并两个有序数组","keywords":"","body":"题目 给你两个有序整数数组 nums1 和 nums2，请你将 nums2 合并到 nums1 中，使 nums1 成为一个有序数组。 解题思路 代码 class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { int len1 = m - 1; int len2 = n - 1; int len = m + n - 1; while(len1 >= 0 && len2 >= 0) { if(nums1[len1]>nums2[len2]){ nums1[len] = nums1[len1]; len1 = len1 -1; }else{ nums1[len] = nums2[len2]; len2 = len2 -1; } len = len -1; } System.arraycopy(nums2, 0, nums1, 0, len2 + 1); } } "},"content/Algorithm/数组拆分返回最大子和.html":{"url":"content/Algorithm/数组拆分返回最大子和.html","title":"数组拆分返回最大子和","keywords":"","body":"题目 给定长度为 2n 的整数数组 nums ，你的任务是将这些数分成 n 对, 例如 (a1, b1), (a2, b2), ..., (an, bn) ，使得从 1 到 n 的 min(ai, bi) 总和最大。 返回该 最大总和 。 解题思路 我们可以对给定数组的元素进行排序，并直接按排序顺序形成元素的配对。这将导致元素的配对，它们之间的差异最小，从而导致所需总和的最大化。 代码 class Solution { public int arrayPairSum(int[] nums) { Arrays.sort(nums); int sum = 0; for (int i = 0; i "},"content/Algorithm/移除指定元素.html":{"url":"content/Algorithm/移除指定元素.html","title":"移除指定元素","keywords":"","body":"题目 给你一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，并返回移除后数组的新长度。 解题思路 代码 class Solution { //双指针，改变原有顺序 // public int removeElement(int[] nums, int val) { // int i = 0; // int j = nums.length; // while (i "},"content/Algorithm/最大连续1个数.html":{"url":"content/Algorithm/最大连续1个数.html","title":"最大连续1个数","keywords":"","body":"题目 给定一个二进制数组， 计算其中最大连续1的个数。 解题思路 代码 class Solution { public int findMaxConsecutiveOnes(int[] nums) { int count = 0; int maxCount = 0; for(int i = 0; i "},"content/Algorithm/移动0.html":{"url":"content/Algorithm/移动0.html","title":"移动0","keywords":"","body":"题目 给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 解题思路 代码 class Solution { public void moveZeroes(int[] nums) { if(nums==null) { return; } //第一次遍历的时候，j指针记录非0的个数，只要是非0的统统都赋给nums[j] int j = 0; for(int i=0;i "},"content/Algorithm/合并区间.html":{"url":"content/Algorithm/合并区间.html","title":"合并区间","keywords":"","body":"题目 给出一个区间的集合，请合并所有重叠的区间。 解题思路 如果我们按照区间的左端点排序，那么在排完序的列表中，可以合并的区间一定是连续的。 如果当前区间的左端点在数组 merged 中最后一个区间的右端点之后，那么它们不会重合，我们可以直接将这个区间加入数组 merged 的末尾； 否则，它们重合，我们需要用当前区间的右端点更新数组 merged 中最后一个区间的右端点，将其置为二者的较大值。 代码 //第一步。排序 Arrays.sort(intervals, (v1, v2) -> v1[0] - v2[0]); //然后比较如果当前区间的左端点在数组 merged 中最后一个区间的右端点之后，那么它们不会重合，我们可以直接将这个区间加入数组 merged 的末尾； //否则，它们重合，我们需要用当前区间的右端点更新数组 merged 中最后一个区间的右端点，将其置为二者的较大值。 class Solution { public int[][] merge(int[][] intervals) { if (intervals.length == 0) { return new int[0][2]; } Arrays.sort(intervals, new Comparator() { public int compare(int[] interval1, int[] interval2) { return interval1[0] - interval2[0]; } }); List merged = new ArrayList(); for (int i = 0; i "},"content/Algorithm/插入区间.html":{"url":"content/Algorithm/插入区间.html","title":"插入区间","keywords":"","body":"题目 给出一个无重叠的 ，按照区间起始端点排序的区间列表。 在列表中插入一个新的区间，你需要确保列表中的区间仍然有序且不重叠（如果有必要的话，可以合并区间） 解题思路 代码 class Solution { public int[][] insert(int[][] intervals, int[] newInterval) { int left = newInterval[0]; int right = newInterval[1]; boolean placed = false; List ansList = new ArrayList(); for (int[] interval : intervals) { if (interval[0] > right) { // 在插入区间的右侧且无交集 if (!placed) { ansList.add(new int[]{left, right}); placed = true; } ansList.add(interval); } else if (interval[1] "},"content/Algorithm/汇总区间.html":{"url":"content/Algorithm/汇总区间.html","title":"汇总区间","keywords":"","body":"题目 给定一个无重复元素的有序整数数组 nums 。 返回 恰好覆盖数组中所有数字 的 最小有序 区间范围列表。也就是说，nums 的每个元素都恰好被某个区间范围所覆盖，并且不存在属于某个范围但不属于 nums 的数字 x 。 列表中的每个区间范围 [a,b] 应该按如下格式输出： \"a->b\" ，如果 a != b \"a\" ，如果 a == b 解题思路 题目所给出的数组是有序的，同时还没有重复元素。在这样的数组里面，两个相邻的元素的差值要么等于 1 要么大于 1。对于那些差值等于 1 的就将它们被放在同一段区间内；否则，就将把它们放在不同的区间。 不要忘记把最后一段区间也放进结果里面。这个逻辑很容易实现，你可以在循环里通过一个特定的判断条件来加入或者在循环结束后加入。 代码 class Solution { public List summaryRanges(int[] nums) { List summary = new ArrayList<>(); for (int i = 0, j = 0; j \" + nums[j]); i = j + 1; } return summary; } } "},"content/Algorithm/删除区间.html":{"url":"content/Algorithm/删除区间.html","title":"删除区间","keywords":"","body":"题目 给你一个区间列表，请你删除列表中被其他区间所覆盖的区间。 只有当 c 在完成所有删除操作后，请你返回列表中剩余区间的数目。 解题思路 如果我们按照区间的左端点排序，那么在排完序的列表中，可以合并的区间一定是连续的。 如果当前区间的左端点在数组 merged 中最后一个区间的右端点之后，那么它们不会重合，我们可以直接将这个区间加入数组 merged 的末尾； 否则，它们重合，我们需要用当前区间的右端点更新数组 merged 中最后一个区间的右端点，将其置为二者的较大值。 代码 //先对原始数组进行排序，左边界升序，右边界降序，这样遍历比较时只需要考虑右边界即可。以此保证左边界相同时，右边的都是可以删除的。用一个符号max记录当前最大的有边界，当左边界不同时，当前右边界的若小于前一个，则可删除，否则就比较当前右边界和上一个哪一个较大，替换max。 class Solution { public int removeCoveredIntervals(int[][] intervals) { Arrays.sort(intervals,new Comparator<>(){ public int compare(int[] o1,int[] o2){ if(o1[0]==o2[0]){ return o2[1]-o1[1]; }else{ return o1[0]-o2[0]; } } }); int count=intervals.length,res=count;; int max=intervals[0][1]; for(int i=1;i "},"content/Algorithm/删除数组中的重复项-保留一个.html":{"url":"content/Algorithm/删除数组中的重复项-保留一个.html","title":"删除数组中的重复项-保留一个","keywords":"","body":"题目 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。 解题思路 代码 class Solution { public int removeDuplicates(int[] nums) { if (nums.length == 0) return 0; int i = 0; for (int j = 1; j "},"content/Algorithm/删除数组中的重复项-保留两个.html":{"url":"content/Algorithm/删除数组中的重复项-保留两个.html","title":"删除数组中的重复项-保留两个","keywords":"","body":"题目 给定一个增序排列数组 nums ，你需要在原地删除重复出现的元素，使得每个元素最多出现两次，返回移除后数组的新长度。 解题思路 代码 class Solution { public int removeDuplicates(int[] nums) { int j = 1, count = 1; for (int i = 1; i "},"content/Algorithm/盛最多水的容器.html":{"url":"content/Algorithm/盛最多水的容器.html","title":"盛最多水的容器","keywords":"","body":"题目 给你 n 个非负整数 a1，a2，...，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 解题思路 双指针，移动对应数字较小的那个指针。 代码 class Solution { public int maxArea(int[] height) { int l = 0, r = height.length - 1; int ans = 0; while (l "},"content/Algorithm/两数组中最长重复子数组.html":{"url":"content/Algorithm/两数组中最长重复子数组.html","title":"两数组中最长重复子数组","keywords":"","body":"题目 给两个整数数组 A 和 B ，返回两个数组中公共的、长度最长的子数组的长度。 解题思路 代码 滑动窗口 class Solution { public int findLength(int[] A, int[] B) { int n = A.length, m = B.length; int ret = 0; for (int i = 0; i 动态规划 令 dp[i][j] 表示 A[i:] 和 B[j:] 的最长公共前缀，那么答案即为所有 dp[i][j] 中的最大值。如果 A[i] == B[j]，那么 dp[i][j] = dp[i + 1][j + 1] + 1，否则 dp[i][j] = 0。 考虑到这里 dp[i][j] 的值从 dp[i + 1][j + 1] 转移得到，所以我们需要倒过来，首先计算 dp[len(A) - 1][len(B) - 1]，最后计算 dp[0][0]。 class Solution { public int findLength(int[] A, int[] B) { int n = A.length, m = B.length; int[][] dp = new int[n + 1][m + 1]; int ans = 0; for (int i = n - 1; i >= 0; i--) { for (int j = m - 1; j >= 0; j--) { dp[i][j] = A[i] == B[j] ? dp[i + 1][j + 1] + 1 : 0; ans = Math.max(ans, dp[i][j]); } } return ans; } } "},"content/Algorithm/二维数组查找包含元素.html":{"url":"content/Algorithm/二维数组查找包含元素.html","title":"二维数组查找包含元素","keywords":"","body":"题目 在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 解题思路 我们可以对给定数组的元素进行排序，并直接按排序顺序形成元素的配对。这将导致元素的配对，它们之间的差异最小，从而导致所需总和的最大化。 代码 class Solution { public boolean findNumberIn2DArray(int[][] matrix, int target) { if (matrix == null || matrix.length == 0 || matrix[0].length == 0) { return false; } int rows = matrix.length, columns = matrix[0].length; int row = 0, column = columns - 1; while (row = 0) { int num = matrix[row][column]; if (num == target) { return true; } else if (num > target) { column--; } else { row++; } } return false; } } "},"content/Algorithm/数组中重复数字.html":{"url":"content/Algorithm/数组中重复数字.html","title":"数组中重复数字","keywords":"","body":"题目 找出数组中重复的数字。 在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。 解题思路 代码 class Solution { public int findRepeatNumber(int[] nums) { Set set = new HashSet(); int repeat = -1; for (int num : nums) { if (!set.add(num)) { repeat = num; break; } } return repeat; } } "},"content/Algorithm/调整数组顺序使奇数位于偶数前面.html":{"url":"content/Algorithm/调整数组顺序使奇数位于偶数前面.html","title":"调整数组顺序使奇数位于偶数前面","keywords":"","body":"题目 输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。 解题思路 代码 class Solution { public int[] exchange(int[] nums) { int i = 0, j = nums.length - 1, tmp; while(i "},"content/Algorithm/最小K个数.html":{"url":"content/Algorithm/最小K个数.html","title":"最小K个数","keywords":"","body":"题目 输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。 解题思路 代码 class Solution { public int[] getLeastNumbers(int[] arr, int k) { if (k == 0 || arr.length == 0) { return new int[0]; } // 最后一个参数表示我们要找的是下标为k-1的数 return quickSearch(arr, 0, arr.length - 1, k - 1); } private int[] quickSearch(int[] nums, int lo, int hi, int k) { // 每快排切分1次，找到排序后下标为j的元素，如果j恰好等于k就返回j以及j左边所有的数； int j = partition(nums, lo, hi); if (j == k) { return Arrays.copyOf(nums, j + 1); } // 否则根据下标j与k的大小关系来决定继续切分左段还是右段。 return j > k? quickSearch(nums, lo, j - 1, k): quickSearch(nums, j + 1, hi, k); } // 快排切分，返回下标j，使得比nums[j]小的数都在j的左边，比nums[j]大的数都在j的右边。 private int partition(int[] nums, int lo, int hi) { int v = nums[lo]; int i = lo, j = hi + 1; while (true) { while (++i = lo && nums[j] > v); if (i >= j) { break; } int t = nums[j]; nums[j] = nums[i]; nums[i] = t; } nums[lo] = nums[j]; nums[j] = v; return j; } } "},"content/Algorithm/和为s的连续正数序列.html":{"url":"content/Algorithm/和为s的连续正数序列.html","title":"和为s的连续正数序列","keywords":"","body":"题目 输入一个正整数 target ，输出所有和为 target 的连续正整数序列（至少含有两个数）。 序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。 解题思路 代码 class Solution { public int[][] findContinuousSequence(int target) { int i = 1; // 滑动窗口的左边界 int j = 1; // 滑动窗口的右边界 int sum = 0; // 滑动窗口中数字的和 List res = new ArrayList<>(); while (i target) { // 左边界向右移动 sum -= i; i++; } else { // 记录结果 int[] arr = new int[j-i]; for (int k = i; k "},"content/Algorithm/矩阵中是否包含字符串路径.html":{"url":"content/Algorithm/矩阵中是否包含字符串路径.html","title":"矩阵中是否包含字符串路径","keywords":"","body":"题目 请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一格开始，每一步可以在矩阵中向左、右、上、下移动一格。如果一条路径经过了矩阵的某一格，那么该路径不能再次进入该格子 解题思路 代码 class Solution { public boolean exist(char[][] board, String word) { char[] words = word.toCharArray(); for(int i = 0; i = board.length || j = board[0].length || board[i][j] != words[p]){ return false; } if(p == words.length - 1){ return true; } char tmp = board[i][j]; board[i][j] = '#'; boolean res = helper(board,words,i-1,j,p+1) || helper(board,words,i+1,j,p+1) || helper(board,words,i,j-1,p+1) || helper(board,words,i,j+1,p+1); board[i][j] = tmp; return res; } } "},"content/Algorithm/数组三数之和.html":{"url":"content/Algorithm/数组三数之和.html","title":"数组三数之和","keywords":"","body":"题目 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 解题思路 代码 class Solution { public List> threeSum(int[] nums) { int n = nums.length; Arrays.sort(nums); List> ans = threeSumTarget(nums,0); return ans; } public List> threeSumTarget(int[] nums,int target){ int n = nums.length; List> res = new ArrayList>(); for (int first = 0; first 0 && nums[first] == nums[first - 1]) { continue; } List> temp = new ArrayList>(); temp = twoSumTarget(nums,first+1,target-nums[first]); for(int i=0;i> twoSumTarget(int[] nums,int start,int target){ List> res = new ArrayList>(); int left = start; int right = nums.length-1; while(left target){ right--; }else{ List temp = new ArrayList(); temp.add(leftValue); temp.add(rightValue); res.add(temp); while(left "},"content/Algorithm/数组中出现次数超过一半的数字.html":{"url":"content/Algorithm/数组中出现次数超过一半的数字.html","title":"数组中出现次数超过一半的数字","keywords":"","body":"题目 数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。解题思路 代码 class Solution { public int majorityElement(int[] nums) { int x = 0, votes = 0, count = 0; for(int num : nums){ if(votes == 0) x = num; votes += num == x ? 1 : -1; } return x; // 验证 x 是否为众数 //for(int num : nums) // if(num == x) count++; // return count > nums.length / 2 ? x : 0; // 当无众数时返回 0 } } "},"content/Algorithm/数组中只出现一次的数字.html":{"url":"content/Algorithm/数组中只出现一次的数字.html","title":"数组中只出现一次的数字","keywords":"","body":"题目 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 解题思路 代码 class Solution { public int singleNumber(int[] nums) { int single = 0; for (int num : nums) { single ^= num; } return single; } } "},"content/Algorithm/数组中两个出现一次的数字.html":{"url":"content/Algorithm/数组中两个出现一次的数字.html","title":"数组中两个出现一次的数字","keywords":"","body":"题目 一个整型数组 nums 里除两个数字之外，其他数字都出现了两次。请写程序找出这两个只出现一次的数字。要求时间复杂度是O(n)，空间复杂度是O(1)。 解题思路 先对所有数字进行一次异或，得到两个出现一次的数字的异或值。 在异或结果中找到任意为 11 的位。 根据这一位对所有的数字进行分组。 在每个组内进行异或操作，得到两个数字。 代码 class Solution { public int[] singleNumbers(int[] nums) { int ret = 0; for (int n : nums) { ret ^= n; } int div = 1; //获得最低位的1 while ((div & ret) == 0) { div "},"content/Algorithm/数组中元素第一和最后位置.html":{"url":"content/Algorithm/数组中元素第一和最后位置.html","title":"数组中元素第一和最后位置","keywords":"","body":"题目 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。 解题思路 代码 class Solution { public int[] searchRange(int[] nums, int target) { int left = left_bound(nums,target); int right = right_bound(nums,target); if(left == -1){ return new int[]{-1, -1}; } else if(right == -1){ return new int[]{-1, -1}; }else{ return new int[]{left, right}; } } int left_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left target) { right = mid - 1; } else if (nums[mid] == target) { // 别返回，锁定左侧边界 right = mid - 1; } } // 最后要检查 left 越界的情况 if (left >= nums.length || nums[left] != target) return -1; return left; } int right_bound(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left target) { right = mid - 1; } else if (nums[mid] == target) { // 别返回，锁定右侧边界 left = mid + 1; } } // 最后要检查 right 越界的情况 if (right "},"content/Algorithm/统计数字在数组中出现次数.html":{"url":"content/Algorithm/统计数字在数组中出现次数.html","title":"统计数字在数组中出现次数","keywords":"","body":"题目 统计一个数字在排序数组中出现的次数。 解题思路 代码 class Solution { public int search(int[] nums, int target) { if (nums == null || nums.length == 0) { return 0; } int left = 0; int right = nums.length - 1; while(left target) right--; } return 0; } } "},"content/Algorithm/无重复数字的全排列.html":{"url":"content/Algorithm/无重复数字的全排列.html","title":"无重复数字的全排列","keywords":"","body":"题目 给定一个 没有重复 数字的序列，返回其所有可能的全排列。 解题思路 代码 class Solution { List> res = new LinkedList<>(); /* 主函数，输入一组不重复的数字，返回它们的全排列 */ List> permute(int[] nums) { // 记录「路径」 LinkedList track = new LinkedList<>(); backtrack(nums, track); return res; } // 路径：记录在 track 中 // 选择列表：nums 中不存在于 track 的那些元素 // 结束条件：nums 中的元素全都在 track 中出现 void backtrack(int[] nums, LinkedList track) { // 触发结束条件 if (track.size() == nums.length) { res.add(new LinkedList(track)); return; } for (int i = 0; i "},"content/Algorithm/重复数字的全排列.html":{"url":"content/Algorithm/重复数字的全排列.html","title":"重复数字的全排列","keywords":"","body":"题目 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。 解题思路 代码 class Solution { Set> result = new HashSet<>(); public List> permuteUnique(int[] nums) { boolean[] visited = new boolean[nums.length]; LinkedList track = new LinkedList<>(); process(nums, track, visited); return new ArrayList<>(result); } private void process(int[] nums, LinkedList track, boolean[] visited){ if(nums.length == track.size()){ result.add(new LinkedList(track)); return; } for(int i = 0; i "},"content/Algorithm/左旋转字符串.html":{"url":"content/Algorithm/左旋转字符串.html","title":"左旋转字符串","keywords":"","body":"题目 字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串\"abcdefg\"和数字2，该函数将返回左旋转两位得到的结果\"cdefgab\"。 解题思路 代码 class Solution { public String reverseLeftWords(String s, int n) { StringBuilder res = new StringBuilder(); for(int i = n; i "},"content/Algorithm/最长公共前缀.html":{"url":"content/Algorithm/最长公共前缀.html","title":"最长公共前缀","keywords":"","body":"题目 编写一个函数来查找字符串数组中的最长公共前缀。 如果不存在公共前缀，返回空字符串 \"\"。 解题思路 代码 class Solution { public String longestCommonPrefix(String[] strs) { if (strs == null || strs.length == 0) { return \"\"; } String prefix = strs[0]; int count = strs.length; for (int i = 1; i "},"content/Algorithm/最长不含重复字符的子串.html":{"url":"content/Algorithm/最长不含重复字符的子串.html","title":"最长不含重复字符的子串","keywords":"","body":"题目 请从字符串中找出一个最长的不包含重复字符的子字符串，计算该最长子字符串的长度。 解题思路 代码 class Solution { public int lengthOfLongestSubstring(String s) { Map dic = new HashMap<>(); int i = 0, res = 0; for(int j = 0; j "},"content/Algorithm/最小覆盖字串.html":{"url":"content/Algorithm/最小覆盖字串.html","title":"最小覆盖字串","keywords":"","body":"题目 给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 \"\" 。 注意：如果 s 中存在这样的子串，我们保证它是唯一的答案。 解题思路 我们可以用滑动窗口的思想解决这个问题，在滑动窗口类型的问题中都会有两个指针。一个用于「延伸」现有窗口的 rr 指针，和一个用于「收缩」窗口的 ll 指针。在任意时刻，只有一个指针运动，而另一个保持静止。我们在 ss 上滑动窗口，通过移动 rr 指针不断扩张窗口。当窗口包含 tt 全部所需的字符后，如果能收缩，我们就收缩窗口直到得到最小窗口。 代码 class Solution { public String minWindow(String s, String t) { if (s == null || s == \"\" || t == null || t == \"\" || s.length() 0 && needs[ch] >= window[ch]) { count++; } //移动到不满足条件为止 while (count == t.length()) { ch = s.charAt(left); if (needs[ch] > 0 && needs[ch] >= window[ch]) { count--; } if (right - left + 1 "},"content/Algorithm/验证回文串.html":{"url":"content/Algorithm/验证回文串.html","title":"验证回文串","keywords":"","body":"题目 给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。 说明：本题中，我们将空字符串定义为有效的回文串。 解题思路 我们直接在原字符串 ss 上使用双指针。在移动任意一个指针时，需要不断地向另一指针的方向移动，直到遇到一个字母或数字字符，或者两指针重合为止。也就是说，我们每次将指针移到下一个字母字符或数字字符，再判断这两个指针指向的字符是否相同。 代码 class Solution { public boolean isPalindrome(String s) { int n = s.length(); int left = 0, right = n - 1; while (left "},"content/Algorithm/第一个只出现一次的字符.html":{"url":"content/Algorithm/第一个只出现一次的字符.html","title":"第一个只出现一次的字符","keywords":"","body":"题目 在字符串 s 中找出第一个只出现一次的字符。如果没有，返回一个单空格。 s 只包含小写字母。 解题思路 代码 class Solution { public char firstUniqChar(String s) { HashMap dic = new HashMap<>(); char[] sc = s.toCharArray(); for(char c : sc) dic.put(c, !dic.containsKey(c)); for(char c : sc) if(dic.get(c)) return c; return ' '; } } "},"content/Algorithm/反转字符串.html":{"url":"content/Algorithm/反转字符串.html","title":"反转字符串","keywords":"","body":"题目 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。 不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。 你可以假设数组中的所有字符都是 ASCII 码表中的可打印字符。 解题思路 代码 class Solution { public void reverseString(char[] s) { int n = s.length; for (int left = 0, right = n - 1; left "},"content/Algorithm/回文子串个数.html":{"url":"content/Algorithm/回文子串个数.html","title":"回文子串个数","keywords":"","body":"题目 给定一个字符串，你的任务是计算这个字符串中有多少个回文子串。 具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。 解题思路 代码 class Solution { public int countSubstrings(String s) { int n = s.length(), ans = 0; for (int i = 0; i = 0 && r "},"content/Algorithm/判断子序列.html":{"url":"content/Algorithm/判断子序列.html","title":"判断子序列","keywords":"","body":"题目 给定字符串 s 和 t ，判断 s 是否为 t 的子序列。 字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，\"ace\"是\"abcde\"的一个子序列，而\"aec\"不是）。 解题思路 代码 class Solution { public boolean isSubsequence(String s, String t) { int n = s.length(), m = t.length(); int i = 0, j = 0; while (i "},"content/Algorithm/字符串排列.html":{"url":"content/Algorithm/字符串排列.html","title":"字符串排列","keywords":"","body":"题目 输入一个字符串，打印出该字符串中字符的所有排列。 你可以以任意顺序返回这个字符串数组，但里面不能有重复元素。 解题思路 代码 class Solution { Set res = new HashSet<>(); public String[] permutation(String s) { char[] c = s.toCharArray(); String track = \"\"; boolean[] visited = new boolean[s.length()]; backtrack(c, track,visited); return res.toArray(new String[res.size()]); } void backtrack(char[] c, String track,boolean[] visited) { // 触发结束条件 if (track.length() == c.length) { res.add(track); return; } for (int i = 0; i "},"content/Algorithm/最长回文子串.html":{"url":"content/Algorithm/最长回文子串.html","title":"最长回文子串","keywords":"","body":"题目 给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 解题思路 代码 class Solution { public String longestPalindrome(String s) { String res = \"\"; for (int i = 0; i s1.length() ? res : s1; res = res.length() > s2.length() ? res : s2; } return res; } String palindrome(String s, int l, int r) { char[] charArray = s.toCharArray(); // 防止索引越界 while(l >= 0 && r "},"content/Algorithm/翻转链表.html":{"url":"content/Algorithm/翻转链表.html","title":"翻转链表","keywords":"","body":"题目 反转一个单链表。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ //非递归 class Solution { public ListNode reverseList(ListNode head) { ListNode pre = null; ListNode cur = head; ListNode tmp = null; while(cur!=null) { //记录当前节点的下一个节点 tmp = cur.next; //然后将当前节点指向pre cur.next = pre; //pre和cur节点都前进一位 pre = cur; cur = tmp; } return pre; } } //递归 class Solution { public ListNode reverseList(ListNode head) { //递归终止条件是当前为空，或者下一个节点为空 if(head==null || head.next==null) { return head; } //这里的last就是最后一个节点 ListNode last = reverseList(head.next); //这里请配合动画演示理解 //如果链表是 1->2->3->4->5，那么此时的last就是5 //而head是4，head的下一个是5，下下一个是空 //所以head.next.next 就是5->4 head.next.next = head; //防止链表循环，需要将head.next设置为空 head.next = null; //每层递归函数都返回last，也就是最后一个节点 return last; } } "},"content/Algorithm/给定值分隔列表.html":{"url":"content/Algorithm/给定值分隔列表.html","title":"给定值分隔列表","keywords":"","body":"题目 给定一个链表和一个特定值 x，对链表进行分隔，使得所有小于 x 的节点都在大于或等于 x 的节点之前。 你应当保留两个分区中每个节点的初始相对位置。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode partition(ListNode head, int x) { { // before and after are the two pointers used to create the two list // before_head and after_head are used to save the heads of the two lists. // All of these are initialized with the dummy nodes created. ListNode before_head = new ListNode(0); ListNode before = before_head; ListNode after_head = new ListNode(0); ListNode after = after_head; while (head != null) { // If the original list node is lesser than the given x, // assign it to the before list. if (head.val "},"content/Algorithm/环形链表.html":{"url":"content/Algorithm/环形链表.html","title":"环形链表","keywords":"","body":"题目 给定一个链表，判断链表中是否有环。 如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。 如果链表中存在环，则返回 true 。 否则，返回 false 。 解题思路 代码 /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next ==null){ return false; } ListNode slow = head; ListNode fast = head.next; while (slow != fast){ if(fast ==null || fast.next == null){ return false; } slow = slow.next; fast = fast.next.next; } return true; } } "},"content/Algorithm/环形链表II.html":{"url":"content/Algorithm/环形链表II.html","title":"环形链表II","keywords":"","body":"题目 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 解题思路 代码 /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { //遍历链表中的每个节点，并将它记录下来；一旦遇到了此前遍历过的节点，就可以判定链表中存在环。借助哈希表可以很方便地实现。 public ListNode detectCycle(ListNode head) { ListNode pos = head; Set visited = new HashSet(); while (pos != null) { if (visited.contains(pos)) { return pos; } else { visited.add(pos); } pos = pos.next; } return null; } public ListNode detectCycle(ListNode head) { //快慢指针 if (head == null) { return null; } ListNode slow = head, fast = head; while (fast != null) { slow = slow.next; if (fast.next != null) { fast = fast.next.next; } else { return null; } if (fast == slow) { ListNode ptr = head; while (ptr != slow) { ptr = ptr.next; slow = slow.next; } return ptr; } } return null; } } "},"content/Algorithm/删除链表中重复元素.html":{"url":"content/Algorithm/删除链表中重复元素.html","title":"删除链表中重复元素","keywords":"","body":"题目 给定一个排序链表，删除所有重复的元素，使得每个元素只出现一次。 解题思路 代码 /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode current = head; while (current != null && current.next != null){ if (current.val == current.next.val){ current.next = current.next.next; }else { current = current.next; } } return head; } } "},"content/Algorithm/删除链表中重复元素不保留.html":{"url":"content/Algorithm/删除链表中重复元素不保留.html","title":"删除链表中重复元素不保留","keywords":"","body":"题目 给定一个排序链表，删除所有含有重复数字的节点，只保留原始链表中 没有重复出现 的数字。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ //链表头结点可能被删除，所以用 dummy node 辅助删除 class Solution { public ListNode deleteDuplicates(ListNode head) { if(head==null || head.next==null) { return head; } ListNode dummy = new ListNode(-1); dummy.next = head; ListNode a = dummy; ListNode b = head; while(b!=null && b.next!=null) { //初始化的时a指向的是哑结点，所以比较逻辑应该是a的下一个节点和b的下一个节点 if(a.next.val!=b.next.val) { a = a.next; b = b.next; } else { //如果a、b指向的节点值相等，就不断移动b，直到a、b指向的值不相等 while(b!=null && b.next!=null && a.next.val==b.next.val) { b = b.next; } a.next = b.next; b = b.next; } } return dummy.next; } } "},"content/Algorithm/合并两个有序列表.html":{"url":"content/Algorithm/合并两个有序列表.html","title":"合并两个有序列表","keywords":"","body":"题目 将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode mergeTwoLists(ListNode L1, ListNode L2) { ListNode tempHead = new ListNode(-1); ListNode node = tempHead; while (L1 != null && L2 != null){ if (L1.val "},"content/Algorithm/删除链表给定值节点.html":{"url":"content/Algorithm/删除链表给定值节点.html","title":"删除链表给定值节点","keywords":"","body":"题目 给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。 返回删除后的链表的头节点。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode deleteNode(ListNode head, int val) { //初始化一个虚拟节点 ListNode dummy = new ListNode(0); //让虚拟节点指向头结点 dummy.next = head; ListNode cur = head; ListNode pre = dummy; while (cur != null) { if (cur.val == val) { //如果找到要删除的结点，直接把他删除 pre.next = cur.next; break; } //如果没找到，pre指针和cur指针都同时往后移一步 pre = cur; cur = cur.next; } //最后返回虚拟节点的下一个结点即可 return dummy.next; } } "},"content/Algorithm/链表中倒数第K个节点.html":{"url":"content/Algorithm/链表中倒数第K个节点.html","title":"链表中倒数第K个节点","keywords":"","body":"题目 输入一个链表，输出该链表中倒数第k个节点。为了符合大多数人的习惯，本题从1开始计数，即链表的尾节点是倒数第1个节点。例如，一个链表有6个节点，从头节点开始，它们的值依次是1、2、3、4、5、6。这个链表的倒数第3个节点是值为4的节点。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode getKthFromEnd(ListNode head, int k) { ListNode pre = head; ListNode cur = head; for(int i = 0;i "},"content/Algorithm/从尾到头打印列表.html":{"url":"content/Algorithm/从尾到头打印列表.html","title":"从尾到头打印列表","keywords":"","body":"题目 输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public int[] reversePrint(ListNode head) { Stack stack = new Stack(); ListNode temp = head; while (temp != null) { stack.push(temp); temp = temp.next; } int size = stack.size(); int[] print = new int[size]; for (int i = 0; i "},"content/Algorithm/反转m到n的链表.html":{"url":"content/Algorithm/反转m到n的链表.html","title":"反转m到n的链表","keywords":"","body":"题目 反转从位置 m 到 n 的链表。请使用一趟扫描完成反转。 说明: 1 ≤ m ≤ n ≤ 链表长度。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { ListNode successor = null; // 后驱节点 ListNode reverseBetween(ListNode head, int m, int n) { // base case if (m == 1) { return reverseN(head, n); } // 前进到反转的起点触发 base case head.next = reverseBetween(head.next, m - 1, n - 1); return head; } ListNode reverseN(ListNode head, int n) { if (n == 1) { // 记录第 n + 1 个节点 successor = head.next; return head; } // 以 head.next 为起点，需要反转前 n - 1 个节点 ListNode last = reverseN(head.next, n - 1); head.next.next = head; // 让反转之后的 head 节点和后面的节点连起来 head.next = successor; return last; } } "},"content/Algorithm/回文列表.html":{"url":"content/Algorithm/回文列表.html","title":"回文列表","keywords":"","body":"题目 请判断一个链表是否为回文链表。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public boolean isPalindrome(ListNode head) { List vals = new ArrayList(); // 将链表的值复制到数组中 ListNode currentNode = head; while (currentNode != null) { vals.add(currentNode.val); currentNode = currentNode.next; } // 使用双指针判断是否回文 int front = 0; int back = vals.size() - 1; while (front "},"content/Algorithm/链表中间节点.html":{"url":"content/Algorithm/链表中间节点.html","title":"链表中间节点","keywords":"","body":"题目 给定一个头结点为 head 的非空单链表，返回链表的中间结点。 如果有两个中间结点，则返回第二个中间结点。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode middleNode(ListNode head) { ListNode slow = head, fast = head; while (fast != null && fast.next != null) { slow = slow.next; fast = fast.next.next; } return slow; } } "},"content/Algorithm/删除链表的倒数第N个节点.html":{"url":"content/Algorithm/删除链表的倒数第N个节点.html","title":"删除链表的倒数第N个节点","keywords":"","body":"题目 给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。 解题思路 代码 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode middleNode(ListNode head) { ListNode slow = head, fast = head; while (fast != null && fast.next != null) { slow = slow.next; fast = fast.next.next; } return slow; } } "},"content/Algorithm/整数拆分乘积最大.html":{"url":"content/Algorithm/整数拆分乘积最大.html","title":"整数拆分乘积最大","keywords":"","body":"题目 给定一个正整数 n，将其拆分为至少两个正整数的和，并使这些整数的乘积最大化。 返回你可以获得的最大乘积。 解题思路 代码 class Solution { public int integerBreak(int n) { int[] dp = new int[n + 1]; for (int i = 2; i "},"content/Algorithm/礼物的最大价值.html":{"url":"content/Algorithm/礼物的最大价值.html","title":"礼物的最大价值","keywords":"","body":"题目 在一个 m*n 的棋盘的每一格都放有一个礼物，每个礼物都有一定的价值（价值大于 0）。你可以从棋盘的左上角开始拿格子里的礼物，并每次向右或者向下移动一格、直到到达棋盘的右下角。给定一个棋盘及其上面的礼物的价值，请计算你最多能拿到多少价值的礼物？ 解题思路 代码 class Solution { public int maxValue(int[][] grid) { int m = grid.length, n = grid[0].length; for(int i = 0; i "},"content/Algorithm/斐波那契数.html":{"url":"content/Algorithm/斐波那契数.html","title":"斐波那契数","keywords":"","body":"题目 F(0) = 0, F(1) = 1 F(N) = F(N - 1) + F(N - 2), 其中 N > 1. 解题思路 代码 class Solution { public int fib(int N) { if(N == 0){ return 0; } int[] dp = new int[N+1]; dp[0] = 0; dp[1] = 1; for(int i = 2;i "},"content/Algorithm/股票最大利润.html":{"url":"content/Algorithm/股票最大利润.html","title":"股票最大利润","keywords":"","body":"题目 假设把某股票的价格按照时间先后顺序存储在数组中，请问买卖该股票一次可能获得的最大利润是多少？ 解题思路 代码 class Solution { public int maxProfit(int[] prices) { if(prices.length == 0) return 0; int profit = 0, cost = prices[0]; for(int i = 1; i "},"content/Algorithm/零钱兑换.html":{"url":"content/Algorithm/零钱兑换.html","title":"零钱兑换","keywords":"","body":"题目 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 你可以认为每种硬币的数量是无限的。 解题思路 代码 //状态转移方程 public class Solution { public int coinChange(int[] coins, int amount) { int max = amount + 1; int[] dp = new int[amount + 1]; //填充数组 Arrays.fill(dp, max); dp[0] = 0; for (int i = 1; i amount ? -1 : dp[amount]; } } "},"content/Algorithm/两个栈实现队列.html":{"url":"content/Algorithm/两个栈实现队列.html","title":"两个栈实现队列","keywords":"","body":"题目 用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 ) 解题思路 代码 class CQueue { Deque stack1; Deque stack2; public CQueue() { stack1 = new LinkedList(); stack2 = new LinkedList(); } public void appendTail(int value) { stack1.push(value); } public int deleteHead() { // 如果第二个栈为空 if (stack2.isEmpty()) { while (!stack1.isEmpty()) { stack2.push(stack1.pop()); } } if (stack2.isEmpty()) { return -1; } else { int deleteItem = stack2.pop(); return deleteItem; } } } "},"content/Algorithm/数值的整数次方.html":{"url":"content/Algorithm/数值的整数次方.html","title":"数值的整数次方","keywords":"","body":"题目 实现函数double Power(double base, int exponent)，求base的exponent次方。不得使用库函数，同时不需要考虑大数问题。 解题思路 代码 class Solution { public double myPow(double x, int n) { if(x == 0) return 0; long b = n; double res = 1.0; if(b 0) { if((b & 1) == 1) res *= x; x *= x; b >>= 1; } return res; } } "},"content/Algorithm/有效的括号.html":{"url":"content/Algorithm/有效的括号.html","title":"有效的括号","keywords":"","body":"题目 给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。 解题思路 代码 class Solution { public boolean isValid(String s) { //1.特判 if(s.isEmpty()) return true; //2.创建辅助栈 Stack stack = new Stack<>(); //3.遍历 for(char c : s.toCharArray()){ if(c == '('){ stack.push(')'); }else if(c == '['){ stack.push(']'); }else if(c == '{'){ stack.push('}'); }else if(stack.isEmpty() || c != stack.pop()){ return false; } } //4.返回 return stack.isEmpty(); } } "},"content/Algorithm/栈的压入弹出序列.html":{"url":"content/Algorithm/栈的压入弹出序列.html","title":"栈的压入弹出序列","keywords":"","body":"题目 输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如，序列 {1,2,3,4,5} 是某栈的压栈序列，序列 {4,5,3,2,1} 是该压栈序列对应的一个弹出序列，但 {4,3,5,1,2} 就不可能是该压栈序列的弹出序列。 解题思路 考虑借用一个辅助栈 stackstack ，模拟 压入 / 弹出操作的排列。根据是否模拟成功，即可得到结果。 代码 class Solution { public boolean validateStackSequences(int[] pushed, int[] popped) { Stack stack = new Stack<>(); int j = 0; for(int i = 0;i "}}