# 缓存

## 缓存雪崩

缓存雪崩就是 Redis 的大量热点数据同时过期(失效)，因为设置了相同的过期时 间，刚好这个时候 Redis 请求的并发量又很大，就会导致所有的请求落到数据库。

解决方案：

1. 加互斥锁或者使用队列，针对同一个 key 只允许一个线程到数据库查询 
2. 缓存定时预先更新，避免同时失效
3. 通过加随机数，使 key 在不同的时间过期
4. 缓存永不过期

## 缓存穿透

缓存穿透是指查询一个根本不存在的数据， 导致每次请求都要到存储层去查询。

解决方案：

1. 缓存空对象
2. 布隆过滤器

### 布隆过滤器

布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。

向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash。得到一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就 完成了 add 操作。

向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位 置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在

## 缓存击穿

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，大并发的请求可能会瞬间把后端DB压垮。

用分布式锁控制访问的线程。

## 缓存一致性

解决方案一：

先删除缓存，再操作数据库。操作数据库成功之后再删除缓存。

如果是主从数据库，使用从库binlog删除，一主多从，每个从库都要采集binlog，消费端收到最后一个binlog才删除缓存。

解决方案二：

更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。

一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。

如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。

# 分布式锁

## Redission实现

```java
RLock lock = Redisson.get("myLock");
lock.lock();
lock.unlock();
```

使用Lua脚本进行加锁。如果锁不存在，hset myLock "客户端id" ：重入次数。接着设置锁过期时间。如果锁存在，则比较客户端id，不包含则返回剩余生存时间。

watch dog启动一个后台线程，每隔10秒检查客户端是否还持有锁，会不断延长锁的时间。

## RedLock

RedLock 的思想是使用多台 Redis Master ，节点完全独立，节点间不需要进行数据同步，因为 Master-Slave 架构一旦 Master 发生故障时数据没有复制到 Slave，被选为 Master 的 Slave 就丢掉了锁，另一个客户端就可以再次拿到锁。锁通过 setNX（原子操作） 命令设置，在有效时间内当获得锁的数量大于 (n/2+1) 代表成功，失败后需要向所有节点发送释放锁的消息。

## 高并发优化

分布式锁的方案在高并发场景下，分布式锁一旦加了之后，对同一个商品的下单请求，会导致所有客户端都必须对同一个商品的库存锁key进行加锁。可以分段加锁，将库存拆成多个库存段，类似stock_01，stock_02。用随机算法，将请求随机在20个分段库存里，选择一个进行加锁。

##  redis 分布式锁和 zk 分布式锁的对比

- redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
- zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。

另外一点就是，如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

redis 分布式锁麻烦，遍历上锁，计算时间等等。zk 的分布式锁语义清晰实现简单。